[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Python/R for Data Science",
    "section": "",
    "text": "This is the lecture notes for STAT 2304 Programming languages for Data Science 2022 Fall at ATU. If you have any comments/suggetions/concers about the notes please contact me at my email xxiao@atu.edu."
  },
  {
    "objectID": "contents/1/01-.html#hello-world",
    "href": "contents/1/01-.html#hello-world",
    "title": "1  Preliminaries",
    "section": "1.2 Hello world!",
    "text": "1.2 Hello world!\n\n\n1.2.1 Setup the Python environment\nIn this section we are going to setup the Python developing environment.\n\n1.2.1.1 VS Code + Anaconda\nClick Appendix A.1 to see the detailed steps for VS Code and Anaconda. You may also check out the official document. It contains more features but less details.\nWe will talk about the relation between Python and Anaconda and more about packages sometime later.\n\n\n1.2.1.2 Google Colab\nClick Appendix A.2 for more details.\n\n\n\n1.2.2 Hello World!\n\nTake VS Code as an example. In the editor window, type in the code, and run the file in the interactive window.\n\nprint('Hello World!')\n\n\n\n\n\n\nIf you see a small green check mark in the interactive window and also the output Hello World!, you are good to go!\n\n\n1.2.3 Python code cells and Notebooks\nIn VS Code you can run codes cell by cell. Each cell is separated by the symbol # %%. Each cell may contain multiple lines. You may click the small button on top of the cell or use keybindings.\n\n\n\n\n\nThis feature actually mimic the notebook. We may start a real Python Notebook file by directly creating a file with extension .ipynb.\n\n\n\n\n\nThe layout is straightforward.\n\n\n1.2.4 Linters\n\n\n\n\n1.2.5 IPython and Jupyter"
  },
  {
    "objectID": "contents/1/01-.html#projects",
    "href": "contents/1/01-.html#projects",
    "title": "1  Preliminaries",
    "section": "1.3 Projects",
    "text": "1.3 Projects\n\nExercise 1.1 (Hello world!) Please set up a Python developing environment, including for .py file and for notebook, that will be used across the semester. Then print Hello World!.\n\n\nExercise 1.2 (Define a function and play with time) Please play with the following codes in a Jupyter notebook. We haven’t talked about any of them right now. Try to guess what they do and write your guess in markdown cells.\n\nimport time\n\ndef multistr(x, n=2):\n    return x * n\n\nt0 = time.time()\nx = 'Python'\nprint(multistr(x, n=10))\nt1 = time.time()\nprint(\"Time used: \", t1-t0)\n\n\n\nExercise 1.3 (Fancy Basketball plot) Here is an example of the data analysis. We pull data from a dataset, filter the data according to our needs and plot it to visualize the data. This is just a show case. You are encouraged to play the code, make tweaks and see what would happen. You don’t have to turn in anything.\nThe data we choose is Stephen Curry’s shots data in 2021-2022 regular season. First we need to load the data. The data is obtained from nba.com using nba_api.\n\nfrom nba_api.stats.static import players\nfrom nba_api.stats.endpoints import shotchartdetail\nplayer_dict = players.get_players()\n\nThe shots data we need is in shotchartdetail. However to use it we need to know the id of Stephen Curry using the dataset player_dict.\n\nfor player in player_dict:\n    if player['full_name'] == 'Stephen Curry':\n        print(player['id'])\n\n201939\n\n\nSo the id of Stephen Curry is 201939. Let’s pull out his shots data in 2021-2022 season.\n\nresults = shotchartdetail.ShotChartDetail(\n            team_id = 0,\n            player_id = 201939,\n            context_measure_simple = 'FGA',\n            season_nullable = '2021-22',\n            season_type_all_star = 'Regular Season')\ndf = results.get_data_frames()[0]\ndf.head()\n\n\n\n\n\n  \n    \n      \n      GRID_TYPE\n      GAME_ID\n      GAME_EVENT_ID\n      PLAYER_ID\n      PLAYER_NAME\n      TEAM_ID\n      TEAM_NAME\n      PERIOD\n      MINUTES_REMAINING\n      SECONDS_REMAINING\n      ...\n      SHOT_ZONE_AREA\n      SHOT_ZONE_RANGE\n      SHOT_DISTANCE\n      LOC_X\n      LOC_Y\n      SHOT_ATTEMPTED_FLAG\n      SHOT_MADE_FLAG\n      GAME_DATE\n      HTM\n      VTM\n    \n  \n  \n    \n      0\n      Shot Chart Detail\n      0022100002\n      26\n      201939\n      Stephen Curry\n      1610612744\n      Golden State Warriors\n      1\n      10\n      9\n      ...\n      Left Side Center(LC)\n      24+ ft.\n      28\n      -109\n      260\n      1\n      0\n      20211019\n      LAL\n      GSW\n    \n    \n      1\n      Shot Chart Detail\n      0022100002\n      34\n      201939\n      Stephen Curry\n      1610612744\n      Golden State Warriors\n      1\n      9\n      41\n      ...\n      Center(C)\n      24+ ft.\n      26\n      48\n      257\n      1\n      0\n      20211019\n      LAL\n      GSW\n    \n    \n      2\n      Shot Chart Detail\n      0022100002\n      37\n      201939\n      Stephen Curry\n      1610612744\n      Golden State Warriors\n      1\n      9\n      10\n      ...\n      Left Side Center(LC)\n      24+ ft.\n      25\n      -165\n      189\n      1\n      1\n      20211019\n      LAL\n      GSW\n    \n    \n      3\n      Shot Chart Detail\n      0022100002\n      75\n      201939\n      Stephen Curry\n      1610612744\n      Golden State Warriors\n      1\n      6\n      17\n      ...\n      Center(C)\n      Less Than 8 ft.\n      1\n      -13\n      12\n      1\n      0\n      20211019\n      LAL\n      GSW\n    \n    \n      4\n      Shot Chart Detail\n      0022100002\n      130\n      201939\n      Stephen Curry\n      1610612744\n      Golden State Warriors\n      1\n      3\n      11\n      ...\n      Center(C)\n      Less Than 8 ft.\n      2\n      -15\n      22\n      1\n      0\n      20211019\n      LAL\n      GSW\n    \n  \n\n5 rows × 24 columns\n\n\n\ndf is the results we get in terms of a DataFrame, and we show the first 5 records as an example.\nThese are all attempts. We are interested in all made. By looking at all the columns, we find a column called SHOT_MADE_FLAG which shows what we want. Therefore we will use it to filter the records.\n\ndf_made = df[df['SHOT_MADE_FLAG']==1]\ndf_made.head()\n\n\n\n\n\n  \n    \n      \n      GRID_TYPE\n      GAME_ID\n      GAME_EVENT_ID\n      PLAYER_ID\n      PLAYER_NAME\n      TEAM_ID\n      TEAM_NAME\n      PERIOD\n      MINUTES_REMAINING\n      SECONDS_REMAINING\n      ...\n      SHOT_ZONE_AREA\n      SHOT_ZONE_RANGE\n      SHOT_DISTANCE\n      LOC_X\n      LOC_Y\n      SHOT_ATTEMPTED_FLAG\n      SHOT_MADE_FLAG\n      GAME_DATE\n      HTM\n      VTM\n    \n  \n  \n    \n      2\n      Shot Chart Detail\n      0022100002\n      37\n      201939\n      Stephen Curry\n      1610612744\n      Golden State Warriors\n      1\n      9\n      10\n      ...\n      Left Side Center(LC)\n      24+ ft.\n      25\n      -165\n      189\n      1\n      1\n      20211019\n      LAL\n      GSW\n    \n    \n      6\n      Shot Chart Detail\n      0022100002\n      176\n      201939\n      Stephen Curry\n      1610612744\n      Golden State Warriors\n      1\n      0\n      27\n      ...\n      Center(C)\n      Less Than 8 ft.\n      2\n      -7\n      29\n      1\n      1\n      20211019\n      LAL\n      GSW\n    \n    \n      9\n      Shot Chart Detail\n      0022100002\n      352\n      201939\n      Stephen Curry\n      1610612744\n      Golden State Warriors\n      2\n      1\n      29\n      ...\n      Center(C)\n      Less Than 8 ft.\n      1\n      -1\n      10\n      1\n      1\n      20211019\n      LAL\n      GSW\n    \n    \n      16\n      Shot Chart Detail\n      0022100002\n      510\n      201939\n      Stephen Curry\n      1610612744\n      Golden State Warriors\n      3\n      2\n      23\n      ...\n      Center(C)\n      Less Than 8 ft.\n      1\n      7\n      8\n      1\n      1\n      20211019\n      LAL\n      GSW\n    \n    \n      18\n      Shot Chart Detail\n      0022100002\n      642\n      201939\n      Stephen Curry\n      1610612744\n      Golden State Warriors\n      4\n      5\n      34\n      ...\n      Center(C)\n      24+ ft.\n      26\n      48\n      260\n      1\n      1\n      20211019\n      LAL\n      GSW\n    \n  \n\n5 rows × 24 columns\n\n\n\nWe also notice that there are two columns LOC_X and LOC_Y shows the coordinates of the attempts. We will use it to draw the heatmap. The full code for drawing out the court draw_court is folded below. It is from Bradley Fay GitHub.\n\n\n\n\n\n\nNote\n\n\n\nNote that, although draw_cort is long, it is not hard to understand. It just draws a court piece by piece.\n\n\n\n\nCode\nfrom matplotlib.patches import Circle, Rectangle, Arc\nimport matplotlib.pyplot as plt\n\n\ndef draw_court(ax=None, color='gray', lw=1, outer_lines=False):\n    \"\"\"\n    Returns an axes with a basketball court drawn onto to it.\n\n    This function draws a court based on the x and y-axis values that the NBA\n    stats API provides for the shot chart data.  For example, the NBA stat API\n    represents the center of the hoop at the (0,0) coordinate.  Twenty-two feet\n    from the left of the center of the hoop in is represented by the (-220,0)\n    coordinates.  So one foot equals +/-10 units on the x and y-axis.\n    \"\"\"\n    if ax is None:\n        ax = plt.gca()\n\n    # Create the various parts of an NBA basketball court\n\n    # Create the basketball hoop\n    hoop = Circle((0, 0), radius=7.5, linewidth=lw, color=color, fill=False)\n\n    # Create backboard\n    backboard = Rectangle((-30, -7.5), 60, -1, linewidth=lw, color=color)\n\n    # The paint\n    # Create the outer box 0f the paint, width=16ft, height=19ft\n    outer_box = Rectangle((-80, -47.5), 160, 190, linewidth=lw, color=color,\n                          fill=False)\n    # Create the inner box of the paint, widt=12ft, height=19ft\n    inner_box = Rectangle((-60, -47.5), 120, 190, linewidth=lw, color=color,\n                          fill=False)\n\n    # Create free throw top arc\n    top_free_throw = Arc((0, 142.5), 120, 120, theta1=0, theta2=180,\n                         linewidth=lw, color=color, fill=False)\n    # Create free throw bottom arc\n    bottom_free_throw = Arc((0, 142.5), 120, 120, theta1=180, theta2=0,\n                            linewidth=lw, color=color, linestyle='dashed')\n    # Restricted Zone, it is an arc with 4ft radius from center of the hoop\n    restricted = Arc((0, 0), 80, 80, theta1=0, theta2=180, linewidth=lw,\n                     color=color)\n\n    # Three point line\n    # Create the right side 3pt lines, it's 14ft long before it arcs\n    corner_three_a = Rectangle((-220, -47.5), 0, 140, linewidth=lw,\n                               color=color)\n    # Create the right side 3pt lines, it's 14ft long before it arcs\n    corner_three_b = Rectangle((220, -47.5), 0, 140, linewidth=lw, color=color)\n    # 3pt arc - center of arc will be the hoop, arc is 23'9\" away from hoop\n    three_arc = Arc((0, 0), 475, 475, theta1=22, theta2=158, linewidth=lw,\n                    color=color)\n\n    # Center Court\n    center_outer_arc = Arc((0, 422.5), 120, 120, theta1=180, theta2=0,\n                           linewidth=lw, color=color)\n    center_inner_arc = Arc((0, 422.5), 40, 40, theta1=180, theta2=0,\n                           linewidth=lw, color=color)\n\n    # List of the court elements to be plotted onto the axes\n    court_elements = [hoop, backboard, outer_box, inner_box, top_free_throw,\n                      bottom_free_throw, restricted, corner_three_a,\n                      corner_three_b, three_arc, center_outer_arc,\n                      center_inner_arc]\n\n    if outer_lines:\n        # Draw the half court line, baseline and side out bound lines\n        outer_lines = Rectangle((-250, -47.5), 500, 470, linewidth=lw,\n                                color=color, fill=False)\n        court_elements.append(outer_lines)\n\n    # Add the court elements onto the axes\n    for element in court_elements:\n        ax.add_patch(element)\n\n    return ax\n\n\n\n# Create figure and axes\nfig = plt.figure(figsize=(6, 6))\nax = fig.add_axes([0, 0, 1, 1])\n\n# Plot hexbin of shots\nax.hexbin(df['LOC_X'], df['LOC_Y'], gridsize=(30, 30), extent=(-300, 300, 0, 940), bins='log', cmap='Blues')\nax = draw_court(ax, 'black')\n\n# Annotate player name and season\nax.text(0, 1.05, 'Stephen Curry\\n2021-22 Regular Season', transform=ax.transAxes, ha='left', va='baseline')\n\n# Set axis limits\n_ = ax.set_xlim(-250, 250)\n_ = ax.set_ylim(0, 400)\n\n\n\n\n\n\n\nClick for Hint.\n\n\n\nSolution (Hint). \nfrom nba_api.stats.static import players\nfrom nba_api.stats.endpoints import shotchartdetail\nplayer_dict = players.get_players()\n\nThese lines import some packages and get player information and save them into player_dict.\n\nfor player in player_dict:\n    if player['full_name'] == 'Stephen Curry':\n        print(player['id'])\n\nGo through all records in player_dict. If the name of a player is Stephen Curry, get his id. Then we will know the id of Stephen Curry.\nTo be omitted."
  },
  {
    "objectID": "contents/2/02-.html",
    "href": "contents/2/02-.html",
    "title": "2  Python Basics",
    "section": "",
    "text": "This section is based on [1].\nThere are several built-in data structures in Python. Here is an (incomplete) list:\n\nNone\nBoolean – True, False\nNumeric Types — int, float, complex\nText Sequence Type — str\nSequence Types — list\nMap type - dict\n\nWe will cover numeric types and strings in this section. The rests are either simple that are self-explained, or not simple that will be discussed later.\n\n\nNumeric types are represented by numbers. If there are no confusions, Python will automatically detect the type.\n\nx = 1 # x is an int.\ny = 2.0 # y is a float.\n\nPython can do math just like other programming languages. The basic math operations are listed as follows.\n\n+, -, *, /, >, <, >=, <= works as normal.\n** is the power operation.\n% is the mod operation.\n!= is not equal\n\n\n\n\nScalars are represented by numbers and strings are represented by quotes. Example:\n\nx = 1       # x is a scalar.\ny = 's'     # y is a string with one letter.\nz = '0'     # z loos like a number, but it is a string.\nw = \"Hello\" # w is a string with double quotes.\n\nHere are some facts.\n\nFor strings, you can use either single quotes ' or double quotes \".\n\\ is used to denote escaped words. You may find the list Here.\nThere are several types of scalars, like int, float, etc.. Usually Python will automatically determine the type of the data, but sometimes you may still want to declare them manually.\nYou can use int(), str(), etc. to change types.\n\nAlthough str is a built-in type, there are tons of tricks with str, and there are tons of packages related to strings. Generally speaking, to play with strings, we are interested in two types of questions.\n\nPut information together to form a string.\nExtract information from a string. We briefly talk about these two tasks.\n\n\n\n\n\n\n\nNote\n\n\n\nThere is a very subtle relations between the variable / constant and the name of the variable / constant. We will talk about these later.\n\n\n\nExample 2.1 Here is an example of playing with strings. Please play with these codes and try to understand what they do.\n\nimport re\n\ndef clean_strings(strings):\n    result = []\n    for value in strings:\n        value = value.strip()\n        value = re.sub('[!#?]', '', value)\n        value = value.title()\n        result.append(value)\n    return result\n\nstates = [' Alabama ', 'Georgia!', 'Georgia', 'georgia', 'FlOrIda',\n          'south carolina##', 'West virginia?']\nprint(clean_strings(states))\n\n['Alabama', 'Georgia', 'Georgia', 'Georgia', 'Florida', 'South Carolina', 'West Virginia']"
  },
  {
    "objectID": "contents/2/02-.html#fundamentals",
    "href": "contents/2/02-.html#fundamentals",
    "title": "2  Python Basics",
    "section": "2.2 Fundamentals",
    "text": "2.2 Fundamentals\nThis section is mainly based on [2].\n\n2.2.1 Indentation\nOne key feature about Python is that its structures (blocks) is determined by Indentation.\nLet’s compare with other languages. Let’s take C as an example.\n\n/*This is a C function.*/\nint f(int x){return x;}\n\nThe block is defined by {} and lines are separated by ;. space and newline are not important when C runs the code. It is recommended to write codes in a “beautiful, stylish” format for readibility, as follows. However it is not mandatary.\n\n/*This is a C function.*/\nint f(int x) {\n   return x;\n}\n\nIn Python, blocks starts from : and then are determined by indents. Therefore you won’t see a lot of {} in Python, and the “beautiful, stylish” format is mandatary.\n\n# This is a Python function.\ndef f(x):\n    return x\n\nThe default value for indentation is 4 spaces, which can be changed by users. We will just use the default value in this course.\n\n\n\n\n\n\nNote\n\n\n\nIt is usually recommended that one line of code should not be very long. If you do have one, and it cannot be shortened, you may break it into multiline codes directly in Python. However, since indentation is super important in Python, when break one line code into multilines, please make sure that everything is aligned perfectly. Please see the following example.\n\nresults = shotchartdetail.ShotChartDetail(\n            team_id = 0,\n            player_id = 201939,\n            context_measure_simple = 'FGA',\n            season_nullable = '2021-22',\n            season_type_all_star = 'Regular Season')\n\n\n\n\n\n2.2.2 Binary operators and comparisons\nMost binary operators behaves as you expected. Here I just want to mention == and is.\n\n== is testing whehter these two objects have the same value.\nis is testing whether these two objects are exactly the same.\n\n\n\n\n\n\n\nNote\n\n\n\nYou may use id(x) to check the id of the object x. Two objects are identical if they have the same id.\n\n\n\n\n\n2.2.3 import\nIn Python a module is simply a file with the .py extension containing Python code. Assume that we have a Python file example.py stored in the folder assests/codes/. The file is as follows.\n\n# from assests/codes/example.py\n\ndef f(x):\n    print(x)\n\nA = 'You get me!'\n\nYou may get access to this function and this string in the following way.\n\nfrom assests.codes import example\n\nexample.f(example.A)\n\nYou get me!\n\n\n\n\n2.2.4 Comments\nAny text preceded by the hash mark (pound sign) # is ignored by the Python interpreter. In many IDEs you may use hotkeys to directly toggle multilines as comments. For example, in VS Code the default setting for toggling comments is ctrl+/.\n\n\n2.2.5 Dynamic references, strong types\nIn some programming languages, you have to declare the variable’s name and what type of data it will hold. If a variable is declared to be a number, it can never hold a different type of value, like a string. This is called static typing because the type of the variable can never change.\nPython is a dynamically typed language, which means you do not have to declare a variable or what kind of data the variable will hold. You can change the value and type of data at any time. This could be either great or terrible news.\nOn the other side, “dynamic typed” doesn’t mean that types are not important in Python. You still have to make sure that the types of all variables meet the requirements of the operations used.\n\na = 1\nb = 2\nb = '2'\nc = a + b\n\nTypeError: unsupported operand type(s) for +: 'int' and 'str'\n\n\nIn this example, b was first assigned by a number, and then it was reassigned by a str. This is totally fine since Python is dynamically types. However later when adding a and b, the type error occurs since you cannot add a number and a str.\n\n\n\n\n\n\nNote\n\n\n\nYou may always use type(x) to detect the type of the object x.\n\n\n\n\n2.2.6 Everything is an object\nEvery number, string, data structure, function, class, module, and so on exists in the Python interpreter in its own “box”, which is referred to as a Python object.\nEach object has an associated type (e.g., string or function) and internal data. In practice this makes the language very flexible, as even functions can be treated like any other object.\nEach object might have attributes and/or methods attached.\n\n\n2.2.7 Mutable and immutable objects\nAn object whose internal state can be changed is mutable. On the other hand, immutable doesn’t allow any change in the object once it has been created.\nSome objects of built-in type that are mutable are:\n\nLists\nDictionaries\nSets\n\nSome objects of built-in type that are immutable are:\n\nNumbers (Integer, Rational, Float, Decimal, Complex & Booleans)\nStrings\nTuples\n\n\nExample 2.2 (Tuples are not really “immutable”) You can treat a tuple as a container, which contains some objects. The relations between the container and its contents are immutable, but the objects it holds might be mutable. Please check the following example.\n\ncontainer = ([1], [2])\nprint('This is `container`: ', container)\nprint('This is the id of `container`: ', id(container))\nprint('This is the id of the first list of `container`: ', id(container[0]))\n\ncontainer[0].append(2)\nprint('This is the new `container`: ', container)\nprint('This is the id of the new `container`: ', id(container))\nprint('This is the id of the first list (which is updated) of the new `container`: ', id(container[0]))\n\nThis is `container`:  ([1], [2])\nThis is the id of `container`:  1757463180032\nThis is the id of the first list of `container`:  1757463111872\nThis is the new `container`:  ([1, 2], [2])\nThis is the id of the new `container`:  1757463180032\nThis is the id of the first list (which is updated) of the new `container`:  1757463111872\n\n\nYou can see that the tuple container and its first object stay the same, although we add one element to the first object."
  },
  {
    "objectID": "contents/2/02-.html#flows-and-logic",
    "href": "contents/2/02-.html#flows-and-logic",
    "title": "2  Python Basics",
    "section": "2.3 Flows and Logic",
    "text": "2.3 Flows and Logic\n\n2.3.1 for loop\n\nrange(10)\nlist\n\n\n\n2.3.2 if conditional control"
  },
  {
    "objectID": "contents/2/02-.html#list",
    "href": "contents/2/02-.html#list",
    "title": "2  Python Basics",
    "section": "2.4 list",
    "text": "2.4 list\n\n\n\n\n\n\nNote\n\n\n\nIn Python, a list is an ordered sequence of object types and a string is an ordered sequence of characters.\n\n\n\nAccess to the data\nSlicing\nMethods\n\nappend and +\nextend\npop\nremove\n\nin\nfor\nlist()\nsorted\nstr.split\nstr.join\n\n\n2.4.1 List Comprehension\nList Comprehension is a convenient way to create lists based on the values of an existing list. It cannot provide any real improvement to the performance of the codes, but it can make the codes shorter and easier to read.\nThe format of list Comprehension is\nnewlist = [expression for item in iterable if condition == True]"
  },
  {
    "objectID": "contents/2/02-.html#dict",
    "href": "contents/2/02-.html#dict",
    "title": "2  Python Basics",
    "section": "2.5 dict",
    "text": "2.5 dict\n\nAccess to the data\nMethods\n\ndirectly add items\nupdate\nget\nkeys\nvalues\nitems\n\ndict()\ndictionary comprehension"
  },
  {
    "objectID": "contents/2/02-.html#exercises",
    "href": "contents/2/02-.html#exercises",
    "title": "2  Python Basics",
    "section": "2.6 Exercises",
    "text": "2.6 Exercises\nMost problems are based on [3], [1] and [4].\n\nExercise 2.1 (Indentation) Please tell the differences between the following codes. If you don’t understand for don’t worry about it. Just focus on the indentation and try to understand how the codes work.\n\nfor i in range(5):\n    print('Hello world!')\nprint('Hello world!')\n\n\nfor i in range(5):\n    print('Hello world!')\n    print('Hello world!')\n\n\nfor i in range(5):\nprint('Hello world!')\nprint('Hello world!')\n\n\nfor i in range(5):\n    pass\nprint('Hello world!')\nprint('Hello world!')\n\n\n\nExercise 2.2 (Play with built-in data types) Please first guess the results of all expressions below, and then run them to check your answers.\n\nprint(True and True)\nprint(True or True)\nprint(False and True)\nprint((1+1>2) or (1-1<1))\n\n\n\nExercise 2.3 (== vs is) Please explain what happens below.\n\na = 1\nb = 1.0\nprint(type(a))\nprint(type(b))\n\nprint(a == b)\nprint(a is b)\n\n<class 'int'>\n<class 'float'>\nTrue\nFalse\n\n\n\n\nExercise 2.4 (Play with strings) Please excute the code below line by line and explain what happens in text cells.\n\n# 1\nanswer = 10\nwronganswer = 11\ntext1 = \"The answer to this question is {}. If you got {}, you are wrong.\".format(answer, wronganswer)\nprint(text1)\n\n# 2\nvar = True\ntext2 = \"This is {}.\".format(var)\nprint(text2)\n\n# 3\nword1 = 'Good '\nword2 = 'buy. '\ntext3 = (word1 + word2) * 3\nprint(text3)\n\n# 4\nsentence = \"This is\\ngood enough\\nfor a exercise to\\nhave so many parts. \" \\\n           \"We would also want to try this symbol: '. \" \\\n           \"Do you know how to type \\\" in double quotes?\"\nprint(sentence)\n\nThe answer to this question is 10. If you got 11, you are wrong.\nThis is True.\nGood buy. Good buy. Good buy. \nThis is\ngood enough\nfor a exercise to\nhave so many parts. We would also want to try this symbol: '. Do you know how to type \" in double quotes?\n\n\n\n\nExercise 2.5 (split and join) Please excute the code below line by line and explain what happens in text cells.\n\nsentence = 'This is an example of a sentence that I expect you to split.'\n\nwordlist = sentence.split(' ')\n\nnewsentence = '\\n'.join(wordlist)\nprint(newsentence)\n\n\n\nExercise 2.6 (List reference) Please finish the following tasks.\n\nGiven the list a, make a new reference b to a. Update the first entry in b to be 0. What happened to the first entry in a? Explain your answer in a text block.\nGiven the list a, make a new copy b of the list a using the function list. Update the first entry in b to be 0. What happened to the first entry in a? Explain your answer in a text block.\n\n\n\nExercise 2.7 (List comprehension) Given a list of numbers, use list comprehension to remove all odd numbers from the list:\n\nnumbers = [3,5,45,97,32,22,10,19,39,43]\n\n\n\nExercise 2.8 (More list comprehension) Use list comprehension to find all of the numbers from 1-1000 that are divisible by 7.\n\n\nExercise 2.9 (More list comprehension) Count the number of spaces in a string.\n\n\nExercise 2.10 (More list comprehension) Use list comprehension to get the index and the value as a tuple for items in the list ['hi', 4, 8.99, 'apple', ('t,b', 'n')]. Result would look like [(index, value), (index, value), ...].\n\n\nExercise 2.11 (More list comprehension) Use list comprehension to find the common numbers in two lists (without using a tuple or set) list_a = [1, 2, 3, 4], list_b = [2, 3, 4, 5].\n\n\nExercise 2.12 (Probability) Compute the probability that two people out of 23 share the same birthday. The math formula for this is \\[1-\\frac{365!/(365-23)!}{365^{23}}=1-\\frac{365}{365}\\cdot\\frac{365-1}{365}\\cdot\\frac{365-2}{365}\\cdot\\ldots\\cdot\\frac{365-22}{365}.\\]\n\nTo directly use the formula we have to use a high performance math package, e.g. math. Please use math.factorial to compute the above formula.\nPlease use the right hand side of the above formula to compute the probability using the following steps.\n\nPlease use the list comprehension to create a list \\(\\left[\\frac{365}{365},\\frac{365-1}{365},\\frac{365-2}{365},\\ldots,\\frac{365-22}{365}\\right]\\).\nUse numpy.prod to compute the product of elements of the above list.\nCompute the probability by finishing the formula.\n\nPlease use time to test which method mentioned above is faster."
  },
  {
    "objectID": "contents/2/02-.html#projects",
    "href": "contents/2/02-.html#projects",
    "title": "2  Python Basics",
    "section": "2.7 Projects",
    "text": "2.7 Projects\nMost projects are based on [2], [5].\n\nExercise 2.13 (Determine the indefinite article) Please finish the following tasks.\n\nPlease construct a list aeiou that contains all vowels.\nGiven a word word, we would like to find the indefinite article article before word. (Hint: the article should be an if the first character of word is a vowel, and a if not.)\n\n\n\n\nClick for Hint.\n\n\nSolution. Consider in, .lower() and if structure.\n\n\n\nExercise 2.14 (Datetime and files names) We would like to write a program to quickly generate N files. Every time we run the code, N files will be generated. We hope to store all files generated and organize them in a neat way. To achieve this, one way is to create a subfolder for each run and store all files generated during that run in the particular subfolder. Since we would like to make it fast, the real point of this task is to find a way to automatically generate the file names for the files generated and the folder names for the subfolders generated. You don’t need to worry about the contents of the files and empty files are totally fine for this problem.\n\n\n\nClick for Hint.\n\n\nSolution. One way to automatically generate file names and folder names is to use the date and the time when the code is run. Please check datetime package for getting and formatting date/time, and os packages for playing with files and folders.\n\n\n\nExercise 2.15 (Color the Gnomic data) We can use ASCII color codes in the string to change the color of strings, as an example \\033[91m for red and \\033[94m for blue. See the following example.\n\nprint('\\033[91m'+'red'+'\\033[92m'+'green'+'\\033[94m'+'blue'+'\\033[93m'+'yellow')\n\nConsider an (incomplete) Gnomic data given below which is represented by a long sequence of A, C, T and G. Please color it using ASCII color codes.\n\nGnomicdata = 'TCGATCTCTTGTAGATCTGTTCTCTAAACGAACTTTAAAATCTGTGTGGCTGTCACTCGG'\\\n             'CTGCATGCTTAGTGCACTCACGCAGTATAATTAATAACTAATTACTGTCGTTGACAGGAC'\\\n             'ACGAGTAACTCGTCTATCTTCTGCAGGCTGCTTACGGTTTCGTCCGTGTTGCAGCCGATC'\\\n             'ATCAGCACATCTAGGTTTTGTCCGGGTGTGACCGAAAGGTAAGATGGAGAGCCTTGTCCC'\\\n             'TGGTTTCAACGAGAAAACACACGTCCAACTCAGTTTGCCTGTTTTACAGGTTCGCGACGT'\\\n             'GCTCGTACGTGGCTTTGGAGACTCCGTGGAGGAGGTCTTATCAGAGGCACGTCAACATCT'\\\n             'TAAAGATGGCACTTGTGGCTTAGTAGAAGTTGAAAAAGGCGTTTTGCCTCAACTTGAACA'\\\n             'GCCCTATGTGTTCATCAAACGTTCGGATGCTCGAACTGCACCTCATGGTCATGTTATGGT'\\\n             'TGAGCTGGTAGCAGAACTCGAAGGCATTCAGTACGGTCGTAGTGGTGAGACACTTGGTGT'\\\n             'CCTTGTCCCTCATGTGGGCGAAATACCAGTGGCTTACCGCAAGGTTCTTCTTCGTAAGAA'\\\n             'CGGTAATAAAGGAGCTGGTGGCCATAGTTACGGCGCCGATCTAAAGTCATTTGACTTAGG'\\\n             'CGACGAGCTTGGCACTGATCCTTATGAAGATTTTCAAGAAAACTGGAACACTAAACATAG'\n\n\n\n\nClick for Hint.\n\n\nSolution (Hint). You may use if to do the conversion. Or you may use dict to do the conversion.\n\n\n\nExercise 2.16 (sorted) Please read through the Key funtions in this article, and sort the following two lists.\n\nSort list1 = [[11,2,3], [2, 3, 1], [5,-1, 2], [2, 3,-8]] according to the sum of each list.\nSort list2 = [{'a': 1, 'b': 2}, {'a': 3, 'b': 4},{'a': 5, 'b': 2}] according to the b value of each dictionary.\n\n\n\nExercise 2.17 (Fantasy Game Inventory) You are creating a fantasy video game. The data structure to model the player’s inventory will be a dictionary where the keys are string values describing the item in the inventory and the value is an integer value detailing how many of that item the player has. For example, the dictionary value {'rope': 1, 'torch': 6, 'gold coin': 42, 'dagger': 1, 'arrow': 12} means the player has 1 rope, 6 torches, 42 gold coins, and so on.\nWrite a program to take any possible inventory and display it like the following:\n\nInventory:\n12 arrow\n42 gold coin\n1 rope\n6 torch\n1 dagger\nTotal number of items: 62\n\n\n\n\n\n\n[1] Youens-Clark, K. (2020). Tiny python projects. Manning Publications.\n\n\n[2] McKinney, W. (2017). Python for data analysis: Data wrangling with pandas, NumPy, and IPython. O’Reilly Media.\n\n\n[3] Shaw, Z. A. (2017). Learn python 3 the hard way. Addison Wesley.\n\n\n[4] Sweigart, A. (2020). Automate the boring stuff with python, 2nd edition practical programming for total beginners: Practical programming for total beginners. No Starch Press.\n\n\n[5] Klosterman, S. (2021). Data science projects with python: A case study approach to gaining valuable insights from real data with machine learning. Packt Publishing, Limited."
  },
  {
    "objectID": "contents/3/03-.html",
    "href": "contents/3/03-.html",
    "title": "3  Package: numpy",
    "section": "",
    "text": "The main reference for this chapter is [1]."
  },
  {
    "objectID": "contents/3/03-.html#basics",
    "href": "contents/3/03-.html#basics",
    "title": "3  Package: numpy",
    "section": "3.1 Basics",
    "text": "3.1 Basics\nThe basic data structure for numpy is numpy.ndarray. You may treat it as a generalized version of lists. However it can do so much more than the build-in list.\nTo use numpy, we just import it. In most cases you would like to use the alias np.\n\nimport numpy as np\n\n\n\n\n\n\n\nNote\n\n\n\nIn many cases, numpy.ndarray is a huge object since it stores tons of data. Therefore many of the operations related to numpy.ndarray are “in-place” by default. This means that if you don’t explicitly ask for a copy, there will be only one copy of the array and all later operations make changes to the original one.\nHowever there are many cases that"
  },
  {
    "objectID": "contents/3/03-.html#create-np.ndarray",
    "href": "contents/3/03-.html#create-np.ndarray",
    "title": "3  Package: numpy",
    "section": "3.2 Create np.ndarray",
    "text": "3.2 Create np.ndarray\n\nconvert a list into a numpy array.\nnp.zeros, np.zeros_like\nnp.ones, np.ones_like\nnp.eye\nnp.random.rand\nnp.arange\nnp.linspace\n\n\n\n\n\n\n\nNote\n\n\n\nPlease be very careful about the format of the input. For example, when you want to specify the dimension of the array, using np.zeros, you need to input a tuple. On the other hand, when using np.random.rand, you just directly input the dimensions one by one.\n\nimport numpy as np\n\nnp.zeros((3, 2))\nnp.random.rand(3, 2)\n\nIn this case, the official documents are always your friend."
  },
  {
    "objectID": "contents/3/03-.html#mathematical-and-statistical-methods",
    "href": "contents/3/03-.html#mathematical-and-statistical-methods",
    "title": "3  Package: numpy",
    "section": "3.3 Mathematical and Statistical Methods",
    "text": "3.3 Mathematical and Statistical Methods\n\n+, -, *, /, **, etc..\nnp.sin, np.exp, np.sqrt, etc..\nmean, sum, std, var, cumsum\nmax and min\nmaximum and minimum\nargmin and argmax\nnp.sort\nnp.unique, np.any\nnp.dot: Matrix multiplication\nnp.concatenate\nBroadcast\n\n\nExample 3.1 (Axis) Given A = np.array([[1,2],[3,4]]) and B = np.array([[5,6],[7,8]]), please use np.concatenate to concatencate these two matrices to get a new matrix, in the order:\n\nA left, B right\nA right, B left\nA up, B down\nA down, B up"
  },
  {
    "objectID": "contents/3/03-.html#common-attributes-and-methods",
    "href": "contents/3/03-.html#common-attributes-and-methods",
    "title": "3  Package: numpy",
    "section": "3.4 Common attributes and methods",
    "text": "3.4 Common attributes and methods\n\nshape\ndtype\nndim\nAny arithmetic operations between equal-size arrays applies the operation element-wise.\n\n\nExample 3.2 MNIST is a very famous dataset of hand written images. Here is how to load it. Note that in this instance of the dataset the data are stored as numpy arraies.\n\nimport tensorflow as tf\n\n(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\nX_train.shape"
  },
  {
    "objectID": "contents/3/03-.html#basic-indexing-and-slicing",
    "href": "contents/3/03-.html#basic-indexing-and-slicing",
    "title": "3  Package: numpy",
    "section": "3.5 Basic indexing and slicing",
    "text": "3.5 Basic indexing and slicing\nFirst see the following example.\n\n\nExample 3.3 \nimport numpy as np\narr = np.arange(10)\n\nprint(arr[5])\nprint(arr[5:8])\n\narr[5:8] = 12\nprint(arr)\n\nprint(arr[5:8:2])\nprint(arr[8:5:-1])\nprint(arr[::-1])\n\n5\n[5 6 7]\n[ 0  1  2  3  4 12 12 12  8  9]\n[12 12]\n[ 8 12 12]\n[ 9  8 12 12 12  4  3  2  1  0]\n\n\n\nTo do slicing in higher dimensional case, you may either treat a numpy array as a nested list, or you may directly work with it with multiindexes.\n\n\nExample 3.4 \nimport numpy as np\narr3d = np.arange(12).reshape(2, 2, 3)\n\nprint('case 1:\\n {}'.format(arr3d))\nprint('case 2:\\n {}'.format(arr3d[0, 1, 2]))\nprint('case 3:\\n {}'.format(arr3d[:, 0: 2, 1]))\nprint('case 4:\\n {}'.format(arr3d[:, 0: 2, 1:2]))\n\ncase 1:\n [[[ 0  1  2]\n  [ 3  4  5]]\n\n [[ 6  7  8]\n  [ 9 10 11]]]\ncase 2:\n 5\ncase 3:\n [[ 1  4]\n [ 7 10]]\ncase 4:\n [[[ 1]\n  [ 4]]\n\n [[ 7]\n  [10]]]"
  },
  {
    "objectID": "contents/3/03-.html#boolean-indexing",
    "href": "contents/3/03-.html#boolean-indexing",
    "title": "3  Package: numpy",
    "section": "3.6 Boolean Indexing",
    "text": "3.6 Boolean Indexing\nnumpy array can accept index in terms of numpy arries with boolean indexing.\n\n\nExample 3.5 \nimport numpy as np\na = np.arange(4)\nb = np.array([True, True, False, True])\nprint(a)\nprint(b)\nprint(a[b])\n\n[0 1 2 3]\n[ True  True False  True]\n[0 1 3]\n\n\n\nWe could combine this way with the logic computation to filter out the elements we don’t want.\n\nExample 3.6 Please replace the odd number in the array by its negative.\n\nimport numpy as np\narr = np.arange(10)\nodd = arr %2 == 1\narr[odd] = arr[odd] * (-1)\n\nprint(arr)\n\n[ 0 -1  2 -3  4 -5  6 -7  8 -9]"
  },
  {
    "objectID": "contents/3/03-.html#fancy-indexing",
    "href": "contents/3/03-.html#fancy-indexing",
    "title": "3  Package: numpy",
    "section": "3.7 Fancy indexing",
    "text": "3.7 Fancy indexing\nFancy indexing is a term adopted by NumPy to describe indexing using integer arrays.\n\n\nExample 3.7 \nimport numpy as np\n\narr = np.zeros((8, 4))\nfor i in range(8):\n    arr[i] = i\n\narr[[4, 3, 0, 6]]\n\narray([[4., 4., 4., 4.],\n       [3., 3., 3., 3.],\n       [0., 0., 0., 0.],\n       [6., 6., 6., 6.]])\n\n\n\n\n\nExample 3.8 \nimport numpy as np\n\narr = np.arange(32).reshape((8, 4))\nprint(arr)\nprint(arr[[1, 5, 7, 2], [0, 3, 1, 2]])\nprint(arr[[1, 5, 7, 2]][:, [0, 3, 1, 2]])\n\n[[ 0  1  2  3]\n [ 4  5  6  7]\n [ 8  9 10 11]\n [12 13 14 15]\n [16 17 18 19]\n [20 21 22 23]\n [24 25 26 27]\n [28 29 30 31]]\n[ 4 23 29 10]\n[[ 4  7  5  6]\n [20 23 21 22]\n [28 31 29 30]\n [ 8 11  9 10]]"
  },
  {
    "objectID": "contents/3/03-.html#copies-and-views",
    "href": "contents/3/03-.html#copies-and-views",
    "title": "3  Package: numpy",
    "section": "3.8 Copies and views",
    "text": "3.8 Copies and views\nThe view of an numpy array is a way to get access to the array without copying internel data. When operating with a view, the original data as well as all other views of the original data will be modified simutanously.\nThe default setting for copies and views is that, basic indexing and slicing will make views, and advanced indexing and slicing (e.g. boolean indexing, fancy indexing, etc.) will make copies. For other operations, you need to check the documents to know how they work. For example, np.reshape creates a view where possible, and np.flatten always creates a copy.\nYou may use np.view() or np.copy() to make views or copies explicitly. ::: {#exm-}\n\nimport numpy as np\narr = np.arange(10)\nb = arr[5:8]\nprint('arr is {}'.format(arr))\nprint('b is {}'.format(b))\n\nb[0] = -1\nprint('arr is {}'.format(arr))\nprint('b is {}'.format(b))\n\n\narr[6] = -2\nprint('arr is {}'.format(arr))\nprint('b is {}'.format(b))\n\nprint('The base of b is {}'.format(b.base))\n\narr is [0 1 2 3 4 5 6 7 8 9]\nb is [5 6 7]\narr is [ 0  1  2  3  4 -1  6  7  8  9]\nb is [-1  6  7]\narr is [ 0  1  2  3  4 -1 -2  7  8  9]\nb is [-1 -2  7]\nThe base of b is [ 0  1  2  3  4 -1 -2  7  8  9]\n\n\n:::\nThe way to make explicit copy is .copy().\n\n\nExample 3.9 \nimport numpy as np\narr = np.arange(10)\nb = arr[5:8].copy()\nprint('arr is {}'.format(arr))\nprint('b is {}'.format(b))\n\nb[0] = -1\nprint('arr is {}'.format(arr))\nprint('b is {}'.format(b))\n\n\narr[6] = -2\nprint('arr is {}'.format(arr))\nprint('b is {}'.format(b))\n\nprint('The base of b is {}'.format(b.base))\n\narr is [0 1 2 3 4 5 6 7 8 9]\nb is [5 6 7]\narr is [0 1 2 3 4 5 6 7 8 9]\nb is [-1  6  7]\narr is [ 0  1  2  3  4  5 -2  7  8  9]\nb is [-1  6  7]\nThe base of b is None"
  },
  {
    "objectID": "contents/3/03-.html#more-commands",
    "href": "contents/3/03-.html#more-commands",
    "title": "3  Package: numpy",
    "section": "3.9 More commands",
    "text": "3.9 More commands\n\n.T\naxis=n is very important.\nnp.reshape()\nnp.tile()\nnp.repeat()"
  },
  {
    "objectID": "contents/3/03-.html#more-advanced-commands",
    "href": "contents/3/03-.html#more-advanced-commands",
    "title": "3  Package: numpy",
    "section": "3.10 More advanced commands",
    "text": "3.10 More advanced commands\n\nnp.where()\nnp.any()\nnp.all()\nnp.argsort()\n\n\nExample 3.10 Get the position where elements of a and b match.\n\na = np.array([1,2,3,2,3,4,3,4,5,6])\nb = np.array([7,2,10,2,7,4,9,4,9,8])\n\nnp.where(a == b)\n\n(array([1, 3, 5, 7], dtype=int64),)\n\n\n\n\n\nExample 3.11 \na = np.array([1,2,3,2,3,4,3,4,5,6])\nb = np.array([7,2,10,2,7,4,9,4,9,8])\n\nnp.where(a == b, a*2, b+1)\n\narray([ 8,  4, 11,  4,  8,  8, 10,  8, 10,  9])\n\n\n\n\n\nExample 3.12 (Playing with axis) \nimport numpy as np\na = np.array([[[1,2],[3,4]],[[5,6],[7,8]]])\n\nnp.any(a==1, axis=0)\nnp.any(a==1, axis=1)\nnp.any(a==1, axis=2)\n\n\nnp.any(a==2, axis=0)\nnp.any(a==2, axis=1)\nnp.any(a==2, axis=2)\n\nnp.any(a==5, axis=0)\nnp.any(a==5, axis=1)\nnp.any(a==5, axis=2)\n\narray([[False, False],\n       [ True, False]])"
  },
  {
    "objectID": "contents/3/03-.html#examples",
    "href": "contents/3/03-.html#examples",
    "title": "3  Package: numpy",
    "section": "3.11 Examples",
    "text": "3.11 Examples\n\nExample 3.13 (Random walks) Adam walks randomly along the axis. He starts from 0. Every step he has equal possibility to go left or right. Please simulate this process.\nUse choices to record the choice of Adam at each step. We may generate a random array where 0 represents left and 1 represents right.\nUse positions to record the position of Adam at each step. Using choices, the position is +1 if we see a 1 and the position is -1 if we see a 0. So the most elegent way to perform this is to\n\nConvert choices from {0, 1} to {-1, 1}.\nTo record the starting position, we attach 0 to the beginning of the new choices.\nApply cumsum to choices to get positions.\n\n\nimport numpy as np\n\nstep = 30\nchoices = np.random.randint(2, size=step)\nchoices = choices * 2 - 1\nchoices = np.concatenate(([0], choices))\npositions = choices.cumsum()\n\nimport matplotlib.pyplot as plt\nplt.plot(positions)\n\n\n\n\n\n\nExample 3.14 (Many random walks) We mainly use numpy.ndarray to write the code in the previous example. The best part here is that it can be easily generalized to many random walks.\nStill keep choices and positions in mind. Now we would like to deal with multiple people simutanously. Each row represents one person’s random walk. All the formulas stay the same. We only need to update the dimension setting in the previous code.\n\nUpdate size in np.random.randint.\nUpdate [0] to np.zeros((N, 1)) in concatenate.\nFor cumsum and concatenate, add axis=1 to indicate that we perform the operations along axis 1.\nWe plot each row in the same figure. plt.legend is used to show the label for each line.\n\n\nimport numpy as np\n\nstep = 30\nN = 3\nchoices = np.random.randint(2, size=(N, step))\nchoices = choices * 2 - 1\nchoices = np.concatenate((np.zeros((N, 1)), choices), axis=1)\npositions = choices.cumsum(axis=1)\n\nimport matplotlib.pyplot as plt\nfor row in positions:\n    plt.plot(row)\nplt.legend([1, 2, 3])\n\n<matplotlib.legend.Legend at 0x20c90adb550>\n\n\n\n\n\n\n\nExample 3.15 (Analyze positions) We play with the numpy array positions to get some information about the random walks of three generated in the previous example.\n\nThe maximal position:\n\n\npositions.max()\n\n4.0\n\n\n\nThe maximal position for each one:\n\n\npositions.max(axis=1)\n\narray([3., 4., 0.])\n\n\n\nThe maximal position across all three for each step:\n\n\npositions.max(axis=0)\n\narray([ 0.,  1.,  2.,  3.,  4.,  3.,  2.,  3.,  2.,  1.,  2.,  1.,  2.,\n        1.,  2.,  1.,  0., -1.,  0.,  1.,  2.,  1.,  2.,  1.,  0., -1.,\n        0., -1.,  0.,  1.,  0.])\n\n\n\nCheck whether anyone once got to the position 3:\n\n\n(positions>=3).any(axis=1)\n\narray([ True,  True, False])\n\n\n\nThe number of people who once got to the position 3:\n\n\n(positions>=3).any(axis=1).sum()\n\n2\n\n\n\nWhich step for each one gets to the right most position:\n\n\npositions.argmax(axis=1)\n\narray([5, 4, 0], dtype=int64)"
  },
  {
    "objectID": "contents/3/03-.html#exercises",
    "href": "contents/3/03-.html#exercises",
    "title": "3  Package: numpy",
    "section": "3.12 Exercises",
    "text": "3.12 Exercises\nMany exercises are from [2].\n\nExercise 3.1 (array) Write a NumPy program to create a \\(3\\times3\\) matrix with values ranging from 2 to 10.\n\n\nExercise 3.2 (array) Write a NumPy program to create a null vector of size 10 and update sixth value to 11.\n\n\nExercise 3.3 (array) Write a NumPy program to reverse an array (first element becomes last).\n\n\nExercise 3.4 (array) Write a NumPy program to create a \\(10\\times10\\) 2D-array with 1 on the border and 0 inside.\n\n\nExercise 3.5 (repeat and tile) Given a = np.array([1,2,3]), please get the desired output array([1, 1, 1, 2, 2, 2, 3, 3, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3]).\n\n\nExercise 3.6 (Compare two numpy arraies) Consider two numpy arraies x and y. Compare them entry by entry. We would like to know how many are the same.\n\n\n\nClick to expand.\n\n\nSolution. Note that bool values True and False can be treated as numbers 1 and 0.\n\nimport numpy as np\n\nx = np.array([1, 2, 3, 4, 5])\ny = np.array([2, 1, 4, 4, 5])\n\nnumofsame = np.sum(x == y)\nprint(numofsame)\n\n2\n\n\n\n\n\nExercise 3.7 Get all items between 5 and 10 from an array a = np.array([2, 6, 1, 9, 10, 3, 27]).\n\n\nExercise 3.8 Swap rows 1 and 2 in the array arr = np.arange(9).reshape(3,3).\n\n\nExercise 3.9 Please finish the following tasks.\n\nReverse the rows of a 2D array arr = np.arange(9).reshape(3,3).\nReverse the columns of a 2D array arr = np.arange(9).reshape(3,3).\n\n\n\nExercise 3.10 Create a 2D array of shape 5x3 to contain random decimal numbers between 5 and 10.\n\n\nExercise 3.11 Use the following code to get the dataset iris.\n\nimport numpy as np\n\nurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\niris_1d = np.genfromtxt(url, delimiter=',', dtype=None, encoding=None)\n\n\niris_1d is a 1D numpy array that each item is a tuple. Please construct a new 1D numpy array that each item is the last componenet of each tuple in iris_1d.\nConvert iris_1d into a 2D array iris_2d by omitting the last field of each item.\n\n\n\nExercise 3.12 (Normalization) Use the following code to get an 1D array sepallength.\n\nimport numpy as np\n\nurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\nsepallength = np.genfromtxt(url, delimiter=',', dtype='float', usecols=[0],\n                            encoding=None)\n\nPlease normalize it such that the values of each item is between 0 and 1.\n\n\nExercise 3.13 np.isnan() is a function to check whether each entry of a numpy array is nan or not. Please use this as well as np.where to find all nan entries in an array.\nYou may use the following array iris_2d to test your code.\n\nimport numpy as np\nurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\niris_2d = np.genfromtxt(url, delimiter=',', dtype='float', encoding=None)\niris_2d[np.random.randint(150, size=20), np.random.randint(4, size=20)] = np.nan\n\n\n\nExercise 3.14 Select the rows of iris_2d that does not have any nan value.\n\nimport numpy as np\nurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\niris_2d = np.genfromtxt(url, delimiter=',', dtype='float', usecols=[0,1,2,3],\n                        encoding=None)\niris_2d[np.random.randint(150, size=20), np.random.randint(4, size=20)] = np.nan\n\n\n\nExercise 3.15 Replace all nan with 0 in numpy array iris_2d.\n\nimport numpy as np\nurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\niris_2d = np.genfromtxt(url, delimiter=',', dtype='float', usecols=[0,1,2,3],\n                        encoding=None)\niris_2d[np.random.randint(150, size=20), np.random.randint(4, size=20)] = np.nan\n\n\n\nExercise 3.16 Consider x = np.array([1, 2, 1, 1, 3, 4, 3, 1, 1, 2, 1, 1, 2]). Please find the index of 5th repetition of number 1 in x."
  },
  {
    "objectID": "contents/3/03-.html#projects",
    "href": "contents/3/03-.html#projects",
    "title": "3  Package: numpy",
    "section": "3.13 Projects",
    "text": "3.13 Projects\n\nExercise 3.17 (Adding one axis) Please download this file.\n\nPlease use matplotlib.pyplot.imread() to read the file as a 3D numpy array.\nCheck the shape of the array.\nAdd one additional axis to it as axis 0 to make it into a 4D array.\n\n\n\nExercise 3.18 (Random) Please finish the following tasks.\n\nUse the package np.random to flip a coin 100 times and record the result in a list coin.\nAssume that the coin is not fair, and the probability to get H is p. Write a code to flip the coin 100 times and record the result in a list coin, with a given parameter p. You may use p=.4 as the first choice.\nFor each list coin created above, write a code to find the longest H streak. We only need the biggest number of consecutive H we get during this 100 tosses. It is NOT necessary to know when we start the streak.\n\n\n\n\nClick for Hint.\n\n\nSolution. The following ideas can be used to solve the problem.\n\nnp.where\nstring, split and join\n\n\n\n\nExercise 3.19 (Bins) Please read the document of np.digitize, and use it to do the following task.\nSet the following bins:\n\nLess than 3: small\n3-5: medium\nBigger than 5: large\n\nPlease transform the following data iris_2c into texts using the given bins.\n\nimport numpy as np\nurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\niris_2c = np.genfromtxt(url, delimiter=',', dtype='object')[:, 2].astype('float')\n\n\n\nExercise 3.20 Consider a 2D numpy array a.\n\nimport numpy as np\na = np.random.rand(5, 5)\n\n\nPlease sort it along the 3rd column.\nPlease sort it along the 2nd row.\n\n\n\n\nClick for Hint.\n\n\nSolution. Please use np.argsort for the problem.\n\n\n\nExercise 3.21 (One-hot vector) Compute the one-hot encodings of a given array. You may use the following array as a test example. In this example, there are 3 labels. So the one-hot vectors are 3 dimensional vectors.\nFor more infomation about one-hot encodings, you may check the Wiki page. You are not allowed to use packages that can directly compute the one-hot encodings for this problem.\n\nimport numpy as np\narr = np.random.randint(1,4, size=6)\n\n\n\nExercise 3.22 From the given 1d array arr = np.arange(15), generate a 2d matrix using strides, with a window length of 4 and strides of 2, like [[0,1,2,3], [2,3,4,5], [4,5,6,7]..].\n\n\n\n\n\n[1] McKinney, W. (2017). Python for data analysis: Data wrangling with pandas, NumPy, and IPython. O’Reilly Media.\n\n\n[2] Prabhakaran, S. (2018). 101 NumPy exercises for data analysis (python)."
  },
  {
    "objectID": "contents/4/04-.html",
    "href": "contents/4/04-.html",
    "title": "4  Package: pandas",
    "section": "",
    "text": "The basic data structure for pandas is pandas.DataFrame. You may treat it as a generalized version of tables.\nTo use pandas, we just import it. In most cases you would like to use the alias pd.\nSince DataFrame is more like a table, the biggest questions here is not to do computations (which is still very important), but to retrieve, search, sort, merge, etc.. those data."
  },
  {
    "objectID": "contents/4/04-.html#basic-pandas",
    "href": "contents/4/04-.html#basic-pandas",
    "title": "4  Package: pandas",
    "section": "4.1 Basic pandas",
    "text": "4.1 Basic pandas\n\n4.1.1 Series and DataFrame\nA Series is a 1-d array-like object which has index. The default index is starting from 0. You may change the index to be something assigned by you. Thus it can be treated as a generalization of a dict.\n\nobj = pd.Series([3, 1, 2, 4])\nprint(obj)\n\n0    3\n1    1\n2    2\n3    4\ndtype: int64\n\n\n\nobj2 = pd.Series([3, 1, 2, 4], index=['a', 'b', 'c', 'd'])\nprint(obj2)\n\na    3\nb    1\nc    2\nd    4\ndtype: int64\n\n\n\ndata3 = {'a': 3, 'b': 1, 'c': 2, 'd': 4}\nobj3 = pd.Series(data3)\nprint(obj3)\n\na    3\nb    1\nc    2\nd    4\ndtype: int64\n\n\nA DataFrame represents a rectangular table of data and contains an ordered collection of columns, each of which can be a different value type. The DataFrame has both a row and column index; it can be thought of as a dict of Series all sharing the same index. When displaying a DataFrame, we may use .head() to just display the first few rows for efficicy.\n\nimport pandas as pd\n\ndata = {'a': [1, 2, 3, 4, 5, 6, 7],\n        'b': [1.1, 2.1, 3.1, 4.1, 5.1, 6.1, 7.1],\n        'c': ['a', 'b', 'c', 'd', 'e', 'f', 'g']}\ndf = pd.DataFrame(data)\ndf.head()\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      1.1\n      a\n    \n    \n      1\n      2\n      2.1\n      b\n    \n    \n      2\n      3\n      3.1\n      c\n    \n    \n      3\n      4\n      4.1\n      d\n    \n    \n      4\n      5\n      5.1\n      e\n    \n  \n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe may use the setting columns= or index= as well as the methods .rename(columns=, index=) to change the column names and the index names. See the following example.\n\nimport numpy as np\nimport pandas as pd\ndata = pd.DataFrame(np.arange(16).reshape((4, 4)),\n                    index=['Ohio', 'Colorado', 'Utah', 'New York'],\n                    columns=['one', 'two', 'three', 'four'])\n\n\n\n\n\n4.1.2 Accessing data\n\nA column in a DataFrame can be retrieved as a Series either by dict-like notation or by attribute. What one gets from this is a Series object.\n\ndict-like notation: df['a']\nby attribute: df.a. Note that if the name of the column is not suitable for attribute names, this method doesn’t work.\n\nRows are retrieved by .loc if using the row index, and by .iloc if using the row number.\n\n\n\n4.1.3 Updating data\n\nAssign values to a column of a DataFrame will update that column. If the column doesn’t exist, new column will be created.\nWhen assign values with non-existent row index, that part of the data will be discarded.\nAny time if there are no values with a specific column and row, it will show as NaN.\n\n\n\nExample 4.1 \nimport pandas as pd\n\ndata = {'a': [1, 2, 3, 4],\n        'b': [1.1, 2.1, 3.1, 4.1],\n        'c': ['a', 'b', 'c', 'd']}\ndf = pd.DataFrame(data)\n\nnewcol = {1: 'good', 3: 'better', 5: 'best'}\ndf['d'] = pd.Series(newcol)\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      1.1\n      a\n      NaN\n    \n    \n      1\n      2\n      2.1\n      b\n      good\n    \n    \n      2\n      3\n      3.1\n      c\n      NaN\n    \n    \n      3\n      4\n      4.1\n      d\n      better\n    \n  \n\n\n\n\n\n\n\n4.1.4 Indexing, Selection, and Filtering\n\nSeries indexing (obj[...]) works analogously to NumPy array indexing, except you can use the Series’s index values instead of only integers.\nWe can use logical expresssion to filter DataFrame.\n\n\nimport pandas as pd\n\ndata = pd.DataFrame(np.arange(16).reshape((4, 4)),\n                    index=['Ohio', 'Colorado', 'Utah', 'New York'],\n                    columns=['one', 'two', 'three', 'four'])\ndata[data['one']>5]\n\n\n\n\n\n  \n    \n      \n      one\n      two\n      three\n      four\n    \n  \n  \n    \n      Utah\n      8\n      9\n      10\n      11\n    \n    \n      New York\n      12\n      13\n      14\n      15\n    \n  \n\n\n\n\n\n.loc, .iloc\n\n\nimport pandas as pd\ndata = pd.DataFrame(np.arange(16).reshape((4, 4)),\n                    index=['Ohio', 'Colorado', 'Utah', 'New York'],\n                    columns=['one', 'two', 'three', 'four'])\nprint(data.loc['Colorado', ['two', 'three']])\nprint(data.iloc[2, [3, 0, 1]])\n\ntwo      5\nthree    6\nName: Colorado, dtype: int32\nfour    11\none      8\ntwo      9\nName: Utah, dtype: int32\n\n\n\nSlicing with labels behaves differently than normal Python slicing in that the endpoint is inclusive.\n\n\nimport pandas as pd\n\nobj = pd.Series(np.arange(4.), index=['a', 'b', 'c', 'd'])\nobj['b':'c']\n\nb    1.0\nc    2.0\ndtype: float64\n\n\n\nReindex .reindex():\n\n\nimport pandas as pd\ndata = pd.DataFrame(np.arange(16).reshape((4, 4)),\n                    index=['Ohio', 'Colorado', 'Utah', 'New York'],\n                    columns=['one', 'two', 'three', 'four'])\n\ndata.reindex(index = ['Colorado', 'Arkansas', 'New York'],\n             columns = ['three', 'five', 'one'])\n\n\n\n\n\n  \n    \n      \n      three\n      five\n      one\n    \n  \n  \n    \n      Colorado\n      6.0\n      NaN\n      4.0\n    \n    \n      Arkansas\n      NaN\n      NaN\n      NaN\n    \n    \n      New York\n      14.0\n      NaN\n      12.0\n    \n  \n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n.loc and .reindex are very similar to each other. The main difference between theses two is that .loc will return a view and .reindex will return a copy in most cases.\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhen locate data using indexes, duplicate labels will return all results.\n\n\n\n\n4.1.5 Essential functions\n\nArithmetic and Data Alignment Elements of the same index and columns will be computed. By default, if any entry is nan, the answer will be nan. You may use fill_value argument to fill the empty slots.\n\n\n\nExample 4.2 \nimport pandas as pd\nimport numpy as np\ndf1 = pd.DataFrame(np.arange(12.).reshape((3, 4)), columns=list('abcd'))\ndf2 = pd.DataFrame(np.arange(20.).reshape((4, 5)), columns=list('abcde'))\ndf2.loc[1, 'b'] = np.nan\n\ndf1.add(df2, fill_value=0)\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n      e\n    \n  \n  \n    \n      0\n      0.0\n      2.0\n      4.0\n      6.0\n      4.0\n    \n    \n      1\n      9.0\n      5.0\n      13.0\n      15.0\n      9.0\n    \n    \n      2\n      18.0\n      20.0\n      22.0\n      24.0\n      14.0\n    \n    \n      3\n      15.0\n      16.0\n      17.0\n      18.0\n      19.0\n    \n  \n\n\n\n\n\nRelatedly, when reindexing a Series or DataFrame, you can also specify a fill_value.\n\n\n4.1.6 Function Application and Mapping\nWe may apply functions to each row/column of a DataFrame. If the function is built-in function that is compatible with DataFrame, you can directly call the function that it will be applied automatically to each row/column. If it is not, we can call apply to get the desired result.\n\n\nExample 4.3 \nimport pandas as pd\ndata = pd.DataFrame(np.random.rand(4, 4),\n                    index=['Ohio', 'Colorado', 'Utah', 'New York'],\n                    columns=['one', 'two', 'three', 'four'])\n\nf = lambda x: x.max() - x.min()\n\nprint(data.apply(f))\nprint(data.apply(f, axis='columns'))\n\none      0.455652\ntwo      0.554529\nthree    0.510554\nfour     0.545947\ndtype: float64\nOhio        0.685735\nColorado    0.538505\nUtah        0.336410\nNew York    0.696605\ndtype: float64\n\n\n\nWe can use more complicated function to get more complicated result.\n\n\nExample 4.4 \nimport pandas as pd\ndata = pd.DataFrame(np.random.rand(4, 4),\n                    index=['Ohio', 'Colorado', 'Utah', 'New York'],\n                    columns=['one', 'two', 'three', 'four'])\n\nf = lambda x: pd.Series([x.max(), x.min()], index=['max', 'min'])\n\nprint(data.apply(f))\n\n          one       two     three      four\nmax  0.909529  0.797564  0.941021  0.738347\nmin  0.328656  0.325377  0.129058  0.307291\n\n\n\n\n\n4.1.7 Sorting and Ranking\n\n.sort_values(by=)\n.rank(ascending=, method=)\n\n\n\n4.1.8 Summarizing and Computing Descriptive Statistics\n\nsum, cumsum\nmean, median\n.describe()\n.cov, .corr\n\n\n\n4.1.9 Unique Values, Value Counts, and Membership\n\nunique\nvalue_counts\n\n\n\n4.1.10 Reading and Writing Data in Text Format\n\nread_csv\nread_excel\ndf.to_csv\n\n\n\n4.1.11 Copies and views\n\ninplace"
  },
  {
    "objectID": "contents/4/04-.html#data-cleaning",
    "href": "contents/4/04-.html#data-cleaning",
    "title": "4  Package: pandas",
    "section": "4.2 Data cleaning",
    "text": "4.2 Data cleaning\n\n4.2.1 Handling Missing Data\n\nnp.nan, pd.NA\npd.isnull(), np.isnan()\ndropna, fillna\n\n\n\nExample 4.5 \nimport pandas as pd\nimport numpy as np\n\ndata = pd.DataFrame([[1., 6.5, 3.], [1., np.nan, np.nan], \n                     [np.nan, np.nan, np.nan], [np.nan, 6.5, 3.]])\ncleaned = data.dropna()\ncleanedrow = data.dropna(how='all')\ndata\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n    \n  \n  \n    \n      0\n      1.0\n      6.5\n      3.0\n    \n    \n      1\n      1.0\n      NaN\n      NaN\n    \n    \n      2\n      NaN\n      NaN\n      NaN\n    \n    \n      3\n      NaN\n      6.5\n      3.0\n    \n  \n\n\n\n\n\ncleaned\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n    \n  \n  \n    \n      0\n      1.0\n      6.5\n      3.0\n    \n  \n\n\n\n\n\ncleanedrow\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n    \n  \n  \n    \n      0\n      1.0\n      6.5\n      3.0\n    \n    \n      1\n      1.0\n      NaN\n      NaN\n    \n    \n      3\n      NaN\n      6.5\n      3.0\n    \n  \n\n\n\n\n\ndata[4] = np.nan\ncleaned1 = data.dropna(axis=1, how='all')\ncleanedthresh = data.dropna(thresh=2)\ndata\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n      4\n    \n  \n  \n    \n      0\n      1.0\n      6.5\n      3.0\n      NaN\n    \n    \n      1\n      1.0\n      NaN\n      NaN\n      NaN\n    \n    \n      2\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      3\n      NaN\n      6.5\n      3.0\n      NaN\n    \n  \n\n\n\n\n\ncleaned1\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n    \n  \n  \n    \n      0\n      1.0\n      6.5\n      3.0\n    \n    \n      1\n      1.0\n      NaN\n      NaN\n    \n    \n      2\n      NaN\n      NaN\n      NaN\n    \n    \n      3\n      NaN\n      6.5\n      3.0\n    \n  \n\n\n\n\n\ncleanedthresh\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n      4\n    \n  \n  \n    \n      0\n      1.0\n      6.5\n      3.0\n      NaN\n    \n    \n      3\n      NaN\n      6.5\n      3.0\n      NaN\n    \n  \n\n\n\n\n\nfill0 = data.fillna(0)\nfilldict = data.fillna({1: 0.5, 2: -0.1})\ndata\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n      4\n    \n  \n  \n    \n      0\n      1.0\n      6.5\n      3.0\n      NaN\n    \n    \n      1\n      1.0\n      NaN\n      NaN\n      NaN\n    \n    \n      2\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      3\n      NaN\n      6.5\n      3.0\n      NaN\n    \n  \n\n\n\n\n\nfill0\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n      4\n    \n  \n  \n    \n      0\n      1.0\n      6.5\n      3.0\n      0.0\n    \n    \n      1\n      1.0\n      0.0\n      0.0\n      0.0\n    \n    \n      2\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      3\n      0.0\n      6.5\n      3.0\n      0.0\n    \n  \n\n\n\n\n\nfilldict\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n      4\n    \n  \n  \n    \n      0\n      1.0\n      6.5\n      3.0\n      NaN\n    \n    \n      1\n      1.0\n      0.5\n      -0.1\n      NaN\n    \n    \n      2\n      NaN\n      0.5\n      -0.1\n      NaN\n    \n    \n      3\n      NaN\n      6.5\n      3.0\n      NaN\n    \n  \n\n\n\n\n\n\n\n4.2.2 Data Transformation\n\n.duplicated(), drop_duplicates()\n\n\n\nExample 4.6 \nimport numpy as np\nimport pandas as pd\n\ndata = pd.DataFrame({'k1': ['one', 'two'] * 3 + ['two'], \n                     'k2': [1, 1, 2, 3, 3, 4, 4]})\ndata.drop_duplicates(['k1'], keep='last')\n\n\n\n\n\n  \n    \n      \n      k1\n      k2\n    \n  \n  \n    \n      4\n      one\n      3\n    \n    \n      6\n      two\n      4\n    \n  \n\n\n\n\n\n\npd.Series.map(), pd.DataFrame.apply()\n\n\n\nExample 4.7 \nimport pandas as pd\nimport numpy as np\n\ndata = pd.DataFrame({'food': ['bacon', 'pulled pork', 'bacon',\n                     'Pastrami', 'corned beef', 'Bacon',\n                     'pastrami', 'honey ham', 'nova lox'],\n                     'ounces': [4, 3, 12, 6, 7.5, 8, 3, 5, 6]})\n\nmeat_to_animal = {\n    'bacon': 'pig',\n    'pulled pork': 'pig',\n    'pastrami': 'cow',\n    'corned beef': 'cow',\n    'honey ham': 'pig',\n    'nova lox': 'salmon'\n    }\n\ndata['animal'] = data['food'].str.lower().map(meat_to_animal)\n\ndata['food'].map(lambda x: meat_to_animal[x.lower()])\n\n0       pig\n1       pig\n2       pig\n3       cow\n4       cow\n5       pig\n6       cow\n7       pig\n8    salmon\nName: food, dtype: object\n\n\n\n\nreplace\nrename \ndescribe\npermutation\nsample\ndummy variables\n\n\n\n4.2.3 Example: Movies\nBelow we explore the MovieLens 1M datasets. You may download it from this link.\n\nimport pandas as pd\nimport numpy as np\nmnames = ['movie_id', 'title', 'genres']\nmovies = pd.read_table('assests/datasets/movies.dat', sep='::',\n                       header=None, names=mnames, engine=\"python\",\n                       encoding='ISO-8859-1')\n\nall_genres = list()\nmovies['genres'].map(lambda x: all_genres.extend(x.split('|')))\n\ngenres = pd.unique(all_genres)\n\ndummies = pd.DataFrame(np.zeros((len(movies), len(genres))), columns=genres)\n\nfor i, gen in enumerate(movies.genres):\n    indices = dummies.columns.get_indexer(gen.split('|'))\n    dummies.iloc[i, indices] = 1\n\nmovies_windic = movies.join(dummies.add_prefix('Genre_'))\n\n\n\n4.2.4 String Manipulation\nThe key idea in this section is that, all methods in pd.Series.str will be applied to each entry of the Series.\n\n\nExample 4.8 \nimport pandas as pd\nimport numpy as np\ns = pd.Series([\"A \", \" B \", \"C\", \"Aaba\", \" Baca \", np.nan, \"CABA\", \"dog\", \"cat\"])\n\ns.str.lower()\ns.str.split('a')\ns.str.len()\ns.str.strip()\ns.str.replace(\"A\", '1')\n\n0        1 \n1        B \n2         C\n3      1aba\n4     Baca \n5       NaN\n6      C1B1\n7       dog\n8       cat\ndtype: object\n\n\n\n\nExample 4.9 We could also use .str to play with column names and row indexes.\n\nimport pandas as pd\nimport numpy as np\ndf = pd.DataFrame(np.random.randn(3, 2),\n                  columns=[\" Column A \", \" Column B \"], index=range(3))\n\ndf.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\ndf\n\n\n\n\n\n  \n    \n      \n      column_a\n      column_b\n    \n  \n  \n    \n      0\n      -0.276580\n      -0.584007\n    \n    \n      1\n      -1.578532\n      -0.573127\n    \n    \n      2\n      0.608779\n      -0.613216\n    \n  \n\n\n\n\n\n\n\n4.2.5 Regular expression\nRegular expressions provide a flexible way to search or match string patterns in text. A single expression, commonly called a regex, is a string formed according to the regular expression language. Python’s built-in re module is responsible for applying regular expressions to strings.\nFor details of the regular expression language in Python, please read the official documents from here. There are also many great websites for learning regex. This is one example.\nWe will briefly mentioned a few rules here.\n\n.: matches any character except a newline.\n\\d: matches any digit. It is the same as [0-9].\n\\w: matches any alphabatic or numeric character. It is the same as [a-zA-Z0-9_].\n\\s: matches any whitespaces. It is the same as [\\t\\n\\r\\f\\v].\n*: Causes the resulting RE to match 0 or more repetitions of the preceding RE, as many repetitions as are possible.\n+: Causes the resulting RE to match 1 or more repetitions of the preceding RE, as many repetitions as are possible.\n?: Causes the resulting RE to match 0 or 1 repetitions of the preceding RE.\n*?, +?, ??: The *, +, and ? qualifiers are all greedy; they match as much text as possible. Adding ? after the qualifier makes it perform the match in non-greedy or minimal fashion; as few characters as possible will be matched.\n{m}: Specifies that exactly m copies of the previous RE should be matched.\n{m,n}: Causes the resulting RE to match from m to n repetitions of the preceding RE, attempting to match as many repetitions as possible.\n{m,n}?: Causes the resulting RE to match from m to n repetitions of the preceding RE, attempting to match as few repetitions as possible.\n[]: Used to indicate a set of characters.\n(): set groups.\n\n\n\nExample 4.10 \nimport re\ntext = \"foo bar\\t baz \\tqux\"\npattern = '\\s+'\nregex = re.compile(pattern)\nregex.split(text)\n\n['foo', 'bar', 'baz', 'qux']\n\n\n\n\n.match()\n.search()\n.findall()\n.split()\n.sub()\n\nWe can use () to specify groups, and use .groups() to get access to the results.\n\n\nExample 4.11 \nimport re\npattern = r'([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\\.([A-Z]{2,4})'\nregex = re.compile(pattern, flags=re.IGNORECASE)\nm = regex.match('wesm@bright.net')\nm.groups()\n\n('wesm', 'bright', 'net')\n\n\n\nTo use regex to DataFrame and Series, you may directly apply .match, .findall, .replace after .str, with the regex pattern as one of the arguments.\n.extract is a method that is not from re. It is used to extract the matched groups and make them as a DataFrame.\n\n\nExample 4.12 \nimport pandas as pd\nimport numpy as np\nmnames = ['movie_id', 'title', 'genres']\nmovies = pd.read_table('assests/datasets/movies.dat', sep='::',\n                       header=None, names=mnames, engine=\"python\",\n                       encoding='ISO-8859-1')\n\npattern = r'([a-zA-Z0-9_\\s,.?:;\\']+)\\((\\d{4})\\)'\nmovies = movies.join(movies.title.str.extract(pattern).rename(columns={0: 'movie title', 1: 'year'}))"
  },
  {
    "objectID": "contents/4/04-.html#data-wrangling",
    "href": "contents/4/04-.html#data-wrangling",
    "title": "4  Package: pandas",
    "section": "4.3 Data Wrangling",
    "text": "4.3 Data Wrangling\n\n4.3.1 Hierarchical indexing\nPandas support a more complex indexing system, that the index may have multiple levels. See the following example.\n\n\nimport pandas as pd\nimport numpy as np\n\ndata = pd.Series(np.random.randn(9),\n                 index = [['a', 'a', 'a', 'b', 'b', 'c', 'c', 'd', 'd'],\n                          [1, 2, 3, 1, 2, 3, 1, 2, 3]])\ndata\n\na  1   -0.796506\n   2   -0.002095\n   3    0.074888\nb  1   -0.414308\n   2   -0.969898\nc  3   -0.513748\n   1   -0.008120\nd  2   -1.297118\n   3    0.607681\ndtype: float64\n\n\nYou may look at the Series using different levels of indexes.\n\ndata['a']\n\n1   -0.796506\n2   -0.002095\n3    0.074888\ndtype: float64\n\n\n\ndata.loc[:, 2]\n\na   -0.002095\nb   -0.969898\nd   -1.297118\ndtype: float64\n\n\nYou may use groupby to group by levels and do calculations related to levels. More .groupby() will be discussed in the next section.\n\ndata.groupby(level=1).sum()\n\n1   -1.218935\n2   -2.269111\n3    0.168820\ndtype: float64\n\n\n\nFrom the example above, you may notice that the 2-level hierarchical indexing for a Series works very similar to a DataFrame. In fact, you may translate it back and forth between a 2-level indexing Series and a DataFrame.\n\ndf = data.unstack()\ndf\n\n\n\n\n\n  \n    \n      \n      1\n      2\n      3\n    \n  \n  \n    \n      a\n      -0.796506\n      -0.002095\n      0.074888\n    \n    \n      b\n      -0.414308\n      -0.969898\n      NaN\n    \n    \n      c\n      -0.008120\n      NaN\n      -0.513748\n    \n    \n      d\n      NaN\n      -1.297118\n      0.607681\n    \n  \n\n\n\n\n\ndf.stack()\n\na  1   -0.796506\n   2   -0.002095\n   3    0.074888\nb  1   -0.414308\n   2   -0.969898\nc  1   -0.008120\n   3   -0.513748\nd  2   -1.297118\n   3    0.607681\ndtype: float64\n\n\nFor DataFrame the index for both axes can be multiindex. The usual indexing way can be used if you want to start from the first level of the index. The more specific method to extract data is .xs.\n\n\nExample 4.13 \nimport pandas as pd\n\ndf1 = pd.DataFrame(\n    {\n        \"A\": [\"A0\", \"A1\", \"A2\", \"A3\"],\n        \"B\": [\"B0\", \"B1\", \"B2\", \"B3\"],\n        \"C\": [\"C0\", \"C1\", \"C2\", \"C3\"],\n        \"D\": [\"D0\", \"D1\", \"D2\", \"D3\"],\n    },\n    index=[0, 1, 2, 3],\n)\n\ndf2 = pd.DataFrame(\n    {\n        \"A\": [\"A4\", \"A5\", \"A6\", \"A7\"],\n        \"B\": [\"B4\", \"B5\", \"B6\", \"B7\"],\n        \"C\": [\"C4\", \"C5\", \"C6\", \"C7\"],\n        \"D\": [\"D4\", \"D5\", \"D6\", \"D7\"],\n    },\n    index=[4, 5, 6, 7],\n)\n\ndf = pd.concat([df1, df2], keys=['x', 'y'])\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      x\n      0\n      A0\n      B0\n      C0\n      D0\n    \n    \n      1\n      A1\n      B1\n      C1\n      D1\n    \n    \n      2\n      A2\n      B2\n      C2\n      D2\n    \n    \n      3\n      A3\n      B3\n      C3\n      D3\n    \n    \n      y\n      4\n      A4\n      B4\n      C4\n      D4\n    \n    \n      5\n      A5\n      B5\n      C5\n      D5\n    \n    \n      6\n      A6\n      B6\n      C6\n      D6\n    \n    \n      7\n      A7\n      B7\n      C7\n      D7\n    \n  \n\n\n\n\n\ndf['A']\n\nx  0    A0\n   1    A1\n   2    A2\n   3    A3\ny  4    A4\n   5    A5\n   6    A6\n   7    A7\nName: A, dtype: object\n\n\n\ndf.loc['x']\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      A0\n      B0\n      C0\n      D0\n    \n    \n      1\n      A1\n      B1\n      C1\n      D1\n    \n    \n      2\n      A2\n      B2\n      C2\n      D2\n    \n    \n      3\n      A3\n      B3\n      C3\n      D3\n    \n  \n\n\n\n\n\ndf.loc['x',3]\n\nA    A3\nB    B3\nC    C3\nD    D3\nName: (x, 3), dtype: object\n\n\n\ndf.xs(3, level=1, drop_level=False)\n\n\n\n\n\n  \n    \n      \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      x\n      3\n      A3\n      B3\n      C3\n      D3\n    \n  \n\n\n\n\n\n\n\n4.3.2 Combining and Merging Datasets\n\n4.3.2.1 merge()\nMerge combines datasets by linking rows using one or more keys. This is from relational databases (e.g., SQL-based).\nHere are some examples.\n\n\nExample 4.14 \nimport pandas as pd\ndf1 = pd.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'a', 'b'],\n                    'data1': range(7)})\ndf2 = pd.DataFrame({'key': ['a', 'b', 'd'], 'data2': range(3)})\n\nThe two DataFrames are displayed as follows.\n\ndf1\n\n\n\n\n\n  \n    \n      \n      key\n      data1\n    \n  \n  \n    \n      0\n      b\n      0\n    \n    \n      1\n      b\n      1\n    \n    \n      2\n      a\n      2\n    \n    \n      3\n      c\n      3\n    \n    \n      4\n      a\n      4\n    \n    \n      5\n      a\n      5\n    \n    \n      6\n      b\n      6\n    \n  \n\n\n\n\n\ndf2\n\n\n\n\n\n  \n    \n      \n      key\n      data2\n    \n  \n  \n    \n      0\n      a\n      0\n    \n    \n      1\n      b\n      1\n    \n    \n      2\n      d\n      2\n    \n  \n\n\n\n\n\npd.merge(df1, df2, on='key')\n\n\n\n\n\n  \n    \n      \n      key\n      data1\n      data2\n    \n  \n  \n    \n      0\n      b\n      0\n      1\n    \n    \n      1\n      b\n      1\n      1\n    \n    \n      2\n      b\n      6\n      1\n    \n    \n      3\n      a\n      2\n      0\n    \n    \n      4\n      a\n      4\n      0\n    \n    \n      5\n      a\n      5\n      0\n    \n  \n\n\n\n\nIf the column names are different in each object, you can specify them separately.\n\ndf3 = pd.DataFrame({'lkey': ['b', 'b', 'a', 'c', 'a', 'a', 'b'],\n                    'data1': range(7)})\ndf4 = pd.DataFrame({'rkey': ['a', 'b', 'd'],\n                    'data2': range(3)})\npd.merge(df3, df4, left_on='lkey', right_on='rkey')\n\n\n\n\n\n  \n    \n      \n      lkey\n      data1\n      rkey\n      data2\n    \n  \n  \n    \n      0\n      b\n      0\n      b\n      1\n    \n    \n      1\n      b\n      1\n      b\n      1\n    \n    \n      2\n      b\n      6\n      b\n      1\n    \n    \n      3\n      a\n      2\n      a\n      0\n    \n    \n      4\n      a\n      4\n      a\n      0\n    \n    \n      5\n      a\n      5\n      a\n      0\n    \n  \n\n\n\n\n\nBy default merge does an inner join, that the keys in the result are the interesection found in both tables. Below are different types of merge. To specify the method for merge, the option is how.\n\ninner\nleft\nright\nouter\n\nLet’s see the following examples.\n\n\n\n\ndf1 = pd.DataFrame({'Key': [1, 2], 'A': [0, 2], 'B': [1, 3]})\ndf1\n\n\n\n\n\n  \n    \n      \n      Key\n      A\n      B\n    \n  \n  \n    \n      0\n      1\n      0\n      1\n    \n    \n      1\n      2\n      2\n      3\n    \n  \n\n\n\n\n\n\n\n\ndf2 = pd.DataFrame({'Key': [1, 3], 'C': [0, 2], 'D': [1, 3]})\ndf2\n\n\n\n\n\n  \n    \n      \n      Key\n      C\n      D\n    \n  \n  \n    \n      0\n      1\n      0\n      1\n    \n    \n      1\n      3\n      2\n      3\n    \n  \n\n\n\n\n\n\n\n\n\n\n\npd.merge(df1, df2, on='Key', how='inner')\n\n\n\n\n\n  \n    \n      \n      Key\n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      1\n      0\n      1\n      0\n      1\n    \n  \n\n\n\n\n\n\n\n\npd.merge(df1, df2, on='Key', how='outer')\n\n\n\n\n\n  \n    \n      \n      Key\n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      1\n      0.0\n      1.0\n      0.0\n      1.0\n    \n    \n      1\n      2\n      2.0\n      3.0\n      NaN\n      NaN\n    \n    \n      2\n      3\n      NaN\n      NaN\n      2.0\n      3.0\n    \n  \n\n\n\n\n\n\n\n\n\n\n\npd.merge(df1, df2, on='Key', how='left')\n\n\n\n\n\n  \n    \n      \n      Key\n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      1\n      0\n      1\n      0.0\n      1.0\n    \n    \n      1\n      2\n      2\n      3\n      NaN\n      NaN\n    \n  \n\n\n\n\n\n\n\n\npd.merge(df1, df2, on='Key', how='right')\n\n\n\n\n\n  \n    \n      \n      Key\n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      1\n      0.0\n      1.0\n      0\n      1\n    \n    \n      1\n      3\n      NaN\n      NaN\n      2\n      3\n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf a key combination appears more than once in both tables, the resulting table will have the Cartesian product of the associated data. Here is a very basic example with one unique key combination\n\ndf1 = pd.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'b'],\n                    'data1': range(6)})\ndf2 = pd.DataFrame({'key': ['a', 'b', 'a', 'b', 'd'],\n                    'data2': range(5)})\npd.merge(df1, df2, on='key', how='left')\n\n\n\n\n\n  \n    \n      \n      key\n      data1\n      data2\n    \n  \n  \n    \n      0\n      b\n      0\n      1.0\n    \n    \n      1\n      b\n      0\n      3.0\n    \n    \n      2\n      b\n      1\n      1.0\n    \n    \n      3\n      b\n      1\n      3.0\n    \n    \n      4\n      a\n      2\n      0.0\n    \n    \n      5\n      a\n      2\n      2.0\n    \n    \n      6\n      c\n      3\n      NaN\n    \n    \n      7\n      a\n      4\n      0.0\n    \n    \n      8\n      a\n      4\n      2.0\n    \n    \n      9\n      b\n      5\n      1.0\n    \n    \n      10\n      b\n      5\n      3.0\n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf the merge keys in a DataFrame is in its index instead of column(s), we could pass left_index=True or right_index=True or both instead of setting left_on/right_on/on.\n\n\n\n\n4.3.2.2 concat()\nThe concat() function (in the main pandas namespace) performs concatenation operations along an axis while performing optional set logic (union or intersection) of the indexes (if any) on the other axes.\n\nimport pandas as pd\n\ndf1 = pd.DataFrame(\n    {\n        \"A\": [\"A0\", \"A1\", \"A2\", \"A3\"],\n        \"B\": [\"B0\", \"B1\", \"B2\", \"B3\"],\n        \"C\": [\"C0\", \"C1\", \"C2\", \"C3\"],\n        \"D\": [\"D0\", \"D1\", \"D2\", \"D3\"],\n    },\n    index=[0, 1, 2, 3],\n)\n\ndf2 = pd.DataFrame(\n    {\n        \"A\": [\"A4\", \"A5\", \"A6\", \"A7\"],\n        \"B\": [\"B4\", \"B5\", \"B6\", \"B7\"],\n        \"C\": [\"C4\", \"C5\", \"C6\", \"C7\"],\n        \"D\": [\"D4\", \"D5\", \"D6\", \"D7\"],\n    },\n    index=[4, 5, 6, 7],\n)\n\ndf3 = pd.DataFrame(\n    {\n        \"A\": [\"A8\", \"A9\", \"A10\", \"A11\"],\n        \"B\": [\"B8\", \"B9\", \"B10\", \"B11\"],\n        \"C\": [\"C8\", \"C9\", \"C10\", \"C11\"],\n        \"D\": [\"D8\", \"D9\", \"D10\", \"D11\"],\n    },\n    index=[8, 9, 10, 11],\n)\n\npd.concat([df1, df2, df3], keys=['x', 'y', 'z'])\n\n\n\n\n\n  \n    \n      \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      x\n      0\n      A0\n      B0\n      C0\n      D0\n    \n    \n      1\n      A1\n      B1\n      C1\n      D1\n    \n    \n      2\n      A2\n      B2\n      C2\n      D2\n    \n    \n      3\n      A3\n      B3\n      C3\n      D3\n    \n    \n      y\n      4\n      A4\n      B4\n      C4\n      D4\n    \n    \n      5\n      A5\n      B5\n      C5\n      D5\n    \n    \n      6\n      A6\n      B6\n      C6\n      D6\n    \n    \n      7\n      A7\n      B7\n      C7\n      D7\n    \n    \n      z\n      8\n      A8\n      B8\n      C8\n      D8\n    \n    \n      9\n      A9\n      B9\n      C9\n      D9\n    \n    \n      10\n      A10\n      B10\n      C10\n      D10\n    \n    \n      11\n      A11\n      B11\n      C11\n      D11\n    \n  \n\n\n\n\n\npd.concat([df1, df2, df3], axis=1)\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n      A\n      B\n      C\n      D\n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      A0\n      B0\n      C0\n      D0\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      1\n      A1\n      B1\n      C1\n      D1\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      2\n      A2\n      B2\n      C2\n      D2\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      3\n      A3\n      B3\n      C3\n      D3\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      4\n      NaN\n      NaN\n      NaN\n      NaN\n      A4\n      B4\n      C4\n      D4\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      5\n      NaN\n      NaN\n      NaN\n      NaN\n      A5\n      B5\n      C5\n      D5\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      6\n      NaN\n      NaN\n      NaN\n      NaN\n      A6\n      B6\n      C6\n      D6\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      7\n      NaN\n      NaN\n      NaN\n      NaN\n      A7\n      B7\n      C7\n      D7\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      8\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      A8\n      B8\n      C8\n      D8\n    \n    \n      9\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      A9\n      B9\n      C9\n      D9\n    \n    \n      10\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      A10\n      B10\n      C10\n      D10\n    \n    \n      11\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      A11\n      B11\n      C11\n      D11\n    \n  \n\n\n\n\n\npd.concat"
  },
  {
    "objectID": "contents/4/04-.html#data-aggregation-and-group-operations",
    "href": "contents/4/04-.html#data-aggregation-and-group-operations",
    "title": "4  Package: pandas",
    "section": "4.4 Data Aggregation and Group Operations",
    "text": "4.4 Data Aggregation and Group Operations\n\n4.4.1 split-apply-combine model\nWe would like to apply group operations based on the split-apply-combine model.\n\nIn the first stage of the process, data contained in a pandas object is split into groups based on one or more keys that you provide. We then use .groupby(keys) to perform the split step. The result is a grouped groupby object.\nOnce this is done, a function is applied to each group, producing a new value.\nFinally the results of all those function applications are combined into a result object. We may apply groupby functions directly as methods to groupby objects.The result is the combined result object.\n\n\n\nExample 4.15 \nimport pandas as pd\ndf = pd.DataFrame({'key1' : ['a', 'a', 'b', 'b', 'a'],\n                   'key2' : ['one', 'two', 'one', 'two', 'one'],\n                   'data1' : np.random.randn(5),\n                   'data2' : np.random.randn(5)})\ndf\n\n\n\n\n\n  \n    \n      \n      key1\n      key2\n      data1\n      data2\n    \n  \n  \n    \n      0\n      a\n      one\n      1.057442\n      0.566464\n    \n    \n      1\n      a\n      two\n      -0.487869\n      0.782018\n    \n    \n      2\n      b\n      one\n      -0.316714\n      0.548751\n    \n    \n      3\n      b\n      two\n      -0.893542\n      -0.574648\n    \n    \n      4\n      a\n      one\n      0.629368\n      -0.002414\n    \n  \n\n\n\n\nNow we want to group data1 in df by key1.\n\ngrouped = df['data1'].groupby(df['key1'])\ngrouped\n\n<pandas.core.groupby.generic.SeriesGroupBy object at 0x00000255FFB6AA30>\n\n\nWhat we get is a groupby object and we could apply group functions to it.\nThe method to look at each group is .get_group.\n\ngrouped.get_group('a')\n\n0    1.057442\n1   -0.487869\n4    0.629368\nName: data1, dtype: float64\n\n\nWe may directly apply some group functions to the groupby object.\n\ngrouped.mean()\n\nkey1\na    0.399647\nb   -0.605128\nName: data1, dtype: float64\n\n\n\ngrouped.size()\n\nkey1\na    3\nb    2\nName: data1, dtype: int64\n\n\nWe could iterate over groups.\n\nfor name, group in grouped:\n    print('name', name)\n    print('group', group)\n\nname a\ngroup 0    1.057442\n1   -0.487869\n4    0.629368\nName: data1, dtype: float64\nname b\ngroup 2   -0.316714\n3   -0.893542\nName: data1, dtype: float64\n\n\nWe could convert the group object into list and dictionary.\n\nlist(grouped)\n\n[('a',\n  0    1.057442\n  1   -0.487869\n  4    0.629368\n  Name: data1, dtype: float64),\n ('b',\n  2   -0.316714\n  3   -0.893542\n  Name: data1, dtype: float64)]\n\n\n\ndict(list(grouped))\n\n{'a': 0    1.057442\n 1   -0.487869\n 4    0.629368\n Name: data1, dtype: float64,\n 'b': 2   -0.316714\n 3   -0.893542\n Name: data1, dtype: float64}\n\n\n\n\n\n4.4.2 More aggregation functions\n\n.describe()\n.count()\n.sum()\n.mean()\n.median\n.std(), .var()\n.min(), .max()\n.prod()\nfirst(), .last()\n.agg()\n\n\n\n4.4.3 Some examples\n\nExample 4.16 Consider the following DataFrame.\n\nimport pandas as pd\ndf = pd.DataFrame({'location': ['East', 'East', 'East', 'East',\n                                'West', 'West', 'West', 'West'],\n                   'data': np.random.randn(8)},\n                   index=['Ohio', 'New York', 'Vermont', 'Florida',\n                          'Oregon', 'Nevada', 'California', 'Idaho'])\ndf.loc[['Vermont', 'Nevada', 'Idaho'], 'data'] = np.nan\n\nWe would like to fill in NA values with the mean from each group.\n\ndf.groupby('location').apply(lambda x: x.fillna(x.mean()))\n\nC:\\Users\\Xinli\\AppData\\Local\\Temp\\ipykernel_5420\\2040193686.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n  df.groupby('location').apply(lambda x: x.fillna(x.mean()))\n\n\n\n\n\n\n  \n    \n      \n      location\n      data\n    \n  \n  \n    \n      Ohio\n      East\n      -0.534246\n    \n    \n      New York\n      East\n      1.153447\n    \n    \n      Vermont\n      East\n      0.173473\n    \n    \n      Florida\n      East\n      -0.098784\n    \n    \n      Oregon\n      West\n      1.793719\n    \n    \n      Nevada\n      West\n      0.378500\n    \n    \n      California\n      West\n      -1.036720\n    \n    \n      Idaho\n      West\n      0.378500\n    \n  \n\n\n\n\nWe could also fill in NA values with predefined values, similar to the non-groupby case.\n\ndf.groupby('location').apply(lambda x: x.fillna({'East': 0.1,\n                                                 'West': -0.5}[x.name]))\n\n\n\n\n\n  \n    \n      \n      location\n      data\n    \n  \n  \n    \n      Ohio\n      East\n      -0.534246\n    \n    \n      New York\n      East\n      1.153447\n    \n    \n      Vermont\n      East\n      0.100000\n    \n    \n      Florida\n      East\n      -0.098784\n    \n    \n      Oregon\n      West\n      1.793719\n    \n    \n      Nevada\n      West\n      -0.500000\n    \n    \n      California\n      West\n      -1.036720\n    \n    \n      Idaho\n      West\n      -0.500000"
  },
  {
    "objectID": "contents/4/04-.html#exercises",
    "href": "contents/4/04-.html#exercises",
    "title": "4  Package: pandas",
    "section": "4.5 Exercises",
    "text": "4.5 Exercises\nMost problems are based on [1].\n\nExercise 4.1 Please use the following code to generate a series ser, and then finish the following tasks.\n\nimport pandas as pd\nimport numpy as np\n\n\nmylist = list('abcedfghijklmnopqrstuvwxyz')\nmyarr = np.arange(26)\nmydict = dict(zip(mylist, myarr))\nser = pd.Series(mydict)\n\n\nConvert the series ser into a dataframe df with its index as another column on the dataframe.\nPick the two columns of df and set them into two serieses ser1 and ser2.\nCombine two series ser1 and ser2 to form a new dataframe newdf, and name their columns ser1 and ser2.\n\n\n\nExercise 4.2 Consider two serieses ser1 and ser2. You may use the following ser1 and ser2 as an example. The output of each questions below should be a series. You may want to learn the following commands:\n\nnp.union1d()\nnp.intersect1d()\nnp.isin()\n\n\nimport pandas as pd\n\nser1 = pd.Series([1, 2, 3, 4, 5])\nser2 = pd.Series([4, 5, 6, 7, 8])\n\n\nFind all the elements from ser1 that are also in ser2.\nFind all the elements from ser2 that are also in ser1.\nFrom ser1 remove items present in ser2.\nFind the union of ser1 and ser2.\nFind the intersection of ser1 and ser2.\nFind all the elemetns that are in either ser1 or ser2, but not both.\n\n\n\nExercise 4.3 (Some statistics) Please check the following commands and answer the following questions.\n\nnp.percentile()\n\nHow to get the minimum, 25th percentile, median, 75th, and max of a numeric series? You may use the following Series as an example.\n\nimport pandas as pd\nser = pd.Series(np.random.normal(10, 5, 25))\n\n\n\nExercise 4.4 Please use pd.Series.value_counts() to calculte the frequency counts of each unique value of the following Series.\n\nimport pandas as pd\nimport numpy as np\nser = pd.Series(np.take(list('abcdefgh'), np.random.randint(8, size=30)))\n\n\n\nExercise 4.5 Please keep the top 2 most frequent items of ser as it is and replace everything else as Other.\n\nimport pandas as pd\nimport numpy as np\nser = pd.Series(np.take(list('abcdefgh'), np.random.randint(8, size=30)))\n\n\n\nExercise 4.6 Please use pd.cut or pd.qcut to bin the Series ser into 10 equal deciles. You may use the following ser as an example.\n\nimport pandas as pd\nser = pd.Series(np.random.random(20))\n\n\n\nExercise 4.7 Consider the Series ser:\n\nimport pandas as pd\nimport numpy as np\nser = pd.Series(np.random.randint(1, 10, 7))\n\nFind the positions of numbers that are multiples of 3 from ser.\n\n\nExercise 4.8 Compute the mean of weights of each fruit.\n\nimport pandas as pd\nfruit = pd.Series(np.random.choice(['apple', 'banana', 'carrot'], 10))\nweights = pd.Series(np.linspace(1, 10, 10))\ndf = pd.DataFrame({'fruit': fruit, 'weights': weights})\n\n\n\nExercise 4.9 Consider the following DataFrame.\n\nimport pandas as pd\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n\n\nCheck if df has any missing values.\nPlease count the number of missing values in each column.\nPlease replace all missing values in Min.Price and Max.Price with their mean respectively.\n\n\n\n\nExercise 4.10 Replace the spaces in my_str = 'dbc deb abed gade' with the least frequent character.\n\n\nExercise 4.11 Suppress scientific notations like e-03 in df and print up to 4 numbers after decimal.\n\nimport pandas as pd\nimport numpy as np\ndf = pd.DataFrame(np.random.random(4)**10, columns=['random'])\ndf\n\n\n\n\n\n  \n    \n      \n      random\n    \n  \n  \n    \n      0\n      8.148425e-07\n    \n    \n      1\n      2.198640e-02\n    \n    \n      2\n      1.051602e-08\n    \n    \n      3\n      6.884282e-08\n    \n  \n\n\n\n\n\n\nExercise 4.12 Format the values in column random of df as percentages.\n\nimport pandas as pd\nimport numpy as np\ndf = pd.DataFrame(np.random.random(4), columns=['random'])\ndf\n\n\n\n\n\n  \n    \n      \n      random\n    \n  \n  \n    \n      0\n      0.755199\n    \n    \n      1\n      0.219599\n    \n    \n      2\n      0.646205\n    \n    \n      3\n      0.824826\n    \n  \n\n\n\n\n\n\nExercise 4.13 (Regular expressions) Please use regular expressions to finish the following tasks.\n\nMatch a string that has an a followed by zero or more b’s.\nMatch a string that has an a followed by one or more b’s.\nMatch a string that has an a followed by zero or one b.\nMatch a string that has an a followed by three b’s.\n\n\n\nExercise 4.14 (More regex) Find all words starting with a or e in a given string:\n\ntext = \"The following example creates an ArrayList with a capacity of 50 elements. Four elements are then added to the ArrayList and the ArrayList is trimmed accordingly.\"\n\n\n\nExercise 4.15 (More regex) Write a Python code to extract year, month and date from a url1:\n\nurl1= \"https://www.washingtonpost.com/news/football-insider/wp/2016/09/02/odell-beckhams-fame-rests-on-one-stupid-little-ball-josh-norman-tells-author/\"\n\n\n\nExercise 4.16 (More regex) Please use regex to parse the following str to create a dictionary.\n\ntext = r'''\n{\n    name: Firstname Lastname;\n    age: 100;\n    salary: 10000 \n}\n'''\n\n\n\nExercise 4.17 Consider the following DataFrame.\n\ndata = [['Evert van Dijk', 'Carmine-pink, salmon-pink streaks, stripes, flecks.  Warm pink, clear carmine pink, rose pink shaded salmon.  Mild fragrance.  Large, very double, in small clusters, high-centered bloom form.  Blooms in flushes throughout the season.'],\n        ['Every Good Gift', 'Red.  Flowers velvety red.  Moderate fragrance.  Average diameter 4\".  Medium-large, full (26-40 petals), borne mostly solitary bloom form.  Blooms in flushes throughout the season.'], \n        ['Evghenya', 'Orange-pink.  75 petals.  Large, very double bloom form.  Blooms in flushes throughout the season.'], \n        ['Evita', 'White or white blend.  None to mild fragrance.  35 petals.  Large, full (26-40 petals), high-centered bloom form.  Blooms in flushes throughout the season.'],\n        ['Evrathin', 'Light pink. [Deep pink.]  Outer petals white. Expand rarely.  Mild fragrance.  35 to 40 petals.  Average diameter 2.5\".  Medium, double (17-25 petals), full (26-40 petals), cluster-flowered, in small clusters bloom form.  Prolific, once-blooming spring or summer.  Glandular sepals, leafy sepals, long sepals buds.'],\n        ['Evita 2', 'White, blush shading.  Mild, wild rose fragrance.  20 to 25 petals.  Average diameter 1.25\".  Small, very double, cluster-flowered bloom form.  Blooms in flushes throughout the season.']]\n  \ndf = pd.DataFrame(data, columns = ['NAME', 'BLOOM']) \ndf \n\n\n\n\n\n  \n    \n      \n      NAME\n      BLOOM\n    \n  \n  \n    \n      0\n      Evert van Dijk\n      Carmine-pink, salmon-pink streaks, stripes, fl...\n    \n    \n      1\n      Every Good Gift\n      Red.  Flowers velvety red.  Moderate fragrance...\n    \n    \n      2\n      Evghenya\n      Orange-pink.  75 petals.  Large, very double b...\n    \n    \n      3\n      Evita\n      White or white blend.  None to mild fragrance....\n    \n    \n      4\n      Evrathin\n      Light pink. [Deep pink.]  Outer petals white. ...\n    \n    \n      5\n      Evita 2\n      White, blush shading.  Mild, wild rose fragran...\n    \n  \n\n\n\n\nPlease use regex methods to find all the () in each columns.\n\n\nExercise 4.18 Get the last two rows of df whose row sum is greater than 100.\n\nimport pandas as pd\ndf = pd.DataFrame(np.random.randint(10, 40, 60).reshape(-1, 4))\n\n\n\nExercise 4.19 The groupby object df_grouped is given below.\n\nimport pandas as pd\nimport numpy as np\ndf = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n                   'price': np.random.rand(9),\n                   'taste': np.random.randint(0, 11, 9)})\n\ndf_grouped = df.groupby(['fruit'])\n\n\nGet the group belonging to apple as a DataFrame.\nFind the second largest value of taste for banana.\nCompute the mean price for every fruit.\n\n\n\nExercise 4.20 Join df1 and df2 by fruit/pazham and weight/kilo.\n\ndf1 = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n                    'weight': ['high', 'medium', 'low'] * 3,\n                    'price': np.random.randint(0, 15, 9)})\n\ndf2 = pd.DataFrame({'pazham': ['apple', 'orange', 'pine'] * 2,\n                    'kilo': ['high', 'low'] * 3,\n                    'price': np.random.randint(0, 15, 6)})"
  },
  {
    "objectID": "contents/4/04-.html#projects",
    "href": "contents/4/04-.html#projects",
    "title": "4  Package: pandas",
    "section": "4.6 Projects",
    "text": "4.6 Projects\n\nExercise 4.21 Extract the valid emails from the series emails. The regex pattern for valid emails is provided as reference.\n\nimport pandas as pd\nemails = pd.Series(['buying books at amazom.com',\n                    'rameses@egypt.com',\n                    'matt@t.co',\n                    'narendra@modi.com'])\npattern = '[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,4}'\n\n\n\nExercise 4.22 Consider the following DataFrame.\n\nimport pandas as pd\nimport numpy as np\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv', usecols=[0,1,2,3,5])\n\n\nReplace NaN with string missing in columns Manufacturer, Model and Type.\nCreate an index as a combination of these three columns.\n\n\n\nExercise 4.23 Given the following DataFrame.\n\nimport pandas as pd\ndf = pd.DataFrame({\n    'name': ['James', 'Jane', 'Melissa', 'Ed', 'Neil'],\n    'age': [30, 40, 32, 67, 43],\n    'score': ['90%', '95%', '100%', '82%', '87%'],\n    'age_missing_data': [30, 40, 32, 67, None],\n    'income':[100000, 80000, 55000, 62000, 120000]\n})\n\n\nPlease use .map to create a new column numeric_score whose value is the number version of score.\nPlease use .apply to create a new column numeric_score whose value is the number version of score.\n\n\n\nExercise 4.24 From ser = pd.Series(['Apple', 'Orange', 'Plan', 'Python', 'Money']), find the words that contain at least 2 vowels.\n\n\nExercise 4.25 Please download the given file with sample emails, and use the following code to load the file and save it to a string content.\n\nwith open('assests/datasets/test_emails.txt', 'r') as f:\n    content = f.read()\n\nPlease use regex to play with content.\n\nGet all valid email address in content, from both the header part or the body part.\nThere are two emails in content. Please get the sender’s email and the receiver’s email from content.\nPlease get the sender’s name.\nPlease get the subject of each email.\n\n\n\nExercise 4.26 The following DataFrame is given.\n\nimport pandas as pd\ndf = pd.DataFrame([\"STD, City    State\",\n                   \"33, Kolkata    West Bengal\",\n                   \"44, Chennai    Tamil Nadu\",\n                   \"40, Hyderabad    Telengana\",\n                   \"80, Bangalore    Karnataka\"],\n                   columns=['row'])\n\n\nSplit the columns into a list with 3 entries.\nMake the first row (row 0) into a header.\nCreate a new DataFrame out of the data.\n\n\n\n\n\n\n[1] Prabhakaran, S. (2018). 101 pandas exercises for data analysis."
  },
  {
    "objectID": "contents/references.html",
    "href": "contents/references.html",
    "title": "References",
    "section": "",
    "text": "[1] Klosterman, S.\n(2021). Data\nscience projects with python: A case study approach to gaining valuable\ninsights from real data with machine learning. Packt\nPublishing, Limited.\n\n\n[2] McKinney, W.\n(2017). Python for data analysis: Data wrangling with pandas, NumPy,\nand IPython. O’Reilly Media.\n\n\n[3] Shaw, Z. A.\n(2017). Learn\npython 3 the hard way. Addison Wesley.\n\n\n[4] Sweigart, A.\n(2020). Automate the\nboring stuff with python, 2nd edition practical programming for total\nbeginners: Practical programming for total beginners. No Starch\nPress.\n\n\n[5] Prabhakaran, S.\n(2018). 101\nNumPy exercises for data analysis (python).\n\n\n[6] Prabhakaran, S.\n(2018). 101\npandas exercises for data analysis.\n\n\n[7] Youens-Clark, K.\n(2020). Tiny python\nprojects. Manning Publications."
  },
  {
    "objectID": "contents/app/setup.html",
    "href": "contents/app/setup.html",
    "title": "Appendix A — Setup",
    "section": "",
    "text": "Note that all the following steps are tested in Windows 10/11. If you use other operation systems please contact me.\n\nGo to Anaconda download page. Download and install Anaconda.\nGo to VS Code download page. Download and install VS Code. Actually Anaconda contains one copy of VS Code. Here I just assume that some of you intall VS Code before Anaconda.\nWhen installing VS Code, you may accept all default settings. When installing Anaconda, please pay attention to the PATH setting.\n\n\n\n\n\n\nThe first box is unchecked by default. This setting is related to the ability to easily run Python code in Terminals. I recommend you to check it. If you don’t check it during this step, you may add it to the system environment variable PATH manually later.\n\nThe UI of VS Code looks as follows.\n\n\n\n\n\n\nPlease look at the fifth tab from the left sidebar. It is the Extension tab.\n\n\n\n\n\nPlease search for python and install the first Python extension from Microsoft. It will actually install five extensions. These are all we need for now.\n\nAfter all are installed, go to the first Explorer tab on the left side bar, and Open Folder. This is the working directory for your project.\n\n\n\n\n\n\nChoose one folder and start a new .py file.\n\n\n\n\n\n\nIf everything is setup correctly, you may see the Python version and environment name at the right lower corner. In our case the environment name is base. We will need it in the future.\n\n\n\n\n\n\nNote that we are not looking at the Python for Language Mode. If you see Select Interpreter there, it means that VS Code doesn’t find your Python interpreter. Please restart VS Code or select it manually, or check whether Anaconda is installed correctly.\n\n\n\n\n\nTo check whether everything is setup correctly, please run the following tests.\n\nUse ctrl+shift+p to open the Command Palette, type “Jupyter: Create Interactive Window” and press enter to open the Jupyter interactive window.\n\n\n\n\n\n\nIf the interactive window starts and you see the loading infomation of your kernel as follows, especially you see the environment name on the right upper corner, then you get everything correctly. However we will still do more tests.\n\n\n\n\n\n\nIn the window type import numpy as np to test whether you are able to import packages. If you don’t see any error messages then it means good.\n\n\n\n\n\n\n\nIn the editor window, type import numpy as np and right click the body to choose Run Current File in Interactive Window, and see whether it runs in interactive window.\n\n\n\n\n\n\n\nOpen the terminal. Please use Command Prompt instead of Powershell. Activate the conda environment by type the command conda activate base in the example above. Please change the name to match your own environment. If conda cannot be recognized, please register Python and Anaconda to the system environment path. Please see the next Appendix for details."
  },
  {
    "objectID": "contents/app/setup.html#sec-googlecolab",
    "href": "contents/app/setup.html#sec-googlecolab",
    "title": "Appendix A — Setup",
    "section": "A.2 Google Colab",
    "text": "A.2 Google Colab\nGoogle Colab is a product from Google Research, that allows anybody to write and execute arbitrary Python code through the browser, and is especially well suited to machine learning, data analysis and education.\nHere is the link to Google Colab. To use it you should have a Google account. Otherwise it is very simple to start, since a lot of packages for our course are already installed.\n\nA.2.1 Install packages\nIf you would like to install more packages, you can type %pip install + package name in a code cell and execute it.\nThe drawback here is that Google Colab can only stay for 24 hours. After that, all additionaly installed packages will be earsed. However you can put %pip install + package name at the beginning of your notebook and these packages will be installed every time you run the notebook.\n\n\nA.2.2 Upload files\nYou may directly upload files to the working directory of Google Colab. This has to be done in the browser. When working with these files, you may just use relative paths.\nThe drawback here is that Google Colab can only stay for 24 hours. After that, although your .ipynb files will be stores, all other files will be earsed.\n\n\nA.2.3 Mount Google Drive\nOne way to let the uploaded files stay in cloud is to upload them to Google Drive, and then load your Google Drive contents from Google Colab.\nGoole Drive is a cloud storage service provided by Google. When you register a Google account you will be automatically assigned a Google Drive account. You may get access to it from this link.\nHere are the steps to mount Google Drive:\n\nUpload your files to your Google Drive.\nRun the following codes in Colab code cells before you are loading the uploaded files:\n\n\nfrom google.colab import drive\ndrive.mount('/content/gdrive')\n\n\nA window pop up asking you about the permission. Authorize and the drive is mounted.\nTo work in directories, the most popular commands are\n\n%ls: list all files and folders in the working directory.\n%cd + folder name: Get into a specific folder.\n%cd..: Get into the parent folder. Then use these commands to find the files your just uploaded.\n\nFinally you may directly get access to those files just like they are in the working directory."
  },
  {
    "objectID": "contents/app/path.html",
    "href": "contents/app/path.html",
    "title": "Appendix B — PATH",
    "section": "",
    "text": "First in the start menu search for Edit the system environment variables.\n\n\n\n\n\n\n\nThen click the Environment Variables... button at the right lower corner.\n\n\n\n\n\n\n\nFind the Path variable in either the upper window or the lower window. Use which one depends on whether you want to register the variable for the user or for the machine. In this example I add for the user.\n\n\n\n\n\n\n\nFinally double click the variable and add the following path to it. You need to make changes according to your installation. I recommend you to locate your Anaconda installation first to get the path."
  }
]