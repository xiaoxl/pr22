[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Python/R for Data Science",
    "section": "",
    "text": "This is the lecture notes for STAT 2304 Programming languages for Data Science 2022 Fall at ATU. If you have any comments/suggetions/concers about the notes please contact me at my email xxiao@atu.edu."
  },
  {
    "objectID": "contents/1/01-.html#hello-world",
    "href": "contents/1/01-.html#hello-world",
    "title": "1  Preliminaries",
    "section": "1.2 Hello world!",
    "text": "1.2 Hello world!\n\n\n1.2.1 Setup the Python environment\nIn this section we are going to setup the Python developing environment.\n\n1.2.1.1 VS Code + Anaconda\nClick Appendix A.1 to see the detailed steps for VS Code and Anaconda. You may also check out the official document. It contains more features but less details.\nWe will talk about the relation between Python and Anaconda and more about packages sometime later.\n\n\n1.2.1.2 Google Colab\nClick Appendix A.2 for more details.\n\n\n\n1.2.2 Hello World!\n\nTake VS Code as an example. In the editor window, type in the code, and run the file in the interactive window.\n\nprint('Hello World!')\n\n\n\n\n\n\nIf you see a small green check mark in the interactive window and also the output Hello World!, you are good to go!\n\n\n1.2.3 Python code cells and Notebooks\nIn VS Code you can run codes cell by cell. Each cell is separated by the symbol # %%. Each cell may contain multiple lines. You may click the small button on top of the cell or use keybindings.\n\n\n\n\n\nThis feature actually mimic the notebook. We may start a real Python Notebook file by directly creating a file with extension .ipynb.\n\n\n\n\n\nThe layout is straightforward.\n\n\n1.2.4 Linters\n\n\n\n\n1.2.5 IPython and Jupyter"
  },
  {
    "objectID": "contents/1/01-.html#projects",
    "href": "contents/1/01-.html#projects",
    "title": "1  Preliminaries",
    "section": "1.3 Projects",
    "text": "1.3 Projects\n\nExercise 1.1 (Hello world!) Please set up a Python developing environment, including for .py file and for notebook, that will be used across the semester. Then print Hello World!.\n\n\nExercise 1.2 (Define a function and play with time) Please play with the following codes in a Jupyter notebook. We haven’t talked about any of them right now. Try to guess what they do and write your guess in markdown cells.\n\nimport time\n\ndef multistr(x, n=2):\n    return x * n\n\nt0 = time.time()\nx = 'Python'\nprint(multistr(x, n=10))\nt1 = time.time()\nprint(\"Time used: \", t1-t0)\n\n\n\nExercise 1.3 (Fancy Basketball plot) Here is an example of the data analysis. We pull data from a dataset, filter the data according to our needs and plot it to visualize the data. This is just a show case. You are encouraged to play the code, make tweaks and see what would happen. You don’t have to turn in anything.\nThe data we choose is Stephen Curry’s shots data in 2021-2022 regular season. First we need to load the data. The data is obtained from nba.com using nba_api.\n\nfrom nba_api.stats.static import players\nfrom nba_api.stats.endpoints import shotchartdetail\nplayer_dict = players.get_players()\n\nThe shots data we need is in shotchartdetail. However to use it we need to know the id of Stephen Curry using the dataset player_dict.\n\nfor player in player_dict:\n    if player['full_name'] == 'Stephen Curry':\n        print(player['id'])\n\n201939\n\n\nSo the id of Stephen Curry is 201939. Let’s pull out his shots data in 2021-2022 season.\n\nresults = shotchartdetail.ShotChartDetail(\n            team_id = 0,\n            player_id = 201939,\n            context_measure_simple = 'FGA',\n            season_nullable = '2021-22',\n            season_type_all_star = 'Regular Season')\ndf = results.get_data_frames()[0]\ndf.head()\n\n\n\n\n\n  \n    \n      \n      GRID_TYPE\n      GAME_ID\n      GAME_EVENT_ID\n      PLAYER_ID\n      PLAYER_NAME\n      TEAM_ID\n      TEAM_NAME\n      PERIOD\n      MINUTES_REMAINING\n      SECONDS_REMAINING\n      ...\n      SHOT_ZONE_AREA\n      SHOT_ZONE_RANGE\n      SHOT_DISTANCE\n      LOC_X\n      LOC_Y\n      SHOT_ATTEMPTED_FLAG\n      SHOT_MADE_FLAG\n      GAME_DATE\n      HTM\n      VTM\n    \n  \n  \n    \n      0\n      Shot Chart Detail\n      0022100002\n      26\n      201939\n      Stephen Curry\n      1610612744\n      Golden State Warriors\n      1\n      10\n      9\n      ...\n      Left Side Center(LC)\n      24+ ft.\n      28\n      -109\n      260\n      1\n      0\n      20211019\n      LAL\n      GSW\n    \n    \n      1\n      Shot Chart Detail\n      0022100002\n      34\n      201939\n      Stephen Curry\n      1610612744\n      Golden State Warriors\n      1\n      9\n      41\n      ...\n      Center(C)\n      24+ ft.\n      26\n      48\n      257\n      1\n      0\n      20211019\n      LAL\n      GSW\n    \n    \n      2\n      Shot Chart Detail\n      0022100002\n      37\n      201939\n      Stephen Curry\n      1610612744\n      Golden State Warriors\n      1\n      9\n      10\n      ...\n      Left Side Center(LC)\n      24+ ft.\n      25\n      -165\n      189\n      1\n      1\n      20211019\n      LAL\n      GSW\n    \n    \n      3\n      Shot Chart Detail\n      0022100002\n      75\n      201939\n      Stephen Curry\n      1610612744\n      Golden State Warriors\n      1\n      6\n      17\n      ...\n      Center(C)\n      Less Than 8 ft.\n      1\n      -13\n      12\n      1\n      0\n      20211019\n      LAL\n      GSW\n    \n    \n      4\n      Shot Chart Detail\n      0022100002\n      130\n      201939\n      Stephen Curry\n      1610612744\n      Golden State Warriors\n      1\n      3\n      11\n      ...\n      Center(C)\n      Less Than 8 ft.\n      2\n      -15\n      22\n      1\n      0\n      20211019\n      LAL\n      GSW\n    \n  \n\n5 rows × 24 columns\n\n\n\ndf is the results we get in terms of a DataFrame, and we show the first 5 records as an example.\nThese are all attempts. We are interested in all made. By looking at all the columns, we find a column called SHOT_MADE_FLAG which shows what we want. Therefore we will use it to filter the records.\n\ndf_made = df[df['SHOT_MADE_FLAG']==1]\ndf_made.head()\n\n\n\n\n\n  \n    \n      \n      GRID_TYPE\n      GAME_ID\n      GAME_EVENT_ID\n      PLAYER_ID\n      PLAYER_NAME\n      TEAM_ID\n      TEAM_NAME\n      PERIOD\n      MINUTES_REMAINING\n      SECONDS_REMAINING\n      ...\n      SHOT_ZONE_AREA\n      SHOT_ZONE_RANGE\n      SHOT_DISTANCE\n      LOC_X\n      LOC_Y\n      SHOT_ATTEMPTED_FLAG\n      SHOT_MADE_FLAG\n      GAME_DATE\n      HTM\n      VTM\n    \n  \n  \n    \n      2\n      Shot Chart Detail\n      0022100002\n      37\n      201939\n      Stephen Curry\n      1610612744\n      Golden State Warriors\n      1\n      9\n      10\n      ...\n      Left Side Center(LC)\n      24+ ft.\n      25\n      -165\n      189\n      1\n      1\n      20211019\n      LAL\n      GSW\n    \n    \n      6\n      Shot Chart Detail\n      0022100002\n      176\n      201939\n      Stephen Curry\n      1610612744\n      Golden State Warriors\n      1\n      0\n      27\n      ...\n      Center(C)\n      Less Than 8 ft.\n      2\n      -7\n      29\n      1\n      1\n      20211019\n      LAL\n      GSW\n    \n    \n      9\n      Shot Chart Detail\n      0022100002\n      352\n      201939\n      Stephen Curry\n      1610612744\n      Golden State Warriors\n      2\n      1\n      29\n      ...\n      Center(C)\n      Less Than 8 ft.\n      1\n      -1\n      10\n      1\n      1\n      20211019\n      LAL\n      GSW\n    \n    \n      16\n      Shot Chart Detail\n      0022100002\n      510\n      201939\n      Stephen Curry\n      1610612744\n      Golden State Warriors\n      3\n      2\n      23\n      ...\n      Center(C)\n      Less Than 8 ft.\n      1\n      7\n      8\n      1\n      1\n      20211019\n      LAL\n      GSW\n    \n    \n      18\n      Shot Chart Detail\n      0022100002\n      642\n      201939\n      Stephen Curry\n      1610612744\n      Golden State Warriors\n      4\n      5\n      34\n      ...\n      Center(C)\n      24+ ft.\n      26\n      48\n      260\n      1\n      1\n      20211019\n      LAL\n      GSW\n    \n  \n\n5 rows × 24 columns\n\n\n\nWe also notice that there are two columns LOC_X and LOC_Y shows the coordinates of the attempts. We will use it to draw the heatmap. The full code for drawing out the court draw_court is folded below. It is from Bradley Fay GitHub.\n\n\n\n\n\n\nNote\n\n\n\nNote that, although draw_cort is long, it is not hard to understand. It just draws a court piece by piece.\n\n\n\n\nCode\nfrom matplotlib.patches import Circle, Rectangle, Arc\nimport matplotlib.pyplot as plt\n\n\ndef draw_court(ax=None, color='gray', lw=1, outer_lines=False):\n    \"\"\"\n    Returns an axes with a basketball court drawn onto to it.\n\n    This function draws a court based on the x and y-axis values that the NBA\n    stats API provides for the shot chart data.  For example, the NBA stat API\n    represents the center of the hoop at the (0,0) coordinate.  Twenty-two feet\n    from the left of the center of the hoop in is represented by the (-220,0)\n    coordinates.  So one foot equals +/-10 units on the x and y-axis.\n    \"\"\"\n    if ax is None:\n        ax = plt.gca()\n\n    # Create the various parts of an NBA basketball court\n\n    # Create the basketball hoop\n    hoop = Circle((0, 0), radius=7.5, linewidth=lw, color=color, fill=False)\n\n    # Create backboard\n    backboard = Rectangle((-30, -7.5), 60, -1, linewidth=lw, color=color)\n\n    # The paint\n    # Create the outer box 0f the paint, width=16ft, height=19ft\n    outer_box = Rectangle((-80, -47.5), 160, 190, linewidth=lw, color=color,\n                          fill=False)\n    # Create the inner box of the paint, widt=12ft, height=19ft\n    inner_box = Rectangle((-60, -47.5), 120, 190, linewidth=lw, color=color,\n                          fill=False)\n\n    # Create free throw top arc\n    top_free_throw = Arc((0, 142.5), 120, 120, theta1=0, theta2=180,\n                         linewidth=lw, color=color, fill=False)\n    # Create free throw bottom arc\n    bottom_free_throw = Arc((0, 142.5), 120, 120, theta1=180, theta2=0,\n                            linewidth=lw, color=color, linestyle='dashed')\n    # Restricted Zone, it is an arc with 4ft radius from center of the hoop\n    restricted = Arc((0, 0), 80, 80, theta1=0, theta2=180, linewidth=lw,\n                     color=color)\n\n    # Three point line\n    # Create the right side 3pt lines, it's 14ft long before it arcs\n    corner_three_a = Rectangle((-220, -47.5), 0, 140, linewidth=lw,\n                               color=color)\n    # Create the right side 3pt lines, it's 14ft long before it arcs\n    corner_three_b = Rectangle((220, -47.5), 0, 140, linewidth=lw, color=color)\n    # 3pt arc - center of arc will be the hoop, arc is 23'9\" away from hoop\n    three_arc = Arc((0, 0), 475, 475, theta1=22, theta2=158, linewidth=lw,\n                    color=color)\n\n    # Center Court\n    center_outer_arc = Arc((0, 422.5), 120, 120, theta1=180, theta2=0,\n                           linewidth=lw, color=color)\n    center_inner_arc = Arc((0, 422.5), 40, 40, theta1=180, theta2=0,\n                           linewidth=lw, color=color)\n\n    # List of the court elements to be plotted onto the axes\n    court_elements = [hoop, backboard, outer_box, inner_box, top_free_throw,\n                      bottom_free_throw, restricted, corner_three_a,\n                      corner_three_b, three_arc, center_outer_arc,\n                      center_inner_arc]\n\n    if outer_lines:\n        # Draw the half court line, baseline and side out bound lines\n        outer_lines = Rectangle((-250, -47.5), 500, 470, linewidth=lw,\n                                color=color, fill=False)\n        court_elements.append(outer_lines)\n\n    # Add the court elements onto the axes\n    for element in court_elements:\n        ax.add_patch(element)\n\n    return ax\n\n\n\n# Create figure and axes\nfig = plt.figure(figsize=(6, 6))\nax = fig.add_axes([0, 0, 1, 1])\n\n# Plot hexbin of shots\nax.hexbin(df['LOC_X'], df['LOC_Y'], gridsize=(30, 30), extent=(-300, 300, 0, 940), bins='log', cmap='Blues')\nax = draw_court(ax, 'black')\n\n# Annotate player name and season\nax.text(0, 1.05, 'Stephen Curry\\n2021-22 Regular Season', transform=ax.transAxes, ha='left', va='baseline')\n\n# Set axis limits\n_ = ax.set_xlim(-250, 250)\n_ = ax.set_ylim(0, 400)\n\n\n\n\n\n\n\nClick for Hint.\n\n\n\nSolution (Hint). \nfrom nba_api.stats.static import players\nfrom nba_api.stats.endpoints import shotchartdetail\nplayer_dict = players.get_players()\n\nThese lines import some packages and get player information and save them into player_dict.\n\nfor player in player_dict:\n    if player['full_name'] == 'Stephen Curry':\n        print(player['id'])\n\nGo through all records in player_dict. If the name of a player is Stephen Curry, get his id. Then we will know the id of Stephen Curry.\nTo be omitted."
  },
  {
    "objectID": "contents/2/02-.html",
    "href": "contents/2/02-.html",
    "title": "2  Python Basics",
    "section": "",
    "text": "This section is based on [1].\nThere are several built-in data structures in Python. Here is an (incomplete) list:\n\nNone\nBoolean – True, False\nNumeric Types — int, float, complex\nText Sequence Type — str\nSequence Types — list\nMap type - dict\n\nWe will cover numeric types and strings in this section. The rests are either simple that are self-explained, or not simple that will be discussed later.\n\n\nNumeric types are represented by numbers. If there are no confusions, Python will automatically detect the type.\n\nx = 1 # x is an int.\ny = 2.0 # y is a float.\n\nPython can do math just like other programming languages. The basic math operations are listed as follows.\n\n+, -, *, /, >, <, >=, <= works as normal.\n** is the power operation.\n% is the mod operation.\n!= is not equal\n\n\n\n\nScalars are represented by numbers and strings are represented by quotes. Example:\n\nx = 1       # x is a scalar.\ny = 's'     # y is a string with one letter.\nz = '0'     # z loos like a number, but it is a string.\nw = \"Hello\" # w is a string with double quotes.\n\nHere are some facts.\n\nFor strings, you can use either single quotes ' or double quotes \".\n\\ is used to denote escaped words. You may find the list Here.\nThere are several types of scalars, like int, float, etc.. Usually Python will automatically determine the type of the data, but sometimes you may still want to declare them manually.\nYou can use int(), str(), etc. to change types.\n\nAlthough str is a built-in type, there are tons of tricks with str, and there are tons of packages related to strings. Generally speaking, to play with strings, we are interested in two types of questions.\n\nPut information together to form a string.\nExtract information from a string. We briefly talk about these two tasks.\n\n\n\n\n\n\n\nNote\n\n\n\nThere is a very subtle relations between the variable / constant and the name of the variable / constant. We will talk about these later.\n\n\n\nExample 2.1 Here is an example of playing with strings. Please play with these codes and try to understand what they do.\n\nimport re\n\ndef clean_strings(strings):\n    result = []\n    for value in strings:\n        value = value.strip()\n        value = re.sub('[!#?]', '', value)\n        value = value.title()\n        result.append(value)\n    return result\n\nstates = [' Alabama ', 'Georgia!', 'Georgia', 'georgia', 'FlOrIda',\n          'south carolina##', 'West virginia?']\nprint(clean_strings(states))\n\n['Alabama', 'Georgia', 'Georgia', 'Georgia', 'Florida', 'South Carolina', 'West Virginia']"
  },
  {
    "objectID": "contents/2/02-.html#fundamentals",
    "href": "contents/2/02-.html#fundamentals",
    "title": "2  Python Basics",
    "section": "2.2 Fundamentals",
    "text": "2.2 Fundamentals\nThis section is mainly based on [2].\n\n2.2.1 Indentation\nOne key feature about Python is that its structures (blocks) is determined by Indentation.\nLet’s compare with other languages. Let’s take C as an example.\n\n/*This is a C function.*/\nint f(int x){return x;}\n\nThe block is defined by {} and lines are separated by ;. space and newline are not important when C runs the code. It is recommended to write codes in a “beautiful, stylish” format for readibility, as follows. However it is not mandatary.\n\n/*This is a C function.*/\nint f(int x) {\n   return x;\n}\n\nIn Python, blocks starts from : and then are determined by indents. Therefore you won’t see a lot of {} in Python, and the “beautiful, stylish” format is mandatary.\n\n# This is a Python function.\ndef f(x):\n    return x\n\nThe default value for indentation is 4 spaces, which can be changed by users. We will just use the default value in this course.\n\n\n\n\n\n\nNote\n\n\n\nIt is usually recommended that one line of code should not be very long. If you do have one, and it cannot be shortened, you may break it into multiline codes directly in Python. However, since indentation is super important in Python, when break one line code into multilines, please make sure that everything is aligned perfectly. Please see the following example.\n\nresults = shotchartdetail.ShotChartDetail(\n            team_id = 0,\n            player_id = 201939,\n            context_measure_simple = 'FGA',\n            season_nullable = '2021-22',\n            season_type_all_star = 'Regular Season')\n\n\n\n\n\n2.2.2 Binary operators and comparisons\nMost binary operators behaves as you expected. Here I just want to mention == and is.\n\n== is testing whehter these two objects have the same value.\nis is testing whether these two objects are exactly the same.\n\n\n\n\n\n\n\nNote\n\n\n\nYou may use id(x) to check the id of the object x. Two objects are identical if they have the same id.\n\n\n\n\n\n2.2.3 import\nIn Python a module is simply a file with the .py extension containing Python code. Assume that we have a Python file example.py stored in the folder assests/codes/. The file is as follows.\n\n# from assests/codes/example.py\n\ndef f(x):\n    print(x)\n\nA = 'You get me!'\n\nYou may get access to this function and this string in the following way.\n\nfrom assests.codes import example\n\nexample.f(example.A)\n\nYou get me!\n\n\n\n\n2.2.4 Comments\nAny text preceded by the hash mark (pound sign) # is ignored by the Python interpreter. In many IDEs you may use hotkeys to directly toggle multilines as comments. For example, in VS Code the default setting for toggling comments is ctrl+/.\n\n\n2.2.5 Dynamic references, strong types\nIn some programming languages, you have to declare the variable’s name and what type of data it will hold. If a variable is declared to be a number, it can never hold a different type of value, like a string. This is called static typing because the type of the variable can never change.\nPython is a dynamically typed language, which means you do not have to declare a variable or what kind of data the variable will hold. You can change the value and type of data at any time. This could be either great or terrible news.\nOn the other side, “dynamic typed” doesn’t mean that types are not important in Python. You still have to make sure that the types of all variables meet the requirements of the operations used.\n\na = 1\nb = 2\nb = '2'\nc = a + b\n\nTypeError: unsupported operand type(s) for +: 'int' and 'str'\n\n\nIn this example, b was first assigned by a number, and then it was reassigned by a str. This is totally fine since Python is dynamically types. However later when adding a and b, the type error occurs since you cannot add a number and a str.\n\n\n\n\n\n\nNote\n\n\n\nYou may always use type(x) to detect the type of the object x.\n\n\n\n\n2.2.6 Everything is an object\nEvery number, string, data structure, function, class, module, and so on exists in the Python interpreter in its own “box”, which is referred to as a Python object.\nEach object has an associated type (e.g., string or function) and internal data. In practice this makes the language very flexible, as even functions can be treated like any other object.\nEach object might have attributes and/or methods attached.\n\n\n2.2.7 Mutable and immutable objects\nAn object whose internal state can be changed is mutable. On the other hand, immutable doesn’t allow any change in the object once it has been created.\nSome objects of built-in type that are mutable are:\n\nLists\nDictionaries\nSets\n\nSome objects of built-in type that are immutable are:\n\nNumbers (Integer, Rational, Float, Decimal, Complex & Booleans)\nStrings\nTuples\n\n\nExample 2.2 (Tuples are not really “immutable”) You can treat a tuple as a container, which contains some objects. The relations between the container and its contents are immutable, but the objects it holds might be mutable. Please check the following example.\n\ncontainer = ([1], [2])\nprint('This is `container`: ', container)\nprint('This is the id of `container`: ', id(container))\nprint('This is the id of the first list of `container`: ', id(container[0]))\n\ncontainer[0].append(2)\nprint('This is the new `container`: ', container)\nprint('This is the id of the new `container`: ', id(container))\nprint('This is the id of the first list (which is updated) of the new `container`: ', id(container[0]))\n\nThis is `container`:  ([1], [2])\nThis is the id of `container`:  2311945167296\nThis is the id of the first list of `container`:  2311944999744\nThis is the new `container`:  ([1, 2], [2])\nThis is the id of the new `container`:  2311945167296\nThis is the id of the first list (which is updated) of the new `container`:  2311944999744\n\n\nYou can see that the tuple container and its first object stay the same, although we add one element to the first object."
  },
  {
    "objectID": "contents/2/02-.html#flows-and-logic",
    "href": "contents/2/02-.html#flows-and-logic",
    "title": "2  Python Basics",
    "section": "2.3 Flows and Logic",
    "text": "2.3 Flows and Logic\n\n2.3.1 for loop\n\nrange(10)\nlist\n\n\n\n2.3.2 if conditional control"
  },
  {
    "objectID": "contents/2/02-.html#list",
    "href": "contents/2/02-.html#list",
    "title": "2  Python Basics",
    "section": "2.4 list",
    "text": "2.4 list\n\n\n\n\n\n\nNote\n\n\n\nIn Python, a list is an ordered sequence of object types and a string is an ordered sequence of characters.\n\n\n\nAccess to the data\nSlicing\nMethods\n\nappend and +\nextend\npop\nremove\n\nin\nfor\nlist()\nsorted\nstr.split\nstr.join\n\n\n2.4.1 List Comprehension\nList Comprehension is a convenient way to create lists based on the values of an existing list. It cannot provide any real improvement to the performance of the codes, but it can make the codes shorter and easier to read.\nThe format of list Comprehension is\nnewlist = [expression for item in iterable if condition == True]"
  },
  {
    "objectID": "contents/2/02-.html#dict",
    "href": "contents/2/02-.html#dict",
    "title": "2  Python Basics",
    "section": "2.5 dict",
    "text": "2.5 dict\n\nAccess to the data\nMethods\n\ndirectly add items\nupdate\nget\nkeys\nvalues\nitems\n\ndict()\ndictionary comprehension"
  },
  {
    "objectID": "contents/2/02-.html#exercises",
    "href": "contents/2/02-.html#exercises",
    "title": "2  Python Basics",
    "section": "2.6 Exercises",
    "text": "2.6 Exercises\nMost problems are based on [3], [1] and [4].\n\nExercise 2.1 (Indentation) Please tell the differences between the following codes. If you don’t understand for don’t worry about it. Just focus on the indentation and try to understand how the codes work.\n\nfor i in range(5):\n    print('Hello world!')\nprint('Hello world!')\n\n\nfor i in range(5):\n    print('Hello world!')\n    print('Hello world!')\n\n\nfor i in range(5):\nprint('Hello world!')\nprint('Hello world!')\n\n\nfor i in range(5):\n    pass\nprint('Hello world!')\nprint('Hello world!')\n\n\n\nExercise 2.2 (Play with built-in data types) Please first guess the results of all expressions below, and then run them to check your answers.\n\nprint(True and True)\nprint(True or True)\nprint(False and True)\nprint((1+1>2) or (1-1<1))\n\n\n\nExercise 2.3 (== vs is) Please explain what happens below.\n\na = 1\nb = 1.0\nprint(type(a))\nprint(type(b))\n\nprint(a == b)\nprint(a is b)\n\n<class 'int'>\n<class 'float'>\nTrue\nFalse\n\n\n\n\nExercise 2.4 (Play with strings) Please excute the code below line by line and explain what happens in text cells.\n\n# 1\nanswer = 10\nwronganswer = 11\ntext1 = \"The answer to this question is {}. If you got {}, you are wrong.\".format(answer, wronganswer)\nprint(text1)\n\n# 2\nvar = True\ntext2 = \"This is {}.\".format(var)\nprint(text2)\n\n# 3\nword1 = 'Good '\nword2 = 'buy. '\ntext3 = (word1 + word2) * 3\nprint(text3)\n\n# 4\nsentence = \"This is\\ngood enough\\nfor a exercise to\\nhave so many parts. \" \\\n           \"We would also want to try this symbol: '. \" \\\n           \"Do you know how to type \\\" in double quotes?\"\nprint(sentence)\n\nThe answer to this question is 10. If you got 11, you are wrong.\nThis is True.\nGood buy. Good buy. Good buy. \nThis is\ngood enough\nfor a exercise to\nhave so many parts. We would also want to try this symbol: '. Do you know how to type \" in double quotes?\n\n\n\n\nExercise 2.5 (split and join) Please excute the code below line by line and explain what happens in text cells.\n\nsentence = 'This is an example of a sentence that I expect you to split.'\n\nwordlist = sentence.split(' ')\n\nnewsentence = '\\n'.join(wordlist)\nprint(newsentence)\n\n\n\nExercise 2.6 (List reference) Please finish the following tasks.\n\nGiven the list a, make a new reference b to a. Update the first entry in b to be 0. What happened to the first entry in a? Explain your answer in a text block.\nGiven the list a, make a new copy b of the list a using the function list. Update the first entry in b to be 0. What happened to the first entry in a? Explain your answer in a text block.\n\n\n\nExercise 2.7 (List comprehension) Given a list of numbers, use list comprehension to remove all odd numbers from the list:\n\nnumbers = [3,5,45,97,32,22,10,19,39,43]\n\n\n\nExercise 2.8 (More list comprehension) Use list comprehension to find all of the numbers from 1-1000 that are divisible by 7.\n\n\nExercise 2.9 (More list comprehension) Count the number of spaces in a string.\n\n\nExercise 2.10 (More list comprehension) Use list comprehension to get the index and the value as a tuple for items in the list ['hi', 4, 8.99, 'apple', ('t,b', 'n')]. Result would look like [(index, value), (index, value), ...].\n\n\nExercise 2.11 (More list comprehension) Use list comprehension to find the common numbers in two lists (without using a tuple or set) list_a = [1, 2, 3, 4], list_b = [2, 3, 4, 5].\n\n\nExercise 2.12 (Probability) Compute the probability that two people out of 23 share the same birthday. The math formula for this is \\[1-\\frac{365!/(365-23)!}{365^{23}}=1-\\frac{365}{365}\\cdot\\frac{365-1}{365}\\cdot\\frac{365-2}{365}\\cdot\\ldots\\cdot\\frac{365-22}{365}.\\]\n\nTo directly use the formula we have to use a high performance math package, e.g. math. Please use math.factorial to compute the above formula.\nPlease use the right hand side of the above formula to compute the probability using the following steps.\n\nPlease use the list comprehension to create a list \\(\\left[\\frac{365}{365},\\frac{365-1}{365},\\frac{365-2}{365},\\ldots,\\frac{365-22}{365}\\right]\\).\nUse numpy.prod to compute the product of elements of the above list.\nCompute the probability by finishing the formula.\n\nPlease use time to test which method mentioned above is faster."
  },
  {
    "objectID": "contents/2/02-.html#projects",
    "href": "contents/2/02-.html#projects",
    "title": "2  Python Basics",
    "section": "2.7 Projects",
    "text": "2.7 Projects\nMost projects are based on [2], [5].\n\nExercise 2.13 (Determine the indefinite article) Please finish the following tasks.\n\nPlease construct a list aeiou that contains all vowels.\nGiven a word word, we would like to find the indefinite article article before word. (Hint: the article should be an if the first character of word is a vowel, and a if not.)\n\n\n\n\nClick for Hint.\n\n\nSolution. Consider in, .lower() and if structure.\n\n\n\nExercise 2.14 (Datetime and files names) We would like to write a program to quickly generate N files. Every time we run the code, N files will be generated. We hope to store all files generated and organize them in a neat way. To achieve this, one way is to create a subfolder for each run and store all files generated during that run in the particular subfolder. Since we would like to make it fast, the real point of this task is to find a way to automatically generate the file names for the files generated and the folder names for the subfolders generated. You don’t need to worry about the contents of the files and empty files are totally fine for this problem.\n\n\n\nClick for Hint.\n\n\nSolution. One way to automatically generate file names and folder names is to use the date and the time when the code is run. Please check datetime package for getting and formatting date/time, and os packages for playing with files and folders.\n\n\n\nExercise 2.15 (Color the Gnomic data) We can use ASCII color codes in the string to change the color of strings, as an example \\033[91m for red and \\033[94m for blue. See the following example.\n\nprint('\\033[91m'+'red'+'\\033[92m'+'green'+'\\033[94m'+'blue'+'\\033[93m'+'yellow')\n\nConsider an (incomplete) Gnomic data given below which is represented by a long sequence of A, C, T and G. Please color it using ASCII color codes.\n\nGnomicdata = 'TCGATCTCTTGTAGATCTGTTCTCTAAACGAACTTTAAAATCTGTGTGGCTGTCACTCGG'\\\n             'CTGCATGCTTAGTGCACTCACGCAGTATAATTAATAACTAATTACTGTCGTTGACAGGAC'\\\n             'ACGAGTAACTCGTCTATCTTCTGCAGGCTGCTTACGGTTTCGTCCGTGTTGCAGCCGATC'\\\n             'ATCAGCACATCTAGGTTTTGTCCGGGTGTGACCGAAAGGTAAGATGGAGAGCCTTGTCCC'\\\n             'TGGTTTCAACGAGAAAACACACGTCCAACTCAGTTTGCCTGTTTTACAGGTTCGCGACGT'\\\n             'GCTCGTACGTGGCTTTGGAGACTCCGTGGAGGAGGTCTTATCAGAGGCACGTCAACATCT'\\\n             'TAAAGATGGCACTTGTGGCTTAGTAGAAGTTGAAAAAGGCGTTTTGCCTCAACTTGAACA'\\\n             'GCCCTATGTGTTCATCAAACGTTCGGATGCTCGAACTGCACCTCATGGTCATGTTATGGT'\\\n             'TGAGCTGGTAGCAGAACTCGAAGGCATTCAGTACGGTCGTAGTGGTGAGACACTTGGTGT'\\\n             'CCTTGTCCCTCATGTGGGCGAAATACCAGTGGCTTACCGCAAGGTTCTTCTTCGTAAGAA'\\\n             'CGGTAATAAAGGAGCTGGTGGCCATAGTTACGGCGCCGATCTAAAGTCATTTGACTTAGG'\\\n             'CGACGAGCTTGGCACTGATCCTTATGAAGATTTTCAAGAAAACTGGAACACTAAACATAG'\n\n\n\n\nClick for Hint.\n\n\nSolution (Hint). You may use if to do the conversion. Or you may use dict to do the conversion.\n\n\n\nExercise 2.16 (sorted) Please read through the Key funtions in this article, and sort the following two lists.\n\nSort list1 = [[11,2,3], [2, 3, 1], [5,-1, 2], [2, 3,-8]] according to the sum of each list.\nSort list2 = [{'a': 1, 'b': 2}, {'a': 3, 'b': 4},{'a': 5, 'b': 2}] according to the b value of each dictionary.\n\n\n\nExercise 2.17 (Fantasy Game Inventory) You are creating a fantasy video game. The data structure to model the player’s inventory will be a dictionary where the keys are string values describing the item in the inventory and the value is an integer value detailing how many of that item the player has. For example, the dictionary value {'rope': 1, 'torch': 6, 'gold coin': 42, 'dagger': 1, 'arrow': 12} means the player has 1 rope, 6 torches, 42 gold coins, and so on.\nWrite a program to take any possible inventory and display it like the following:\n\nInventory:\n12 arrow\n42 gold coin\n1 rope\n6 torch\n1 dagger\nTotal number of items: 62\n\n\n\n\n\n\n[1] Youens-Clark, K. (2020). Tiny python projects. Manning Publications.\n\n\n[2] McKinney, W. (2017). Python for data analysis: Data wrangling with pandas, NumPy, and IPython. O’Reilly Media.\n\n\n[3] Shaw, Z. A. (2017). Learn python 3 the hard way. Addison Wesley.\n\n\n[4] Sweigart, A. (2020). Automate the boring stuff with python, 2nd edition practical programming for total beginners: Practical programming for total beginners. No Starch Press.\n\n\n[5] Klosterman, S. (2021). Data science projects with python: A case study approach to gaining valuable insights from real data with machine learning. Packt Publishing, Limited."
  },
  {
    "objectID": "contents/3/03-.html",
    "href": "contents/3/03-.html",
    "title": "3  Package: numpy",
    "section": "",
    "text": "The main reference for this chapter is [1]."
  },
  {
    "objectID": "contents/3/03-.html#basics",
    "href": "contents/3/03-.html#basics",
    "title": "3  Package: numpy",
    "section": "3.1 Basics",
    "text": "3.1 Basics\nThe basic data structure for numpy is numpy.ndarray. You may treat it as a generalized version of lists. However it can do so much more than the build-in list.\nTo use numpy, we just import it. In most cases you would like to use the alias np.\n\nimport numpy as np\n\n\n\n\n\n\n\nNote\n\n\n\nIn many cases, numpy.ndarray is a huge object since it stores tons of data. Therefore many of the operations related to numpy.ndarray are “in-place” by default. This means that if you don’t explicitly ask for a copy, there will be only one copy of the array and all later operations make changes to the original one.\nHowever there are many cases that"
  },
  {
    "objectID": "contents/3/03-.html#create-np.ndarray",
    "href": "contents/3/03-.html#create-np.ndarray",
    "title": "3  Package: numpy",
    "section": "3.2 Create np.ndarray",
    "text": "3.2 Create np.ndarray\n\nconvert a list into a numpy array.\nnp.zeros, np.zeros_like\nnp.ones, np.ones_like\nnp.eye\nnp.random.rand\nnp.arange\nnp.linspace\n\n\n\n\n\n\n\nNote\n\n\n\nPlease be very careful about the format of the input. For example, when you want to specify the dimension of the array, using np.zeros, you need to input a tuple. On the other hand, when using np.random.rand, you just directly input the dimensions one by one.\n\nimport numpy as np\n\nnp.zeros((3, 2))\nnp.random.rand(3, 2)\n\nIn this case, the official documents are always your friend."
  },
  {
    "objectID": "contents/3/03-.html#mathematical-and-statistical-methods",
    "href": "contents/3/03-.html#mathematical-and-statistical-methods",
    "title": "3  Package: numpy",
    "section": "3.3 Mathematical and Statistical Methods",
    "text": "3.3 Mathematical and Statistical Methods\n\n+, -, *, /, **, etc..\nnp.sin, np.exp, np.sqrt, etc..\nmean, sum, std, var, cumsum\nmax and min\nmaximum and minimum\nargmin and argmax\nnp.sort\nnp.unique, np.any\nnp.dot: Matrix multiplication\nnp.concatenate\nBroadcast\n\n\nExample 3.1 (Axis) Given A = np.array([[1,2],[3,4]]) and B = np.array([[5,6],[7,8]]), please use np.concatenate to concatencate these two matrices to get a new matrix, in the order:\n\nA left, B right\nA right, B left\nA up, B down\nA down, B up"
  },
  {
    "objectID": "contents/3/03-.html#common-attributes-and-methods",
    "href": "contents/3/03-.html#common-attributes-and-methods",
    "title": "3  Package: numpy",
    "section": "3.4 Common attributes and methods",
    "text": "3.4 Common attributes and methods\n\nshape\ndtype\nndim\nAny arithmetic operations between equal-size arrays applies the operation element-wise.\n\n\nExample 3.2 MNIST is a very famous dataset of hand written images. Here is how to load it. Note that in this instance of the dataset the data are stored as numpy arraies.\n\nimport tensorflow as tf\n\n(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\nX_train.shape"
  },
  {
    "objectID": "contents/3/03-.html#basic-indexing-and-slicing",
    "href": "contents/3/03-.html#basic-indexing-and-slicing",
    "title": "3  Package: numpy",
    "section": "3.5 Basic indexing and slicing",
    "text": "3.5 Basic indexing and slicing\nFirst see the following example.\n\n\nExample 3.3 \nimport numpy as np\narr = np.arange(10)\n\nprint(arr[5])\nprint(arr[5:8])\n\narr[5:8] = 12\nprint(arr)\n\nprint(arr[5:8:2])\nprint(arr[8:5:-1])\nprint(arr[::-1])\n\n5\n[5 6 7]\n[ 0  1  2  3  4 12 12 12  8  9]\n[12 12]\n[ 8 12 12]\n[ 9  8 12 12 12  4  3  2  1  0]\n\n\n\nTo do slicing in higher dimensional case, you may either treat a numpy array as a nested list, or you may directly work with it with multiindexes.\n\n\nExample 3.4 \nimport numpy as np\narr3d = np.arange(12).reshape(2, 2, 3)\n\nprint('case 1:\\n {}'.format(arr3d))\nprint('case 2:\\n {}'.format(arr3d[0, 1, 2]))\nprint('case 3:\\n {}'.format(arr3d[:, 0: 2, 1]))\nprint('case 4:\\n {}'.format(arr3d[:, 0: 2, 1:2]))\n\ncase 1:\n [[[ 0  1  2]\n  [ 3  4  5]]\n\n [[ 6  7  8]\n  [ 9 10 11]]]\ncase 2:\n 5\ncase 3:\n [[ 1  4]\n [ 7 10]]\ncase 4:\n [[[ 1]\n  [ 4]]\n\n [[ 7]\n  [10]]]"
  },
  {
    "objectID": "contents/3/03-.html#boolean-indexing",
    "href": "contents/3/03-.html#boolean-indexing",
    "title": "3  Package: numpy",
    "section": "3.6 Boolean Indexing",
    "text": "3.6 Boolean Indexing\nnumpy array can accept index in terms of numpy arries with boolean indexing.\n\n\nExample 3.5 \nimport numpy as np\na = np.arange(4)\nb = np.array([True, True, False, True])\nprint(a)\nprint(b)\nprint(a[b])\n\n[0 1 2 3]\n[ True  True False  True]\n[0 1 3]\n\n\n\nWe could combine this way with the logic computation to filter out the elements we don’t want.\n\nExample 3.6 Please replace the odd number in the array by its negative.\n\nimport numpy as np\narr = np.arange(10)\nodd = arr %2 == 1\narr[odd] = arr[odd] * (-1)\n\nprint(arr)\n\n[ 0 -1  2 -3  4 -5  6 -7  8 -9]"
  },
  {
    "objectID": "contents/3/03-.html#fancy-indexing",
    "href": "contents/3/03-.html#fancy-indexing",
    "title": "3  Package: numpy",
    "section": "3.7 Fancy indexing",
    "text": "3.7 Fancy indexing\nFancy indexing is a term adopted by NumPy to describe indexing using integer arrays.\n\n\nExample 3.7 \nimport numpy as np\n\narr = np.zeros((8, 4))\nfor i in range(8):\n    arr[i] = i\n\narr[[4, 3, 0, 6]]\n\narray([[4., 4., 4., 4.],\n       [3., 3., 3., 3.],\n       [0., 0., 0., 0.],\n       [6., 6., 6., 6.]])\n\n\n\n\n\nExample 3.8 \nimport numpy as np\n\narr = np.arange(32).reshape((8, 4))\nprint(arr)\nprint(arr[[1, 5, 7, 2], [0, 3, 1, 2]])\nprint(arr[[1, 5, 7, 2]][:, [0, 3, 1, 2]])\n\n[[ 0  1  2  3]\n [ 4  5  6  7]\n [ 8  9 10 11]\n [12 13 14 15]\n [16 17 18 19]\n [20 21 22 23]\n [24 25 26 27]\n [28 29 30 31]]\n[ 4 23 29 10]\n[[ 4  7  5  6]\n [20 23 21 22]\n [28 31 29 30]\n [ 8 11  9 10]]"
  },
  {
    "objectID": "contents/3/03-.html#copies-and-views",
    "href": "contents/3/03-.html#copies-and-views",
    "title": "3  Package: numpy",
    "section": "3.8 Copies and views",
    "text": "3.8 Copies and views\nThe view of an numpy array is a way to get access to the array without copying internel data. When operating with a view, the original data as well as all other views of the original data will be modified simutanously.\nThe default setting for copies and views is that, basic indexing and slicing will make views, and advanced indexing and slicing (e.g. boolean indexing, fancy indexing, etc.) will make copies. For other operations, you need to check the documents to know how they work. For example, np.reshape creates a view where possible, and np.flatten always creates a copy.\nYou may use np.view() or np.copy() to make views or copies explicitly. ::: {#exm-}\n\nimport numpy as np\narr = np.arange(10)\nb = arr[5:8]\nprint('arr is {}'.format(arr))\nprint('b is {}'.format(b))\n\nb[0] = -1\nprint('arr is {}'.format(arr))\nprint('b is {}'.format(b))\n\n\narr[6] = -2\nprint('arr is {}'.format(arr))\nprint('b is {}'.format(b))\n\nprint('The base of b is {}'.format(b.base))\n\narr is [0 1 2 3 4 5 6 7 8 9]\nb is [5 6 7]\narr is [ 0  1  2  3  4 -1  6  7  8  9]\nb is [-1  6  7]\narr is [ 0  1  2  3  4 -1 -2  7  8  9]\nb is [-1 -2  7]\nThe base of b is [ 0  1  2  3  4 -1 -2  7  8  9]\n\n\n:::\nThe way to make explicit copy is .copy().\n\n\nExample 3.9 \nimport numpy as np\narr = np.arange(10)\nb = arr[5:8].copy()\nprint('arr is {}'.format(arr))\nprint('b is {}'.format(b))\n\nb[0] = -1\nprint('arr is {}'.format(arr))\nprint('b is {}'.format(b))\n\n\narr[6] = -2\nprint('arr is {}'.format(arr))\nprint('b is {}'.format(b))\n\nprint('The base of b is {}'.format(b.base))\n\narr is [0 1 2 3 4 5 6 7 8 9]\nb is [5 6 7]\narr is [0 1 2 3 4 5 6 7 8 9]\nb is [-1  6  7]\narr is [ 0  1  2  3  4  5 -2  7  8  9]\nb is [-1  6  7]\nThe base of b is None"
  },
  {
    "objectID": "contents/3/03-.html#more-commands",
    "href": "contents/3/03-.html#more-commands",
    "title": "3  Package: numpy",
    "section": "3.9 More commands",
    "text": "3.9 More commands\n\n.T\naxis=n is very important.\nnp.reshape()\nnp.tile()\nnp.repeat()"
  },
  {
    "objectID": "contents/3/03-.html#more-advanced-commands",
    "href": "contents/3/03-.html#more-advanced-commands",
    "title": "3  Package: numpy",
    "section": "3.10 More advanced commands",
    "text": "3.10 More advanced commands\n\nnp.where()\nnp.any()\nnp.all()\nnp.argsort()\n\n\nExample 3.10 Get the position where elements of a and b match.\n\na = np.array([1,2,3,2,3,4,3,4,5,6])\nb = np.array([7,2,10,2,7,4,9,4,9,8])\n\nnp.where(a == b)\n\n(array([1, 3, 5, 7], dtype=int64),)\n\n\n\n\n\nExample 3.11 \na = np.array([1,2,3,2,3,4,3,4,5,6])\nb = np.array([7,2,10,2,7,4,9,4,9,8])\n\nnp.where(a == b, a*2, b+1)\n\narray([ 8,  4, 11,  4,  8,  8, 10,  8, 10,  9])\n\n\n\n\n\nExample 3.12 (Playing with axis) \nimport numpy as np\na = np.array([[[1,2],[3,4]],[[5,6],[7,8]]])\n\nnp.any(a==1, axis=0)\nnp.any(a==1, axis=1)\nnp.any(a==1, axis=2)\n\n\nnp.any(a==2, axis=0)\nnp.any(a==2, axis=1)\nnp.any(a==2, axis=2)\n\nnp.any(a==5, axis=0)\nnp.any(a==5, axis=1)\nnp.any(a==5, axis=2)\n\narray([[False, False],\n       [ True, False]])"
  },
  {
    "objectID": "contents/3/03-.html#examples",
    "href": "contents/3/03-.html#examples",
    "title": "3  Package: numpy",
    "section": "3.11 Examples",
    "text": "3.11 Examples\n\nExample 3.13 (Random walks) Adam walks randomly along the axis. He starts from 0. Every step he has equal possibility to go left or right. Please simulate this process.\nUse choices to record the choice of Adam at each step. We may generate a random array where 0 represents left and 1 represents right.\nUse positions to record the position of Adam at each step. Using choices, the position is +1 if we see a 1 and the position is -1 if we see a 0. So the most elegent way to perform this is to\n\nConvert choices from {0, 1} to {-1, 1}.\nTo record the starting position, we attach 0 to the beginning of the new choices.\nApply cumsum to choices to get positions.\n\n\nimport numpy as np\n\nstep = 30\nchoices = np.random.randint(2, size=step)\nchoices = choices * 2 - 1\nchoices = np.concatenate(([0], choices))\npositions = choices.cumsum()\n\nimport matplotlib.pyplot as plt\nplt.plot(positions)\n\n\n\n\n\n\nExample 3.14 (Many random walks) We mainly use numpy.ndarray to write the code in the previous example. The best part here is that it can be easily generalized to many random walks.\nStill keep choices and positions in mind. Now we would like to deal with multiple people simutanously. Each row represents one person’s random walk. All the formulas stay the same. We only need to update the dimension setting in the previous code.\n\nUpdate size in np.random.randint.\nUpdate [0] to np.zeros((N, 1)) in concatenate.\nFor cumsum and concatenate, add axis=1 to indicate that we perform the operations along axis 1.\nWe plot each row in the same figure. plt.legend is used to show the label for each line.\n\n\nimport numpy as np\n\nstep = 30\nN = 3\nchoices = np.random.randint(2, size=(N, step))\nchoices = choices * 2 - 1\nchoices = np.concatenate((np.zeros((N, 1)), choices), axis=1)\npositions = choices.cumsum(axis=1)\n\nimport matplotlib.pyplot as plt\nfor row in positions:\n    plt.plot(row)\nplt.legend([1, 2, 3])\n\n<matplotlib.legend.Legend at 0x2d700cce130>\n\n\n\n\n\n\n\nExample 3.15 (Analyze positions) We play with the numpy array positions to get some information about the random walks of three generated in the previous example.\n\nThe maximal position:\n\n\npositions.max()\n\n1.0\n\n\n\nThe maximal position for each one:\n\n\npositions.max(axis=1)\n\narray([1., 1., 0.])\n\n\n\nThe maximal position across all three for each step:\n\n\npositions.max(axis=0)\n\narray([ 0.,  1.,  0., -1.,  0.,  1.,  0.,  1.,  0.,  1.,  0., -1., -2.,\n       -3., -4., -5., -4., -3., -2., -3., -4., -3., -2., -3., -2., -1.,\n        0.,  1.,  0., -1.,  0.])\n\n\n\nCheck whether anyone once got to the position 3:\n\n\n(positions>=3).any(axis=1)\n\narray([False, False, False])\n\n\n\nThe number of people who once got to the position 3:\n\n\n(positions>=3).any(axis=1).sum()\n\n0\n\n\n\nWhich step for each one gets to the right most position:\n\n\npositions.argmax(axis=1)\n\narray([1, 1, 0], dtype=int64)"
  },
  {
    "objectID": "contents/3/03-.html#exercises",
    "href": "contents/3/03-.html#exercises",
    "title": "3  Package: numpy",
    "section": "3.12 Exercises",
    "text": "3.12 Exercises\nMany exercises are from [2].\n\nExercise 3.1 (array) Write a NumPy program to create a \\(3\\times3\\) matrix with values ranging from 2 to 10.\n\n\nExercise 3.2 (array) Write a NumPy program to create a null vector of size 10 and update sixth value to 11.\n\n\nExercise 3.3 (array) Write a NumPy program to reverse an array (first element becomes last).\n\n\nExercise 3.4 (array) Write a NumPy program to create a \\(10\\times10\\) 2D-array with 1 on the border and 0 inside.\n\n\nExercise 3.5 (repeat and tile) Given a = np.array([1,2,3]), please get the desired output array([1, 1, 1, 2, 2, 2, 3, 3, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3]).\n\n\nExercise 3.6 (Compare two numpy arraies) Consider two numpy arraies x and y. Compare them entry by entry. We would like to know how many are the same.\n\n\n\nClick to expand.\n\n\nSolution. Note that bool values True and False can be treated as numbers 1 and 0.\n\nimport numpy as np\n\nx = np.array([1, 2, 3, 4, 5])\ny = np.array([2, 1, 4, 4, 5])\n\nnumofsame = np.sum(x == y)\nprint(numofsame)\n\n2\n\n\n\n\n\nExercise 3.7 Get all items between 5 and 10 from an array a = np.array([2, 6, 1, 9, 10, 3, 27]).\n\n\nExercise 3.8 Swap rows 1 and 2 in the array arr = np.arange(9).reshape(3,3).\n\n\nExercise 3.9 Please finish the following tasks.\n\nReverse the rows of a 2D array arr = np.arange(9).reshape(3,3).\nReverse the columns of a 2D array arr = np.arange(9).reshape(3,3).\n\n\n\nExercise 3.10 Create a 2D array of shape 5x3 to contain random decimal numbers between 5 and 10.\n\n\nExercise 3.11 Use the following code to get the dataset iris.\n\nimport numpy as np\n\nurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\niris_1d = np.genfromtxt(url, delimiter=',', dtype=None, encoding=None)\n\n\niris_1d is a 1D numpy array that each item is a tuple. Please construct a new 1D numpy array that each item is the last componenet of each tuple in iris_1d.\nConvert iris_1d into a 2D array iris_2d by omitting the last field of each item.\n\n\n\nExercise 3.12 (Normalization) Use the following code to get an 1D array sepallength.\n\nimport numpy as np\n\nurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\nsepallength = np.genfromtxt(url, delimiter=',', dtype='float', usecols=[0],\n                            encoding=None)\n\nPlease normalize it such that the values of each item is between 0 and 1.\n\n\nExercise 3.13 np.isnan() is a function to check whether each entry of a numpy array is nan or not. Please use this as well as np.where to find all nan entries in an array.\nYou may use the following array iris_2d to test your code.\n\nimport numpy as np\nurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\niris_2d = np.genfromtxt(url, delimiter=',', dtype='float', encoding=None)\niris_2d[np.random.randint(150, size=20), np.random.randint(4, size=20)] = np.nan\n\n\n\nExercise 3.14 Select the rows of iris_2d that does not have any nan value.\n\nimport numpy as np\nurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\niris_2d = np.genfromtxt(url, delimiter=',', dtype='float', usecols=[0,1,2,3],\n                        encoding=None)\niris_2d[np.random.randint(150, size=20), np.random.randint(4, size=20)] = np.nan\n\n\n\nExercise 3.15 Replace all nan with 0 in numpy array iris_2d.\n\nimport numpy as np\nurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\niris_2d = np.genfromtxt(url, delimiter=',', dtype='float', usecols=[0,1,2,3],\n                        encoding=None)\niris_2d[np.random.randint(150, size=20), np.random.randint(4, size=20)] = np.nan\n\n\n\nExercise 3.16 Consider x = np.array([1, 2, 1, 1, 3, 4, 3, 1, 1, 2, 1, 1, 2]). Please find the index of 5th repetition of number 1 in x."
  },
  {
    "objectID": "contents/3/03-.html#projects",
    "href": "contents/3/03-.html#projects",
    "title": "3  Package: numpy",
    "section": "3.13 Projects",
    "text": "3.13 Projects\n\nExercise 3.17 (Adding one axis) Please download this file.\n\nPlease use matplotlib.pyplot.imread() to read the file as a 3D numpy array.\nCheck the shape of the array.\nAdd one additional axis to it as axis 0 to make it into a 4D array.\n\n\n\nExercise 3.18 (Random) Please finish the following tasks.\n\nUse the package np.random to flip a coin 100 times and record the result in a list coin.\nAssume that the coin is not fair, and the probability to get H is p. Write a code to flip the coin 100 times and record the result in a list coin, with a given parameter p. You may use p=.4 as the first choice.\nFor each list coin created above, write a code to find the longest H streak. We only need the biggest number of consecutive H we get during this 100 tosses. It is NOT necessary to know when we start the streak.\n\n\n\n\nClick for Hint.\n\n\nSolution. The following ideas can be used to solve the problem.\n\nnp.where\nstring, split and join\n\n\n\n\nExercise 3.19 (Bins) Please read the document of np.digitize, and use it to do the following task.\nSet the following bins:\n\nLess than 3: small\n3-5: medium\nBigger than 5: large\n\nPlease transform the following data iris_2c into texts using the given bins.\n\nimport numpy as np\nurl = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\niris_2c = np.genfromtxt(url, delimiter=',', dtype='object')[:, 2].astype('float')\n\n\n\nExercise 3.20 Consider a 2D numpy array a.\n\nimport numpy as np\na = np.random.rand(5, 5)\n\n\nPlease sort it along the 3rd column.\nPlease sort it along the 2nd row.\n\n\n\n\nClick for Hint.\n\n\nSolution. Please use np.argsort for the problem.\n\n\n\nExercise 3.21 (One-hot vector) Compute the one-hot encodings of a given array. You may use the following array as a test example. In this example, there are 3 labels. So the one-hot vectors are 3 dimensional vectors.\nFor more infomation about one-hot encodings, you may check the Wiki page. You are not allowed to use packages that can directly compute the one-hot encodings for this problem.\n\nimport numpy as np\narr = np.random.randint(1,4, size=6)\n\n\n\nExercise 3.22 From the given 1d array arr = np.arange(15), generate a 2d matrix using strides, with a window length of 4 and strides of 2, like [[0,1,2,3], [2,3,4,5], [4,5,6,7]..].\n\n\n\n\n\n[1] McKinney, W. (2017). Python for data analysis: Data wrangling with pandas, NumPy, and IPython. O’Reilly Media.\n\n\n[2] Prabhakaran, S. (2018). 101 NumPy exercises for data analysis (python)."
  },
  {
    "objectID": "contents/4/04-.html",
    "href": "contents/4/04-.html",
    "title": "4  Package: pandas",
    "section": "",
    "text": "The basic data structure for pandas is pandas.DataFrame. You may treat it as a generalized version of tables.\nTo use pandas, we just import it. In most cases you would like to use the alias pd.\nSince DataFrame is more like a table, the biggest questions here is not to do computations (which is still very important), but to retrieve, search, sort, merge, etc.. those data."
  },
  {
    "objectID": "contents/4/04-.html#basic-pandas",
    "href": "contents/4/04-.html#basic-pandas",
    "title": "4  Package: pandas",
    "section": "4.1 Basic pandas",
    "text": "4.1 Basic pandas\n\n4.1.1 Series and DataFrame\nA Series is a 1-d array-like object which has index. The default index is starting from 0. You may change the index to be something assigned by you. Thus it can be treated as a generalization of a dict.\n\nobj = pd.Series([3, 1, 2, 4])\nobj\n\n0    3\n1    1\n2    2\n3    4\ndtype: int64\n\n\n\nobj2 = pd.Series([3, 1, 2, 4], index=['a', 'b', 'c', 'd'])\nobj2\n\na    3\nb    1\nc    2\nd    4\ndtype: int64\n\n\n\ndata3 = {'a': 3, 'b': 1, 'c': 2, 'd': 4}\nobj3 = pd.Series(data3)\nobj3\n\na    3\nb    1\nc    2\nd    4\ndtype: int64\n\n\nA DataFrame represents a rectangular table of data and contains an ordered collection of columns, each of which can be a different value type. The DataFrame has both a row and column index; it can be thought of as a dict of Series all sharing the same index. When displaying a DataFrame, we may use .head() to just display the first few rows for efficicy.\n\nimport pandas as pd\n\ndata = {'a': [1, 2, 3, 4, 5, 6, 7],\n        'b': [1.1, 2.1, 3.1, 4.1, 5.1, 6.1, 7.1],\n        'c': ['a', 'b', 'c', 'd', 'e', 'f', 'g']}\ndf = pd.DataFrame(data)\ndf.head()\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      1.1\n      a\n    \n    \n      1\n      2\n      2.1\n      b\n    \n    \n      2\n      3\n      3.1\n      c\n    \n    \n      3\n      4\n      4.1\n      d\n    \n    \n      4\n      5\n      5.1\n      e\n    \n  \n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe may use the setting columns= or index= as well as the methods .rename(columns=, index=) to change the column names and the index names. See the following example.\n\nimport numpy as np\nimport pandas as pd\ndata = pd.DataFrame(np.arange(16).reshape((4, 4)),\n                    index=['Ohio', 'Colorado', 'Utah', 'New York'],\n                    columns=['one', 'two', 'three', 'four'])\n\n\n\n\n\n4.1.2 Accessing data\n\nA column in a DataFrame can be retrieved as a Series either by dict-like notation or by attribute. What one gets from this is a Series object.\n\ndict-like notation: df['a']\nby attribute: df.a. Note that if the name of the column is not suitable for attribute names, this method doesn’t work.\n\nRows are retrieved by .loc if using the row index, and by .iloc if using the row number.\n\n\n\n4.1.3 Updating data\n\nAssign values to a column of a DataFrame will update that column. If the column doesn’t exist, new column will be created.\nWhen assign values with non-existent row index, that part of the data will be discarded.\nAny time if there are no values with a specific column and row, it will show as NaN.\n\n\n\nExample 4.1 \nimport pandas as pd\n\ndata = {'a': [1, 2, 3, 4],\n        'b': [1.1, 2.1, 3.1, 4.1],\n        'c': ['a', 'b', 'c', 'd']}\ndf = pd.DataFrame(data)\n\nnewcol = {1: 'good', 3: 'better', 5: 'best'}\ndf['d'] = pd.Series(newcol)\ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n    \n  \n  \n    \n      0\n      1\n      1.1\n      a\n      NaN\n    \n    \n      1\n      2\n      2.1\n      b\n      good\n    \n    \n      2\n      3\n      3.1\n      c\n      NaN\n    \n    \n      3\n      4\n      4.1\n      d\n      better\n    \n  \n\n\n\n\n\n\n\n4.1.4 Indexing, Selection, and Filtering\n\nSeries indexing (obj[...]) works analogously to NumPy array indexing, except you can use the Series’s index values instead of only integers.\nWe can use logical expresssion to filter DataFrame.\n\n\nimport pandas as pd\n\ndata = pd.DataFrame(np.arange(16).reshape((4, 4)),\n                    index=['Ohio', 'Colorado', 'Utah', 'New York'],\n                    columns=['one', 'two', 'three', 'four'])\ndata[data['one']>5]\n\n\n\n\n\n  \n    \n      \n      one\n      two\n      three\n      four\n    \n  \n  \n    \n      Utah\n      8\n      9\n      10\n      11\n    \n    \n      New York\n      12\n      13\n      14\n      15\n    \n  \n\n\n\n\n\n.loc, .iloc\n\n\nimport pandas as pd\ndata = pd.DataFrame(np.arange(16).reshape((4, 4)),\n                    index=['Ohio', 'Colorado', 'Utah', 'New York'],\n                    columns=['one', 'two', 'three', 'four'])\nprint(data.loc['Colorado', ['two', 'three']])\nprint(data.iloc[2, [3, 0, 1]])\n\ntwo      5\nthree    6\nName: Colorado, dtype: int32\nfour    11\none      8\ntwo      9\nName: Utah, dtype: int32\n\n\n\nSlicing with labels behaves differently than normal Python slicing in that the endpoint is inclusive.\n\n\nimport pandas as pd\n\nobj = pd.Series(np.arange(4.), index=['a', 'b', 'c', 'd'])\nobj['b':'c']\n\nb    1.0\nc    2.0\ndtype: float64\n\n\n\nReindex .reindex():\n\n\nimport pandas as pd\ndata = pd.DataFrame(np.arange(16).reshape((4, 4)),\n                    index=['Ohio', 'Colorado', 'Utah', 'New York'],\n                    columns=['one', 'two', 'three', 'four'])\n\ndata.reindex(index = ['Colorado', 'Arkansas', 'New York'],\n             columns = ['three', 'five', 'one'])\n\n\n\n\n\n  \n    \n      \n      three\n      five\n      one\n    \n  \n  \n    \n      Colorado\n      6.0\n      NaN\n      4.0\n    \n    \n      Arkansas\n      NaN\n      NaN\n      NaN\n    \n    \n      New York\n      14.0\n      NaN\n      12.0\n    \n  \n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n.loc and .reindex are very similar to each other. The main difference between theses two is that .loc will return a view and .reindex will return a copy in most cases.\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhen locate data using indexes, duplicate labels will return all results.\n\n\n\n\n4.1.5 Essential functions\n\nArithmetic and Data Alignment Elements of the same index and columns will be computed. By default, if any entry is nan, the answer will be nan. You may use fill_value argument to fill the empty slots.\n\n\n\nExample 4.2 \nimport pandas as pd\nimport numpy as np\ndf1 = pd.DataFrame(np.arange(12.).reshape((3, 4)), columns=list('abcd'))\ndf2 = pd.DataFrame(np.arange(20.).reshape((4, 5)), columns=list('abcde'))\ndf2.loc[1, 'b'] = np.nan\n\ndf1.add(df2, fill_value=0)\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n      d\n      e\n    \n  \n  \n    \n      0\n      0.0\n      2.0\n      4.0\n      6.0\n      4.0\n    \n    \n      1\n      9.0\n      5.0\n      13.0\n      15.0\n      9.0\n    \n    \n      2\n      18.0\n      20.0\n      22.0\n      24.0\n      14.0\n    \n    \n      3\n      15.0\n      16.0\n      17.0\n      18.0\n      19.0\n    \n  \n\n\n\n\n\nRelatedly, when reindexing a Series or DataFrame, you can also specify a fill_value.\n\n\n4.1.6 Function Application and Mapping\nWe may apply functions to each row/column of a DataFrame. If the function is built-in function that is compatible with DataFrame, you can directly call the function that it will be applied automatically to each row/column. If it is not, we can call apply to get the desired result.\n\n\nExample 4.3 \nimport pandas as pd\ndata = pd.DataFrame(np.random.rand(4, 4),\n                    index=['Ohio', 'Colorado', 'Utah', 'New York'],\n                    columns=['one', 'two', 'three', 'four'])\n\nf = lambda x: x.max() - x.min()\n\nprint(data.apply(f))\nprint(data.apply(f, axis='columns'))\n\none      0.733638\ntwo      0.845186\nthree    0.684077\nfour     0.749613\ndtype: float64\nOhio        0.721876\nColorado    0.771429\nUtah        0.662834\nNew York    0.777315\ndtype: float64\n\n\n\nWe can use more complicated function to get more complicated result.\n\n\nExample 4.4 \nimport pandas as pd\ndata = pd.DataFrame(np.random.rand(4, 4),\n                    index=['Ohio', 'Colorado', 'Utah', 'New York'],\n                    columns=['one', 'two', 'three', 'four'])\n\nf = lambda x: pd.Series([x.max(), x.min()], index=['max', 'min'])\n\nprint(data.apply(f))\n\n          one       two     three      four\nmax  0.532926  0.723024  0.837914  0.934831\nmin  0.059230  0.021503  0.071344  0.356255\n\n\n\n\n\n4.1.7 Sorting and Ranking\n\n.sort_values(by=)\n.rank(ascending=, method=)\n\n\n\n4.1.8 Summarizing and Computing Descriptive Statistics\n\nsum, cumsum\nmean, median\n.describe()\n.cov, .corr\n\n\n\n4.1.9 Unique Values, Value Counts, and Membership\n\nunique\nvalue_counts\n\n\n\n4.1.10 Reading and Writing Data in Text Format\n\nread_csv\nread_excel\ndf.to_csv\n\n\n\n4.1.11 Copies and views\n\ninplace"
  },
  {
    "objectID": "contents/4/04-.html#data-cleaning",
    "href": "contents/4/04-.html#data-cleaning",
    "title": "4  Package: pandas",
    "section": "4.2 Data cleaning",
    "text": "4.2 Data cleaning\n\n4.2.1 Handling Missing Data\n\nnp.nan, pd.NA\npd.isnull(), np.isnan()\ndropna, fillna\n\n\n\nExample 4.5 \nimport pandas as pd\nimport numpy as np\n\ndata = pd.DataFrame([[1., 6.5, 3.], [1., np.nan, np.nan], \n                     [np.nan, np.nan, np.nan], [np.nan, 6.5, 3.]])\ncleaned = data.dropna()\ncleanedrow = data.dropna(how='all')\ndata\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n    \n  \n  \n    \n      0\n      1.0\n      6.5\n      3.0\n    \n    \n      1\n      1.0\n      NaN\n      NaN\n    \n    \n      2\n      NaN\n      NaN\n      NaN\n    \n    \n      3\n      NaN\n      6.5\n      3.0\n    \n  \n\n\n\n\n\ncleaned\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n    \n  \n  \n    \n      0\n      1.0\n      6.5\n      3.0\n    \n  \n\n\n\n\n\ncleanedrow\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n    \n  \n  \n    \n      0\n      1.0\n      6.5\n      3.0\n    \n    \n      1\n      1.0\n      NaN\n      NaN\n    \n    \n      3\n      NaN\n      6.5\n      3.0\n    \n  \n\n\n\n\n\ndata[4] = np.nan\ncleaned1 = data.dropna(axis=1, how='all')\ncleanedthresh = data.dropna(thresh=2)\ndata\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n      4\n    \n  \n  \n    \n      0\n      1.0\n      6.5\n      3.0\n      NaN\n    \n    \n      1\n      1.0\n      NaN\n      NaN\n      NaN\n    \n    \n      2\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      3\n      NaN\n      6.5\n      3.0\n      NaN\n    \n  \n\n\n\n\n\ncleaned1\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n    \n  \n  \n    \n      0\n      1.0\n      6.5\n      3.0\n    \n    \n      1\n      1.0\n      NaN\n      NaN\n    \n    \n      2\n      NaN\n      NaN\n      NaN\n    \n    \n      3\n      NaN\n      6.5\n      3.0\n    \n  \n\n\n\n\n\ncleanedthresh\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n      4\n    \n  \n  \n    \n      0\n      1.0\n      6.5\n      3.0\n      NaN\n    \n    \n      3\n      NaN\n      6.5\n      3.0\n      NaN\n    \n  \n\n\n\n\n\nfill0 = data.fillna(0)\nfilldict = data.fillna({1: 0.5, 2: -0.1})\ndata\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n      4\n    \n  \n  \n    \n      0\n      1.0\n      6.5\n      3.0\n      NaN\n    \n    \n      1\n      1.0\n      NaN\n      NaN\n      NaN\n    \n    \n      2\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      3\n      NaN\n      6.5\n      3.0\n      NaN\n    \n  \n\n\n\n\n\nfill0\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n      4\n    \n  \n  \n    \n      0\n      1.0\n      6.5\n      3.0\n      0.0\n    \n    \n      1\n      1.0\n      0.0\n      0.0\n      0.0\n    \n    \n      2\n      0.0\n      0.0\n      0.0\n      0.0\n    \n    \n      3\n      0.0\n      6.5\n      3.0\n      0.0\n    \n  \n\n\n\n\n\nfilldict\n\n\n\n\n\n  \n    \n      \n      0\n      1\n      2\n      4\n    \n  \n  \n    \n      0\n      1.0\n      6.5\n      3.0\n      NaN\n    \n    \n      1\n      1.0\n      0.5\n      -0.1\n      NaN\n    \n    \n      2\n      NaN\n      0.5\n      -0.1\n      NaN\n    \n    \n      3\n      NaN\n      6.5\n      3.0\n      NaN\n    \n  \n\n\n\n\n\n\n\n4.2.2 Data Transformation\n\n.duplicated(), drop_duplicates()\n\n\n\nExample 4.6 \nimport numpy as np\nimport pandas as pd\n\ndata = pd.DataFrame({'k1': ['one', 'two'] * 3 + ['two'], \n                     'k2': [1, 1, 2, 3, 3, 4, 4]})\ndata.drop_duplicates(['k1'], keep='last')\n\n\n\n\n\n  \n    \n      \n      k1\n      k2\n    \n  \n  \n    \n      4\n      one\n      3\n    \n    \n      6\n      two\n      4\n    \n  \n\n\n\n\n\n\npd.Series.map(), pd.DataFrame.apply()\n\n\n\nExample 4.7 \nimport pandas as pd\nimport numpy as np\n\ndata = pd.DataFrame({'food': ['bacon', 'pulled pork', 'bacon',\n                     'Pastrami', 'corned beef', 'Bacon',\n                     'pastrami', 'honey ham', 'nova lox'],\n                     'ounces': [4, 3, 12, 6, 7.5, 8, 3, 5, 6]})\n\nmeat_to_animal = {\n    'bacon': 'pig',\n    'pulled pork': 'pig',\n    'pastrami': 'cow',\n    'corned beef': 'cow',\n    'honey ham': 'pig',\n    'nova lox': 'salmon'\n    }\n\ndata['animal'] = data['food'].str.lower().map(meat_to_animal)\n\ndata['food'].map(lambda x: meat_to_animal[x.lower()])\n\n0       pig\n1       pig\n2       pig\n3       cow\n4       cow\n5       pig\n6       cow\n7       pig\n8    salmon\nName: food, dtype: object\n\n\n\n\nreplace\nrename \ndescribe\npermutation\nsample\ndummy variables\n\n\n\n4.2.3 Example: Movies\nBelow we explore the MovieLens 1M datasets. You may download it from this link.\n\nimport pandas as pd\nimport numpy as np\nmnames = ['movie_id', 'title', 'genres']\nmovies = pd.read_table('assests/datasets/movies.dat', sep='::',\n                       header=None, names=mnames, engine=\"python\",\n                       encoding='ISO-8859-1')\n\nall_genres = list()\nmovies['genres'].map(lambda x: all_genres.extend(x.split('|')))\n\ngenres = pd.unique(all_genres)\n\ndummies = pd.DataFrame(np.zeros((len(movies), len(genres))), columns=genres)\n\nfor i, gen in enumerate(movies.genres):\n    indices = dummies.columns.get_indexer(gen.split('|'))\n    dummies.iloc[i, indices] = 1\n\nmovies_windic = movies.join(dummies.add_prefix('Genre_'))\n\n\n\n4.2.4 String Manipulation\nThe key idea in this section is that, all methods in pd.Series.str will be applied to each entry of the Series.\n\n\nExample 4.8 \nimport pandas as pd\nimport numpy as np\ns = pd.Series([\"A \", \" B \", \"C\", \"Aaba\", \" Baca \", np.nan, \"CABA\", \"dog\", \"cat\"])\n\ns.str.lower()\ns.str.split('a')\ns.str.len()\ns.str.strip()\ns.str.replace(\"A\", '1')\n\n0        1 \n1        B \n2         C\n3      1aba\n4     Baca \n5       NaN\n6      C1B1\n7       dog\n8       cat\ndtype: object\n\n\n\n\nExample 4.9 We could also use .str to play with column names and row indexes.\n\nimport pandas as pd\nimport numpy as np\ndf = pd.DataFrame(np.random.randn(3, 2),\n                  columns=[\" Column A \", \" Column B \"], index=range(3))\n\ndf.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\ndf\n\n\n\n\n\n  \n    \n      \n      column_a\n      column_b\n    \n  \n  \n    \n      0\n      -0.065274\n      -0.103331\n    \n    \n      1\n      -0.656704\n      -1.715433\n    \n    \n      2\n      0.720629\n      2.791583\n    \n  \n\n\n\n\n\n\n\n4.2.5 Regular expression\nRegular expressions provide a flexible way to search or match string patterns in text. A single expression, commonly called a regex, is a string formed according to the regular expression language. Python’s built-in re module is responsible for applying regular expressions to strings.\nFor details of the regular expression language in Python, please read the official documents from here. There are also many great websites for learning regex. This is one example.\nWe will briefly mentioned a few rules here.\n\n.: matches any character except a newline.\n\\d: matches any digit. It is the same as [0-9].\n\\w: matches any alphabatic or numeric character. It is the same as [a-zA-Z0-9_].\n\\s: matches any whitespaces. It is the same as [\\t\\n\\r\\f\\v].\n*: Causes the resulting RE to match 0 or more repetitions of the preceding RE, as many repetitions as are possible.\n+: Causes the resulting RE to match 1 or more repetitions of the preceding RE, as many repetitions as are possible.\n?: Causes the resulting RE to match 0 or 1 repetitions of the preceding RE.\n*?, +?, ??: The *, +, and ? qualifiers are all greedy; they match as much text as possible. Adding ? after the qualifier makes it perform the match in non-greedy or minimal fashion; as few characters as possible will be matched.\n{m}: Specifies that exactly m copies of the previous RE should be matched.\n{m,n}: Causes the resulting RE to match from m to n repetitions of the preceding RE, attempting to match as many repetitions as possible.\n{m,n}?: Causes the resulting RE to match from m to n repetitions of the preceding RE, attempting to match as few repetitions as possible.\n[]: Used to indicate a set of characters.\n(): set groups.\n\n\n\nExample 4.10 \nimport re\ntext = \"foo bar\\t baz \\tqux\"\npattern = '\\s+'\nregex = re.compile(pattern)\nregex.split(text)\n\n['foo', 'bar', 'baz', 'qux']\n\n\n\n\n.match()\n.search()\n.findall()\n.split()\n.sub()\n\nWe can use () to specify groups, and use .groups() to get access to the results.\n\n\nExample 4.11 \nimport re\npattern = r'([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\\.([A-Z]{2,4})'\nregex = re.compile(pattern, flags=re.IGNORECASE)\nm = regex.match('wesm@bright.net')\nm.groups()\n\n('wesm', 'bright', 'net')\n\n\n\nTo use regex to DataFrame and Series, you may directly apply .match, .findall, .replace after .str, with the regex pattern as one of the arguments.\n.extract is a method that is not from re. It is used to extract the matched groups and make them as a DataFrame.\n\n\nExample 4.12 \nimport pandas as pd\nimport numpy as np\nmnames = ['movie_id', 'title', 'genres']\nmovies = pd.read_table('assests/datasets/movies.dat', sep='::',\n                       header=None, names=mnames, engine=\"python\",\n                       encoding='ISO-8859-1')\n\npattern = r'([a-zA-Z0-9_\\s,.?:;\\']+)\\((\\d{4})\\)'\nmovies = movies.join(movies.title.str.extract(pattern).rename(columns={0: 'movie title', 1: 'year'}))"
  },
  {
    "objectID": "contents/4/04-.html#data-wrangling",
    "href": "contents/4/04-.html#data-wrangling",
    "title": "4  Package: pandas",
    "section": "4.3 Data Wrangling",
    "text": "4.3 Data Wrangling\n\n4.3.1 Hierarchical indexing\nPandas support a more complex indexing system, that the index may have multiple levels. See the following example.\n\n\nimport pandas as pd\nimport numpy as np\n\ndata = pd.Series(np.random.randn(9),\n                 index = [['a', 'a', 'a', 'b', 'b', 'c', 'c', 'd', 'd'],\n                          [1, 2, 3, 1, 2, 3, 1, 2, 3]])\ndata\n\na  1   -0.789929\n   2   -0.969528\n   3    0.722539\nb  1    2.654742\n   2   -1.655269\nc  3    0.892599\n   1   -0.248211\nd  2   -0.130479\n   3    0.116614\ndtype: float64\n\n\nYou may look at the Series using different levels of indexes.\n\ndata['a']\n\n1   -0.789929\n2   -0.969528\n3    0.722539\ndtype: float64\n\n\n\ndata.loc[:, 2]\n\na   -0.969528\nb   -1.655269\nd   -0.130479\ndtype: float64\n\n\nYou may use groupby to group by levels and do calculations related to levels. More .groupby() will be discussed in the next section.\n\ndata.groupby(level=1).sum()\n\n1    1.616602\n2   -2.755277\n3    1.731752\ndtype: float64\n\n\n\nFrom the example above, you may notice that the 2-level hierarchical indexing for a Series works very similar to a DataFrame. In fact, you may translate it back and forth between a 2-level indexing Series and a DataFrame.\n\ndf = data.unstack()\ndf\n\n\n\n\n\n  \n    \n      \n      1\n      2\n      3\n    \n  \n  \n    \n      a\n      -0.789929\n      -0.969528\n      0.722539\n    \n    \n      b\n      2.654742\n      -1.655269\n      NaN\n    \n    \n      c\n      -0.248211\n      NaN\n      0.892599\n    \n    \n      d\n      NaN\n      -0.130479\n      0.116614\n    \n  \n\n\n\n\n\ndf.stack()\n\na  1   -0.789929\n   2   -0.969528\n   3    0.722539\nb  1    2.654742\n   2   -1.655269\nc  1   -0.248211\n   3    0.892599\nd  2   -0.130479\n   3    0.116614\ndtype: float64\n\n\nFor DataFrame the index for both axes can be multiindex. The usual indexing way can be used if you want to start from the first level of the index. The more specific method to extract data is .xs.\n\n\nExample 4.13 \nimport pandas as pd\n\ndf1 = pd.DataFrame(\n    {\n        \"A\": [\"A0\", \"A1\", \"A2\", \"A3\"],\n        \"B\": [\"B0\", \"B1\", \"B2\", \"B3\"],\n        \"C\": [\"C0\", \"C1\", \"C2\", \"C3\"],\n        \"D\": [\"D0\", \"D1\", \"D2\", \"D3\"],\n    },\n    index=[0, 1, 2, 3],\n)\n\ndf2 = pd.DataFrame(\n    {\n        \"A\": [\"A4\", \"A5\", \"A6\", \"A7\"],\n        \"B\": [\"B4\", \"B5\", \"B6\", \"B7\"],\n        \"C\": [\"C4\", \"C5\", \"C6\", \"C7\"],\n        \"D\": [\"D4\", \"D5\", \"D6\", \"D7\"],\n    },\n    index=[4, 5, 6, 7],\n)\n\ndf = pd.concat([df1, df2], keys=['x', 'y'])\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      x\n      0\n      A0\n      B0\n      C0\n      D0\n    \n    \n      1\n      A1\n      B1\n      C1\n      D1\n    \n    \n      2\n      A2\n      B2\n      C2\n      D2\n    \n    \n      3\n      A3\n      B3\n      C3\n      D3\n    \n    \n      y\n      4\n      A4\n      B4\n      C4\n      D4\n    \n    \n      5\n      A5\n      B5\n      C5\n      D5\n    \n    \n      6\n      A6\n      B6\n      C6\n      D6\n    \n    \n      7\n      A7\n      B7\n      C7\n      D7\n    \n  \n\n\n\n\n\ndf['A']\n\nx  0    A0\n   1    A1\n   2    A2\n   3    A3\ny  4    A4\n   5    A5\n   6    A6\n   7    A7\nName: A, dtype: object\n\n\n\ndf.loc['x']\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      A0\n      B0\n      C0\n      D0\n    \n    \n      1\n      A1\n      B1\n      C1\n      D1\n    \n    \n      2\n      A2\n      B2\n      C2\n      D2\n    \n    \n      3\n      A3\n      B3\n      C3\n      D3\n    \n  \n\n\n\n\n\ndf.loc['x',3]\n\nA    A3\nB    B3\nC    C3\nD    D3\nName: (x, 3), dtype: object\n\n\n\ndf.xs(3, level=1, drop_level=False)\n\n\n\n\n\n  \n    \n      \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      x\n      3\n      A3\n      B3\n      C3\n      D3\n    \n  \n\n\n\n\n\n\n\n4.3.2 Combining and Merging Datasets\n\n4.3.2.1 merge()\nMerge combines datasets by linking rows using one or more keys. This is from relational databases (e.g., SQL-based).\nHere are some examples.\n\n\nExample 4.14 \nimport pandas as pd\ndf1 = pd.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'a', 'b'],\n                    'data1': range(7)})\ndf2 = pd.DataFrame({'key': ['a', 'b', 'd'], 'data2': range(3)})\n\nThe two DataFrames are displayed as follows.\n\ndf1\n\n\n\n\n\n  \n    \n      \n      key\n      data1\n    \n  \n  \n    \n      0\n      b\n      0\n    \n    \n      1\n      b\n      1\n    \n    \n      2\n      a\n      2\n    \n    \n      3\n      c\n      3\n    \n    \n      4\n      a\n      4\n    \n    \n      5\n      a\n      5\n    \n    \n      6\n      b\n      6\n    \n  \n\n\n\n\n\ndf2\n\n\n\n\n\n  \n    \n      \n      key\n      data2\n    \n  \n  \n    \n      0\n      a\n      0\n    \n    \n      1\n      b\n      1\n    \n    \n      2\n      d\n      2\n    \n  \n\n\n\n\n\npd.merge(df1, df2, on='key')\n\n\n\n\n\n  \n    \n      \n      key\n      data1\n      data2\n    \n  \n  \n    \n      0\n      b\n      0\n      1\n    \n    \n      1\n      b\n      1\n      1\n    \n    \n      2\n      b\n      6\n      1\n    \n    \n      3\n      a\n      2\n      0\n    \n    \n      4\n      a\n      4\n      0\n    \n    \n      5\n      a\n      5\n      0\n    \n  \n\n\n\n\nIf the column names are different in each object, you can specify them separately.\n\ndf3 = pd.DataFrame({'lkey': ['b', 'b', 'a', 'c', 'a', 'a', 'b'],\n                    'data1': range(7)})\ndf4 = pd.DataFrame({'rkey': ['a', 'b', 'd'],\n                    'data2': range(3)})\npd.merge(df3, df4, left_on='lkey', right_on='rkey')\n\n\n\n\n\n  \n    \n      \n      lkey\n      data1\n      rkey\n      data2\n    \n  \n  \n    \n      0\n      b\n      0\n      b\n      1\n    \n    \n      1\n      b\n      1\n      b\n      1\n    \n    \n      2\n      b\n      6\n      b\n      1\n    \n    \n      3\n      a\n      2\n      a\n      0\n    \n    \n      4\n      a\n      4\n      a\n      0\n    \n    \n      5\n      a\n      5\n      a\n      0\n    \n  \n\n\n\n\n\nBy default merge does an inner join, that the keys in the result are the interesection found in both tables. Below are different types of merge. To specify the method for merge, the option is how.\n\ninner\nleft\nright\nouter\n\nLet’s see the following examples.\n\n\n\ndf1 = pd.DataFrame({'Key': [1, 2], 'A': [0, 2], 'B': [1, 3]})\ndf1\n\n\n\n\n\n  \n    \n      \n      Key\n      A\n      B\n    \n  \n  \n    \n      0\n      1\n      0\n      1\n    \n    \n      1\n      2\n      2\n      3\n    \n  \n\n\n\n\n\n\n\ndf2 = pd.DataFrame({'Key': [1, 3], 'C': [0, 2], 'D': [1, 3]})\ndf2\n\n\n\n\n\n  \n    \n      \n      Key\n      C\n      D\n    \n  \n  \n    \n      0\n      1\n      0\n      1\n    \n    \n      1\n      3\n      2\n      3\n    \n  \n\n\n\n\n\n\n\n\n\npd.merge(df1, df2, on='Key', how='inner')\n\n\n\n\n\n  \n    \n      \n      Key\n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      1\n      0\n      1\n      0\n      1\n    \n  \n\n\n\n\n\n\n\npd.merge(df1, df2, on='Key', how='outer')\n\n\n\n\n\n  \n    \n      \n      Key\n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      1\n      0.0\n      1.0\n      0.0\n      1.0\n    \n    \n      1\n      2\n      2.0\n      3.0\n      NaN\n      NaN\n    \n    \n      2\n      3\n      NaN\n      NaN\n      2.0\n      3.0\n    \n  \n\n\n\n\n\n\n\n\n\npd.merge(df1, df2, on='Key', how='left')\n\n\n\n\n\n  \n    \n      \n      Key\n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      1\n      0\n      1\n      0.0\n      1.0\n    \n    \n      1\n      2\n      2\n      3\n      NaN\n      NaN\n    \n  \n\n\n\n\n\n\n\npd.merge(df1, df2, on='Key', how='right')\n\n\n\n\n\n  \n    \n      \n      Key\n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      1\n      0.0\n      1.0\n      0\n      1\n    \n    \n      1\n      3\n      NaN\n      NaN\n      2\n      3\n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf a key combination appears more than once in both tables, the resulting table will have the Cartesian product of the associated data. Here is a very basic example with one unique key combination.\n\ndf1 = pd.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'b'],\n                    'data1': range(6)})\ndf2 = pd.DataFrame({'key': ['a', 'b', 'a', 'b', 'd'],\n                    'data2': range(5)})\npd.merge(df1, df2, on='key', how='left')\n\n\n\n\n\n  \n    \n      \n      key\n      data1\n      data2\n    \n  \n  \n    \n      0\n      b\n      0\n      1.0\n    \n    \n      1\n      b\n      0\n      3.0\n    \n    \n      2\n      b\n      1\n      1.0\n    \n    \n      3\n      b\n      1\n      3.0\n    \n    \n      4\n      a\n      2\n      0.0\n    \n    \n      5\n      a\n      2\n      2.0\n    \n    \n      6\n      c\n      3\n      NaN\n    \n    \n      7\n      a\n      4\n      0.0\n    \n    \n      8\n      a\n      4\n      2.0\n    \n    \n      9\n      b\n      5\n      1.0\n    \n    \n      10\n      b\n      5\n      3.0\n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf the merge keys in a DataFrame is in its index instead of column(s), we could pass left_index=True or right_index=True or both instead of setting left_on/right_on/on.\n\n\n\nExample 4.15 If we want to really create a Cartesian product, we may use the option how='cross'. For example, we would like to generate a deck of cards, we may use the following codes.\n\nsuit = pd.DataFrame({'suit': ['spades', 'hearts', 'clubs', 'diamonds']})\nface = pd.DataFrame({'face': list(range(1, 14))})\ndeck = pd.merge(suit, face, how='cross')\n\n\n\n\n4.3.2.2 concat()\nThe concat() function (in the main pandas namespace) performs concatenation operations along an axis while performing optional set logic (union or intersection) of the indexes (if any) on the other axes.\n\nimport pandas as pd\n\ndf1 = pd.DataFrame(\n    {\n        \"A\": [\"A0\", \"A1\", \"A2\", \"A3\"],\n        \"B\": [\"B0\", \"B1\", \"B2\", \"B3\"],\n        \"C\": [\"C0\", \"C1\", \"C2\", \"C3\"],\n        \"D\": [\"D0\", \"D1\", \"D2\", \"D3\"],\n    },\n    index=[0, 1, 2, 3],\n)\n\ndf2 = pd.DataFrame(\n    {\n        \"A\": [\"A4\", \"A5\", \"A6\", \"A7\"],\n        \"B\": [\"B4\", \"B5\", \"B6\", \"B7\"],\n        \"C\": [\"C4\", \"C5\", \"C6\", \"C7\"],\n        \"D\": [\"D4\", \"D5\", \"D6\", \"D7\"],\n    },\n    index=[4, 5, 6, 7],\n)\n\ndf3 = pd.DataFrame(\n    {\n        \"A\": [\"A8\", \"A9\", \"A10\", \"A11\"],\n        \"B\": [\"B8\", \"B9\", \"B10\", \"B11\"],\n        \"C\": [\"C8\", \"C9\", \"C10\", \"C11\"],\n        \"D\": [\"D8\", \"D9\", \"D10\", \"D11\"],\n    },\n    index=[8, 9, 10, 11],\n)\n\npd.concat([df1, df2, df3], keys=['x', 'y', 'z'])\n\n\n\n\n\n  \n    \n      \n      \n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      x\n      0\n      A0\n      B0\n      C0\n      D0\n    \n    \n      1\n      A1\n      B1\n      C1\n      D1\n    \n    \n      2\n      A2\n      B2\n      C2\n      D2\n    \n    \n      3\n      A3\n      B3\n      C3\n      D3\n    \n    \n      y\n      4\n      A4\n      B4\n      C4\n      D4\n    \n    \n      5\n      A5\n      B5\n      C5\n      D5\n    \n    \n      6\n      A6\n      B6\n      C6\n      D6\n    \n    \n      7\n      A7\n      B7\n      C7\n      D7\n    \n    \n      z\n      8\n      A8\n      B8\n      C8\n      D8\n    \n    \n      9\n      A9\n      B9\n      C9\n      D9\n    \n    \n      10\n      A10\n      B10\n      C10\n      D10\n    \n    \n      11\n      A11\n      B11\n      C11\n      D11\n    \n  \n\n\n\n\nThe default way of pd.concat() is vertically. Note that it will check the column names. If the column names don’t match, new columns will be created and nan values will be assigned.\nIf you want to concatenate the DataFrame horizontally you need to add axis=1 option. Similarly, row index will be checked before concatenating. See the following example.\n\n\nExample 4.16 \npd.concat([df1, df2, df3], axis=1)\n\n\n\n\n\n  \n    \n      \n      A\n      B\n      C\n      D\n      A\n      B\n      C\n      D\n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      0\n      A0\n      B0\n      C0\n      D0\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      1\n      A1\n      B1\n      C1\n      D1\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      2\n      A2\n      B2\n      C2\n      D2\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      3\n      A3\n      B3\n      C3\n      D3\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      4\n      NaN\n      NaN\n      NaN\n      NaN\n      A4\n      B4\n      C4\n      D4\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      5\n      NaN\n      NaN\n      NaN\n      NaN\n      A5\n      B5\n      C5\n      D5\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      6\n      NaN\n      NaN\n      NaN\n      NaN\n      A6\n      B6\n      C6\n      D6\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      7\n      NaN\n      NaN\n      NaN\n      NaN\n      A7\n      B7\n      C7\n      D7\n      NaN\n      NaN\n      NaN\n      NaN\n    \n    \n      8\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      A8\n      B8\n      C8\n      D8\n    \n    \n      9\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      A9\n      B9\n      C9\n      D9\n    \n    \n      10\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      A10\n      B10\n      C10\n      D10\n    \n    \n      11\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      NaN\n      A11\n      B11\n      C11\n      D11\n    \n  \n\n\n\n\n\n\nExample 4.17 Consider the deck example from Example 4.15. This time we would like to use pd.concat() to get the result.\n\nsuitlist = ['spades', 'hearts', 'clubs', 'diamonds']\nfacelist = list(range(1, 14))\ndecklist = [pd.DataFrame({'suit': suit, 'face': facelist}) for suit in suitlist]\ndeck = pd.concat(decklist, ignore_index=True)"
  },
  {
    "objectID": "contents/4/04-.html#data-aggregation-and-group-operations",
    "href": "contents/4/04-.html#data-aggregation-and-group-operations",
    "title": "4  Package: pandas",
    "section": "4.4 Data Aggregation and Group Operations",
    "text": "4.4 Data Aggregation and Group Operations\n\n4.4.1 split-apply-combine model\nWe would like to apply group operations based on the split-apply-combine model.\n\nIn the first stage of the process, data contained in a pandas object is split into groups based on one or more keys that you provide. We then use .groupby(keys) to perform the split step. The result is a grouped groupby object.\nOnce this is done, a function is applied to each group, producing a new value.\nFinally the results of all those function applications are combined into a result object. We may apply groupby functions directly as methods to groupby objects.The result is the combined result object.\n\n\n\nExample 4.18 \nimport pandas as pd\ndf = pd.DataFrame({'key1' : ['a', 'a', 'b', 'b', 'a'],\n                   'key2' : ['one', 'two', 'one', 'two', 'one'],\n                   'data1' : np.random.randn(5),\n                   'data2' : np.random.randn(5)})\ndf\n\n\n\n\n\n  \n    \n      \n      key1\n      key2\n      data1\n      data2\n    \n  \n  \n    \n      0\n      a\n      one\n      1.131205\n      -0.695254\n    \n    \n      1\n      a\n      two\n      -0.304263\n      -0.689704\n    \n    \n      2\n      b\n      one\n      1.423866\n      0.383788\n    \n    \n      3\n      b\n      two\n      -0.716951\n      1.631138\n    \n    \n      4\n      a\n      one\n      1.235810\n      -0.240931\n    \n  \n\n\n\n\nNow we want to group data1 in df by key1.\n\ngrouped = df['data1'].groupby(df['key1'])\ngrouped\n\n<pandas.core.groupby.generic.SeriesGroupBy object at 0x0000021F197328E0>\n\n\nWhat we get is a groupby object and we could apply group functions to it.\nThe method to look at each group is .get_group.\n\ngrouped.get_group('a')\n\n0    1.131205\n1   -0.304263\n4    1.235810\nName: data1, dtype: float64\n\n\nWe may directly apply some group functions to the groupby object.\n\ngrouped.mean()\n\nkey1\na    0.687584\nb    0.353458\nName: data1, dtype: float64\n\n\n\ngrouped.size()\n\nkey1\na    3\nb    2\nName: data1, dtype: int64\n\n\nWe could iterate over groups.\n\nfor name, group in grouped:\n    print('name', name)\n    print('group', group)\n\nname a\ngroup 0    1.131205\n1   -0.304263\n4    1.235810\nName: data1, dtype: float64\nname b\ngroup 2    1.423866\n3   -0.716951\nName: data1, dtype: float64\n\n\nWe could convert the group object into list and dictionary.\n\nlist(grouped)\n\n[('a',\n  0    1.131205\n  1   -0.304263\n  4    1.235810\n  Name: data1, dtype: float64),\n ('b',\n  2    1.423866\n  3   -0.716951\n  Name: data1, dtype: float64)]\n\n\n\ndict(list(grouped))\n\n{'a': 0    1.131205\n 1   -0.304263\n 4    1.235810\n Name: data1, dtype: float64,\n 'b': 2    1.423866\n 3   -0.716951\n Name: data1, dtype: float64}\n\n\n\n\n\n4.4.2 More aggregation functions\n\n.describe()\n.count()\n.sum()\n.mean()\n.median\n.std(), .var()\n.min(), .max()\n.prod()\nfirst(), .last()\n.agg()\n\n\n\n4.4.3 Some examples\n\nExample 4.19 Consider the following DataFrame.\n\nimport pandas as pd\ndf = pd.DataFrame({'location': ['East', 'East', 'East', 'East',\n                                'West', 'West', 'West', 'West'],\n                   'data': np.random.randn(8)},\n                   index=['Ohio', 'New York', 'Vermont', 'Florida',\n                          'Oregon', 'Nevada', 'California', 'Idaho'])\ndf.loc[['Vermont', 'Nevada', 'Idaho'], 'data'] = np.nan\n\nWe would like to fill in NA values with the mean from each group.\n\ndf.groupby('location').apply(lambda x: x.fillna(x.mean()))\n\nC:\\Users\\Xinli\\AppData\\Local\\Temp\\ipykernel_8772\\2040193686.py:1: FutureWarning:\n\nDropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n\n\n\n\n\n\n\n  \n    \n      \n      location\n      data\n    \n  \n  \n    \n      Ohio\n      East\n      -0.626595\n    \n    \n      New York\n      East\n      0.433917\n    \n    \n      Vermont\n      East\n      -0.283301\n    \n    \n      Florida\n      East\n      -0.657224\n    \n    \n      Oregon\n      West\n      -2.045580\n    \n    \n      Nevada\n      West\n      -0.582582\n    \n    \n      California\n      West\n      0.880416\n    \n    \n      Idaho\n      West\n      -0.582582\n    \n  \n\n\n\n\nWe could also fill in NA values with predefined values, similar to the non-groupby case.\n\ndf.groupby('location').apply(lambda x: x.fillna({'East': 0.1,\n                                                 'West': -0.5}[x.name]))\n\n\n\n\n\n  \n    \n      \n      location\n      data\n    \n  \n  \n    \n      Ohio\n      East\n      -0.626595\n    \n    \n      New York\n      East\n      0.433917\n    \n    \n      Vermont\n      East\n      0.100000\n    \n    \n      Florida\n      East\n      -0.657224\n    \n    \n      Oregon\n      West\n      -2.045580\n    \n    \n      Nevada\n      West\n      -0.500000\n    \n    \n      California\n      West\n      0.880416\n    \n    \n      Idaho\n      West\n      -0.500000"
  },
  {
    "objectID": "contents/4/04-.html#exercises",
    "href": "contents/4/04-.html#exercises",
    "title": "4  Package: pandas",
    "section": "4.5 Exercises",
    "text": "4.5 Exercises\nMost problems are based on [1].\n\nExercise 4.1 Please use the following code to generate a series ser, and then finish the following tasks.\n\nimport pandas as pd\nimport numpy as np\n\n\nmylist = list('abcedfghijklmnopqrstuvwxyz')\nmyarr = np.arange(26)\nmydict = dict(zip(mylist, myarr))\nser = pd.Series(mydict)\n\n\nConvert the series ser into a dataframe df with its index as another column on the dataframe.\nPick the two columns of df and set them into two serieses ser1 and ser2.\nCombine two series ser1 and ser2 to form a new dataframe newdf, and name their columns ser1 and ser2.\n\n\n\nExercise 4.2 Consider two serieses ser1 and ser2. You may use the following ser1 and ser2 as an example. The output of each questions below should be a series. You may want to learn the following commands:\n\nnp.union1d()\nnp.intersect1d()\nnp.isin()\n\n\nimport pandas as pd\n\nser1 = pd.Series([1, 2, 3, 4, 5])\nser2 = pd.Series([4, 5, 6, 7, 8])\n\n\nFind all the elements from ser1 that are also in ser2.\nFind all the elements from ser2 that are also in ser1.\nFrom ser1 remove items present in ser2.\nFind the union of ser1 and ser2.\nFind the intersection of ser1 and ser2.\nFind all the elemetns that are in either ser1 or ser2, but not both.\n\n\n\nExercise 4.3 (Some statistics) Please check the following commands and answer the following questions.\n\nnp.percentile()\n\nHow to get the minimum, 25th percentile, median, 75th, and max of a numeric series? You may use the following Series as an example.\n\nimport pandas as pd\nser = pd.Series(np.random.normal(10, 5, 25))\n\n\n\nExercise 4.4 Please use pd.Series.value_counts() to calculte the frequency counts of each unique value of the following Series.\n\nimport pandas as pd\nimport numpy as np\nser = pd.Series(np.take(list('abcdefgh'), np.random.randint(8, size=30)))\n\n\n\nExercise 4.5 Please keep the top 2 most frequent items of ser as it is and replace everything else as Other.\n\nimport pandas as pd\nimport numpy as np\nser = pd.Series(np.take(list('abcdefgh'), np.random.randint(8, size=30)))\n\n\n\nExercise 4.6 Please use pd.cut or pd.qcut to bin the Series ser into 10 equal deciles. You may use the following ser as an example.\n\nimport pandas as pd\nser = pd.Series(np.random.random(20))\n\n\n\nExercise 4.7 Consider the Series ser:\n\nimport pandas as pd\nimport numpy as np\nser = pd.Series(np.random.randint(1, 10, 7))\n\nFind the positions of numbers that are multiples of 3 from ser.\n\n\nExercise 4.8 Compute the mean of weights of each fruit.\n\nimport pandas as pd\nfruit = pd.Series(np.random.choice(['apple', 'banana', 'carrot'], 10))\nweights = pd.Series(np.linspace(1, 10, 10))\ndf = pd.DataFrame({'fruit': fruit, 'weights': weights})\n\n\n\nExercise 4.9 Consider the following DataFrame.\n\nimport pandas as pd\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n\n\nCheck if df has any missing values.\nPlease count the number of missing values in each column.\nPlease replace all missing values in Min.Price and Max.Price with their mean respectively.\n\n\n\n\nExercise 4.10 Replace the spaces in my_str = 'dbc deb abed gade' with the least frequent character.\n\n\nExercise 4.11 Suppress scientific notations like e-03 in df and print up to 4 numbers after decimal.\n\nimport pandas as pd\nimport numpy as np\ndf = pd.DataFrame(np.random.random(4)**10, columns=['random'])\ndf\n\n\n\n\n\n  \n    \n      \n      random\n    \n  \n  \n    \n      0\n      0.012124\n    \n    \n      1\n      0.026927\n    \n    \n      2\n      0.697808\n    \n    \n      3\n      0.180105\n    \n  \n\n\n\n\n\n\nExercise 4.12 Format the values in column random of df as percentages.\n\nimport pandas as pd\nimport numpy as np\ndf = pd.DataFrame(np.random.random(4), columns=['random'])\ndf\n\n\n\n\n\n  \n    \n      \n      random\n    \n  \n  \n    \n      0\n      0.894645\n    \n    \n      1\n      0.495184\n    \n    \n      2\n      0.255707\n    \n    \n      3\n      0.155605\n    \n  \n\n\n\n\n\n\nExercise 4.13 (Regular expressions) Please use regular expressions to finish the following tasks.\n\nMatch a string that has an a followed by zero or more b’s.\nMatch a string that has an a followed by one or more b’s.\nMatch a string that has an a followed by zero or one b.\nMatch a string that has an a followed by three b’s.\n\n\n\nExercise 4.14 (More regex) Find all words starting with a or e in a given string:\n\ntext = \"The following example creates an ArrayList with a capacity of 50 elements. Four elements are then added to the ArrayList and the ArrayList is trimmed accordingly.\"\n\n\n\nExercise 4.15 (More regex) Write a Python code to extract year, month and date from a url1:\n\nurl1= \"https://www.washingtonpost.com/news/football-insider/wp/2016/09/02/odell-beckhams-fame-rests-on-one-stupid-little-ball-josh-norman-tells-author/\"\n\n\n\nExercise 4.16 (More regex) Please use regex to parse the following str to create a dictionary.\n\ntext = r'''\n{\n    name: Firstname Lastname;\n    age: 100;\n    salary: 10000 \n}\n'''\n\n\n\nExercise 4.17 Consider the following DataFrame.\n\ndata = [['Evert van Dijk', 'Carmine-pink, salmon-pink streaks, stripes, flecks.  Warm pink, clear carmine pink, rose pink shaded salmon.  Mild fragrance.  Large, very double, in small clusters, high-centered bloom form.  Blooms in flushes throughout the season.'],\n        ['Every Good Gift', 'Red.  Flowers velvety red.  Moderate fragrance.  Average diameter 4\".  Medium-large, full (26-40 petals), borne mostly solitary bloom form.  Blooms in flushes throughout the season.'], \n        ['Evghenya', 'Orange-pink.  75 petals.  Large, very double bloom form.  Blooms in flushes throughout the season.'], \n        ['Evita', 'White or white blend.  None to mild fragrance.  35 petals.  Large, full (26-40 petals), high-centered bloom form.  Blooms in flushes throughout the season.'],\n        ['Evrathin', 'Light pink. [Deep pink.]  Outer petals white. Expand rarely.  Mild fragrance.  35 to 40 petals.  Average diameter 2.5\".  Medium, double (17-25 petals), full (26-40 petals), cluster-flowered, in small clusters bloom form.  Prolific, once-blooming spring or summer.  Glandular sepals, leafy sepals, long sepals buds.'],\n        ['Evita 2', 'White, blush shading.  Mild, wild rose fragrance.  20 to 25 petals.  Average diameter 1.25\".  Small, very double, cluster-flowered bloom form.  Blooms in flushes throughout the season.']]\n  \ndf = pd.DataFrame(data, columns = ['NAME', 'BLOOM']) \ndf \n\n\n\n\n\n  \n    \n      \n      NAME\n      BLOOM\n    \n  \n  \n    \n      0\n      Evert van Dijk\n      Carmine-pink, salmon-pink streaks, stripes, fl...\n    \n    \n      1\n      Every Good Gift\n      Red.  Flowers velvety red.  Moderate fragrance...\n    \n    \n      2\n      Evghenya\n      Orange-pink.  75 petals.  Large, very double b...\n    \n    \n      3\n      Evita\n      White or white blend.  None to mild fragrance....\n    \n    \n      4\n      Evrathin\n      Light pink. [Deep pink.]  Outer petals white. ...\n    \n    \n      5\n      Evita 2\n      White, blush shading.  Mild, wild rose fragran...\n    \n  \n\n\n\n\nPlease use regex methods to find all the () in each columns.\n\n\nExercise 4.18 Get the last two rows of df whose row sum is greater than 100.\n\nimport pandas as pd\ndf = pd.DataFrame(np.random.randint(10, 40, 60).reshape(-1, 4))\n\n\n\nExercise 4.19 The groupby object df_grouped is given below.\n\nimport pandas as pd\nimport numpy as np\ndf = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n                   'price': np.random.rand(9),\n                   'taste': np.random.randint(0, 11, 9)})\n\ndf_grouped = df.groupby(['fruit'])\n\n\nGet the group belonging to apple as a DataFrame.\nFind the second largest value of taste for banana.\nCompute the mean price for every fruit.\n\n\n\nExercise 4.20 Join df1 and df2 by fruit/pazham and weight/kilo.\n\ndf1 = pd.DataFrame({'fruit': ['apple', 'banana', 'orange'] * 3,\n                    'weight': ['high', 'medium', 'low'] * 3,\n                    'price': np.random.randint(0, 15, 9)})\n\ndf2 = pd.DataFrame({'pazham': ['apple', 'orange', 'pine'] * 2,\n                    'kilo': ['high', 'low'] * 3,\n                    'price': np.random.randint(0, 15, 6)})"
  },
  {
    "objectID": "contents/4/04-.html#projects",
    "href": "contents/4/04-.html#projects",
    "title": "4  Package: pandas",
    "section": "4.6 Projects",
    "text": "4.6 Projects\n\nExercise 4.21 Extract the valid emails from the series emails. The regex pattern for valid emails is provided as reference.\n\nimport pandas as pd\nemails = pd.Series(['buying books at amazom.com',\n                    'rameses@egypt.com',\n                    'matt@t.co',\n                    'narendra@modi.com'])\npattern = '[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,4}'\n\n\n\nExercise 4.22 Consider the following DataFrame.\n\nimport pandas as pd\nimport numpy as np\ndf = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv', usecols=[0,1,2,3,5])\n\n\nReplace NaN with string missing in columns Manufacturer, Model and Type.\nCreate an index as a combination of these three columns.\n\n\n\nExercise 4.23 Given the following DataFrame.\n\nimport pandas as pd\ndf = pd.DataFrame({\n    'name': ['James', 'Jane', 'Melissa', 'Ed', 'Neil'],\n    'age': [30, 40, 32, 67, 43],\n    'score': ['90%', '95%', '100%', '82%', '87%'],\n    'age_missing_data': [30, 40, 32, 67, None],\n    'income':[100000, 80000, 55000, 62000, 120000]\n})\n\n\nPlease use .map to create a new column numeric_score whose value is the number version of score.\nPlease use .apply to create a new column numeric_score whose value is the number version of score.\n\n\n\nExercise 4.24 From ser = pd.Series(['Apple', 'Orange', 'Plan', 'Python', 'Money']), find the words that contain at least 2 vowels.\n\n\nExercise 4.25 Please download the given file with sample emails, and use the following code to load the file and save it to a string content.\n\nwith open('assests/datasets/test_emails.txt', 'r') as f:\n    content = f.read()\n\nPlease use regex to play with content.\n\nGet all valid email address in content, from both the header part or the body part.\nThere are two emails in content. Please get the sender’s email and the receiver’s email from content.\nPlease get the sender’s name.\nPlease get the subject of each email.\n\n\n\nExercise 4.26 The following DataFrame is given.\n\nimport pandas as pd\ndf = pd.DataFrame([\"STD, City    State\",\n                   \"33, Kolkata    West Bengal\",\n                   \"44, Chennai    Tamil Nadu\",\n                   \"40, Hyderabad    Telengana\",\n                   \"80, Bangalore    Karnataka\"],\n                   columns=['row'])\n\n\nSplit the columns into a list with 3 entries.\nMake the first row (row 0) into a header.\nCreate a new DataFrame out of the data.\n\n\n\n\n\n\n[1] Prabhakaran, S. (2018). 101 pandas exercises for data analysis."
  },
  {
    "objectID": "contents/5/05-.html",
    "href": "contents/5/05-.html",
    "title": "5  Visualization",
    "section": "",
    "text": "The main reference for this Chapter is [1]."
  },
  {
    "objectID": "contents/5/05-.html#matplotlib.pyplot",
    "href": "contents/5/05-.html#matplotlib.pyplot",
    "title": "5  Visualization",
    "section": "5.1 matplotlib.pyplot",
    "text": "5.1 matplotlib.pyplot\nmatplotlib is a modern and classic plot library. Its main features are inspired by MATLAB. In this book we mostly use pyplot package from matplotlib. We use the following import convention:\n\nimport matplotlib.pyplot as plt\n\n\n5.1.1 matplotlib interface\nmatplotlib has two major application interfaces, or styles of using the library:\n\nAn explicit Axes interface that uses methods on a Figure or Axes object to create other Artists, and build a visualization step by step. You may treat this Figure object as a canvas, and Axes as plots on a canvas. There might be one or more plots on one canvas. This has also been called an object-oriented interface.\nAn implicit pyplot interface that keeps track of the last Figure and Axes created, and adds Artists to the object it thinks the user wants.\n\nHere is an example of an explicit interface.\n\nfig = plt.figure()\nax = fig.subplots()\nax.plot([1, 2, 3, 4], [0, 0.5, 1, 0.2])\n\n\n\n\nHere is an example of an implicit interface.\n\nplt.plot([1, 2, 3, 4], [0, 0.5, 1, 0.2])\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf the plot is not shown, you may want to type plt.show() to force the plot being rendered. However, to make plt.show() work is related to switching matplotlib backends, and is sometimes very complicated.\n\n\nThe purpose to explicitly use fig and ax is to have more control over the configurations. The first important configuration is subplots.\n\n.subplot()\n.subplots()\n.add_subplot()\n\nPlease see the following examples.\n\n\nExample 5.1 \nplt.subplot(1, 2, 1)\nplt.plot([1, 2, 3], [0, 0.5, 0.2])\n\n\n\n\n\n\n\nExample 5.2 \nplt.subplot(1, 2, 1)\nplt.plot([1, 2, 3], [0, 0.5, 0.2])\nplt.subplot(1, 2, 2)\nplt.plot([3, 2, 1], [0, 0.5, 0.2])\n\n\n\n\n\n\n\nExample 5.3 \nfig, axs = plt.subplots(1, 2)\naxs[0].plot([1, 2, 3], [0, 0.5, 0.2])\naxs[1].plot([3, 2, 1], [0, 0.5, 0.2])\n\n\n\n\n\n\n\nExample 5.4 \nimport numpy as np\nfig = plt.figure()\nax1 = fig.add_subplot(2, 2, 1)\nax2 = fig.add_subplot(2, 2, 3)\nax3 = fig.add_subplot(1, 2, 2)\n\nax3.plot([1, 2, 3], [0, 0.5, 0.2])\n\n\n\n\nThe auguments 2, 2, 1 means that we split the figure into a 2x2 grid and the axis ax1 is in the 1st position. The rest is understood in the same way.\n\n\nExample 5.5 If you don’t explicitly initialize fig and ax, you may use plt.gcf() and plt.gca() to get the handles for further operations.\n\nplt.subplot(1, 2, 1)\nax = plt.gca()\nax.plot([1, 2, 3], [0, 0.5, 0.2])\n\nplt.subplot(1, 2, 2)\nax = plt.gca()\nax.plot([3, 2, 1], [0, 0.5, 0.2])\n\n\n\n\n\nThe purpose to explicitly use fig and ax is to have more control over the configurations. For example, when generate a figure object, we may use figsize=(3, 3) as an option to set the figure size to be 3x3. dpi is another commonly modified option.\n\nfig = plt.figure(figsize=(2, 2), dpi=50)\nplt.plot([1, 2, 3], [0, 0.5, 0.2])\n\n\n\n\nIf you would like to change this setting later, you may use the following command before plotting.\n\nfig.set_size_inches(10, 10)\nfig.set_dpi(300)\nplt.plot([1, 2, 3], [0, 0.5, 0.2])\n\n\n\n\nYou may use fig.savefig('filename.png') to save the image into a file.\n\n\n5.1.2 Downstream packages\nThere are multiple packages depending on matplotlib to provide plotting. For example, you may directly plot from a Pandas DataFrame or a Pandas Series.\n\n\nExample 5.6 \nimport pandas as pd\nimport numpy as np\ns = pd.Series(np.random.randn(10).cumsum(), index=np.arange(0, 100, 10))\ns.plot()\n\n<AxesSubplot:>\n\n\n\n\n\n\ndf = pd.DataFrame(np.random.randn(10, 4).cumsum(0),\n                  columns=['A', 'B', 'C', 'D'],\n                  index=np.arange(0, 100, 10))\ndf.plot()\n\n<AxesSubplot:>\n\n\n\n\n\n\n\n\n5.1.3 plotting\n\n5.1.3.1 plt.plot()\nThis is the command for line plotting. You may use linestyle='--' and color='g' to control the line style and color. The style can be shortened as g--.\nHere is a list of commonly used linestyles and colors.\n\nline styles\n\nsolid or -\ndashed or --\ndashdot or -.\ndotted or :\n\nmarker styles\n\no as circle markers\n+ as plusses\n^ as triangles\ns as squares\n\ncolors\n\nb as blue\ng as green\nr as red\nk as black\nw as white\n\n\nThe input of plt.plot() is two lists x and y. If there is only one list inputed, that one will be recognized as y and the index of elements of y will be used as the dafault x.\n\n\nExample 5.7 \nplt.plot(np.random.randn(30).cumsum(), color='r', linestyle='--', marker='o')\n\n\n\n\nYou may compare it with this Example for the purpose of seaborn from next Section.\n\n\n\n5.1.3.2 plt.bar() and plt.barh()\nThe two commands make vertical and horizontal bar plots, respectively. ::: {#exm-}\n\nimport pandas as pd\ndata = pd.Series(np.random.rand(16), index=list('abcdefghijklmnop'))\n\nfig, axes = plt.subplots(2, 1)\naxes[0].bar(x=data.index, height=data, color='k', alpha=0.7)\naxes[1].barh(y=data.index, width=data, color='b', alpha=0.7)\n\n<BarContainer object of 16 artists>\n\n\n\n\n\nWe may also directly plot the bar plot from the Series.\n\nfig, axes = plt.subplots(2, 1)\ndata.plot.bar(ax=axes[0], color='k', alpha=0.7)\ndata.plot.barh(ax=axes[1], color='b', alpha=0.7)\n\n<AxesSubplot:>\n\n\n\n\n\n:::\nWith a DataFrame, bar plots group the values in each row together in a group in bars. This is easier if we directly plot from the DataFrame.\n\n\nExample 5.8 \ndf = pd.DataFrame(np.random.rand(6, 4),\n                  index=['one', 'two', 'three', 'four', 'five', 'six'],\n                  columns=pd.Index(['A', 'B', 'C', 'D'], name='Genus'))\ndf\n\n\n\n\n\n  \n    \n      Genus\n      A\n      B\n      C\n      D\n    \n  \n  \n    \n      one\n      0.567510\n      0.325200\n      0.894765\n      0.604747\n    \n    \n      two\n      0.221577\n      0.271110\n      0.050578\n      0.706701\n    \n    \n      three\n      0.645981\n      0.013974\n      0.712380\n      0.665214\n    \n    \n      four\n      0.951308\n      0.610438\n      0.682647\n      0.595708\n    \n    \n      five\n      0.021769\n      0.157346\n      0.893726\n      0.554695\n    \n    \n      six\n      0.291958\n      0.608744\n      0.166046\n      0.319448\n    \n  \n\n\n\n\n\ndf.plot.bar()\n\n<AxesSubplot:>\n\n\n\n\n\n\ndf.plot.barh(stacked=True, alpha=0.5)\n\n<AxesSubplot:>\n\n\n\n\n\n\n\n\n5.1.3.3 plt.scatter()\n\n\nExample 5.9 \nimport numpy as np\n\nN = 100\ndata = 0.9 * np.random.rand(N, 2)\narea = (20 * np.random.rand(N))**2 \nc = np.sqrt(area)\nplt.scatter(data[:, 0], data[:, 1], s=area, marker='^', c=c)\n\n<matplotlib.collections.PathCollection at 0x1b799bf6f70>\n\n\n\n\n\n\n\n\n5.1.3.4 plt.hist()\nHere are two plots with build-in statistics. The plot command will have statistics as outputs. To disable it we could send the outputs to a temporary variable _. ::: {#exm-histogram1}\n\nmu, sigma = 100, 15\nx = mu + sigma * np.random.randn(10000)\ny = mu-30 + sigma*2 * np.random.randn(10000)\n_ = plt.hist(x, 50, density=True, facecolor='g', alpha=0.75)\n_ = plt.hist(y, 50, density=True, facecolor='r', alpha=0.75)\n\n\n\n\n:::\n\n\n\n5.1.4 plt.boxplot()\n\n\nExample 5.10 \nspread = np.random.rand(50) * 100\ncenter = np.ones(30) * 50\nflier_high = np.random.rand(10) * 100 + 100\nflier_low = np.random.rand(10) * -100\ndata = np.concatenate((spread, center, flier_high, flier_low)).reshape(50, 2)\n\n_ = plt.boxplot(data, flierprops={'markerfacecolor': 'g', 'marker': 'D'})\n\n\n\n\n\n\n\n5.1.5 Titles, labels and legends\n\nTitles\n\nplt.title(label), plt.xlabel(label), plt.ylabel(label) will set the title/xlabel/ylabel.\nax.set_title(label), ax.set_xlabel(label), ax.set_ylabel(label) will do the same thing.\n\nLabels\n\nplt methods\n\nxlim(), ylim(), xticks(), yticks(), xticklabels(), yticklabels()\nall the above with arguments\n\nax methods\n\nget_xlim(), get_ylim(), etc..\nset_xlim(), set_ylim(), etc..\n\n\nLegneds\n\nFirst add label option to each piece when plotting, and then add ax.legends() or plt.legends() at the end to display the legends.\nYou may use handles, labels = ax.get_legend_handles_labels() to get the handles and labels of the legends, and modify them if necessary.\n\n\n\n\nExample 5.11 \nimport numpy as np\nfig, ax = plt.subplots(1, 1)\nax.plot(np.random.randn(1000).cumsum(), 'k', label='one')\nax.plot(np.random.randn(1000).cumsum(), 'r--', label='two')\nax.plot(np.random.randn(1000).cumsum(), 'b.', label='three')\n\nax.set_title('Example')\nax.set_xlabel('x')\nax.set_ylabel('y')\n\nax.set_yticks([-40, 0, 40])\nax.set_yticklabels(['good', 'bad', 'ugly'])\n\nax.legend(loc='best')\n\n<matplotlib.legend.Legend at 0x1b799bb8c10>\n\n\n\n\n\n\n\n\n5.1.6 Annotations\n\nThe command to add simple annotations is ax.text(). The required auguments are the coordinates of the text and the text itself. You may add several options to modify the style.\nIf arrows are needed, we may use ax.annotation(). Here an arrow will be shown from xytext to xy. The style of the arrow is controlled by the option arrowprops.\n\n\n\nExample 5.12 \nfig, ax = plt.subplots(figsize=(5, 5))\nax.plot(np.random.randn(1000).cumsum(), 'k', label='one')\nax.text(500, 0, 'Hello world!', family='monospace', fontsize=15, c='r')\nax.annotate('test', xy=(400, 0), xytext=(400, -10), c='r',\n            arrowprops={'facecolor': 'black',\n                        'shrink': 0.05})\n\nText(400, -10, 'test')\n\n\n\n\n\n\n\n\n5.1.7 Example\n\nExample 5.13 The stock data can be downloaded from here.\n\nfrom datetime import datetime\nfig, ax = plt.subplots()\ndata = pd.read_csv('assests/datasets/spx.csv', index_col=0, parse_dates=True)\nspx = data['SPX']\nspx.plot(ax=ax, style='k-')\ncrisis_data = [(datetime(2007, 10, 11), 'Peak of bull market'),\n               (datetime(2008, 3, 12), 'Bear Stearns Fails'),\n               (datetime(2008, 9, 15), 'Lehman Bankruptcy')]\nfor date, label in crisis_data:\n    ax.annotate(label, xy=(date, spx.asof(date) + 75),\n                xytext=(date, spx.asof(date) + 225),\n                arrowprops=dict(facecolor='black', headwidth=4, width=2,\n                                headlength=4),\n                horizontalalignment='left', verticalalignment='top')\nax.set_xlim(['1/1/2007', '1/1/2011'])\nax.set_ylim([600, 1800])\n_ = ax.set_title('Important dates in the 2008-2009 financial crisis')\n\n\n\n\n\n\nExample 5.14 Here is an example of arrows with different shapes. For more details please read the official document.\n\nfig, ax = plt.subplots()\n\nx = np.linspace(0, 20, 1000)\nax.plot(x, np.cos(x))\nax.axis('equal')\n\nax.annotate('local maximum', xy=(6.28, 1), xytext=(10, 4),\n            arrowprops=dict(facecolor='black', shrink=0.05))\n\nax.annotate('local minimum', xy=(5 * np.pi, -1), xytext=(2, -6),\n            arrowprops=dict(arrowstyle=\"->\",\n                            connectionstyle=\"angle3,angleA=0,angleB=-90\",\n                            color='r'))\n\nText(2, -6, 'local minimum')"
  },
  {
    "objectID": "contents/5/05-.html#seaborn",
    "href": "contents/5/05-.html#seaborn",
    "title": "5  Visualization",
    "section": "5.2 seaborn",
    "text": "5.2 seaborn\nThere are some new libraries built upon matplotlib, and seaborn is one of them. seaborn is for statistical graphics.\nseaborn is used imported in the following way.\n\nimport seaborn as sns\n\nseaborn also modifies the default matplotlib color schemes and plot styles to improve readability and aesthetics. Even if you do not use the seaborn API, you may prefer to import seaborn as a simple way to improve the visual aesthetics of general matplotlib plots.\nTo apply sns theme, run the following code.\n\nsns.set_theme()\n\nLet us directly run a few codes from the last section and compare the differences between them.\n\n\nExample 5.15 \nplt.plot(np.random.randn(30).cumsum(), color='r', linestyle='--', marker='o')\n\n\n\n\nPlease compare the output of the same code with the previous example\n\n\n5.2.1 Scatter plots with relplot()\nThe basic scatter plot method is scatterplot(). It is wrapped in relplot() as the default plotting method. So here we will mainly talk about relplot(). It is named that way because it is designed to visualize many different statistical relationships.\nThe idea of relplot() is to display points based on the variables x and y you choose, and assign different properties to alter the apperance of the points.\n\ncol will create multiple plots based on the column you choose.\nhue is for color encoding, based on the column you choose.\nsize will change the marker area, based on the column you choose.\nstyle will change the marker symbol, based on the column you choose.\n\n\nExample 5.16 Consider the following example. tips is a DataFrame, which is shown below.\n\nimport seaborn as sns\ntips = sns.load_dataset(\"tips\")\ntips\n\n\n\n\n\n  \n    \n      \n      total_bill\n      tip\n      sex\n      smoker\n      day\n      time\n      size\n    \n  \n  \n    \n      0\n      16.99\n      1.01\n      Female\n      No\n      Sun\n      Dinner\n      2\n    \n    \n      1\n      10.34\n      1.66\n      Male\n      No\n      Sun\n      Dinner\n      3\n    \n    \n      2\n      21.01\n      3.50\n      Male\n      No\n      Sun\n      Dinner\n      3\n    \n    \n      3\n      23.68\n      3.31\n      Male\n      No\n      Sun\n      Dinner\n      2\n    \n    \n      4\n      24.59\n      3.61\n      Female\n      No\n      Sun\n      Dinner\n      4\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      239\n      29.03\n      5.92\n      Male\n      No\n      Sat\n      Dinner\n      3\n    \n    \n      240\n      27.18\n      2.00\n      Female\n      Yes\n      Sat\n      Dinner\n      2\n    \n    \n      241\n      22.67\n      2.00\n      Male\n      Yes\n      Sat\n      Dinner\n      2\n    \n    \n      242\n      17.82\n      1.75\n      Male\n      No\n      Sat\n      Dinner\n      2\n    \n    \n      243\n      18.78\n      3.00\n      Female\n      No\n      Thur\n      Dinner\n      2\n    \n  \n\n244 rows × 7 columns\n\n\n\n\nsns.relplot(data=tips,\n            x=\"total_bill\", y=\"tip\", col=\"time\",\n            hue=\"smoker\", style=\"smoker\", size=\"size\")\n\n<seaborn.axisgrid.FacetGrid at 0x1b79b52dca0>\n\n\n\n\n\n\nThe default type of plots for relplot() is scatter plots. However you may change it to line plot by setting kind='line'.\n\n\nExample 5.17 \ndots = sns.load_dataset(\"dots\")\nsns.relplot(data=dots, kind=\"line\",\n            x=\"time\", y=\"firing_rate\", col=\"align\",\n            hue=\"choice\", size=\"coherence\", style=\"choice\",\n            facet_kws=dict(sharex=False))\n\n<seaborn.axisgrid.FacetGrid at 0x1b79a9752b0>\n\n\n\n\n\n\n\n\n5.2.2 regplot()\nThis method is a combination between scatter plots and linear regression.\n\nExample 5.18 We still use tips as an example.\n\nsns.regplot(x='total_bill', y='tip', data=tips)\n\n<AxesSubplot:xlabel='total_bill', ylabel='tip'>\n\n\n\n\n\n\n\n\n5.2.3 pairplot()\nThis is a way to display the pairwise relations among several variables.\n\nExample 5.19 The following code shows the pairplots among all numeric data in tips.\n\nsns.pairplot(tips, diag_kind='kde', plot_kws={'alpha': 0.2})\n\n<seaborn.axisgrid.PairGrid at 0x1b79a889340>\n\n\n\n\n\n\n\n\n5.2.4 barplot\n\n\nExample 5.20 \nsns.barplot(x='total_bill', y='day', data=tips, orient='h')\n\n<AxesSubplot:xlabel='total_bill', ylabel='day'>\n\n\n\n\n\nIn the plot, there are several total_bill during each day. The value in the plot is the average of total_bill in each day, and the black line stands for the 95% confidence interval.\n\nsns.barplot(x='total_bill', y='day', hue='time', data=tips, orient='h')\n\n<AxesSubplot:xlabel='total_bill', ylabel='day'>\n\n\n\n\n\nIn this plot, lunch and dinner are distinguished by colors.\n\n\n\n5.2.5 Histogram\n\n\nExample 5.21 \nmu, sigma = 100, 15\nx = mu + sigma * np.random.randn(10000)\ny = mu-30 + sigma*2 * np.random.randn(10000)\ndf = pd.DataFrame(np.array([x,y]).T)\nsns.histplot(df, bins=100, kde=True)\n\n<AxesSubplot:ylabel='Count'>\n\n\n\n\n\nPlease compare this plot with this Example"
  },
  {
    "objectID": "contents/5/05-.html#examples",
    "href": "contents/5/05-.html#examples",
    "title": "5  Visualization",
    "section": "5.3 Examples",
    "text": "5.3 Examples\n\n5.3.1 Example 1: USA.gov Data From Bitly\nIn 2011, URL shortening service Bitly partnered with the US government website USA.gov to provide a feed of anonymous data gathered from users who shorten links ending with .gov or .mil. The data is gotten from [1].\nThe data file can be downloaded from here. The file is mostly in JSON. It can be converted into a DataFrame by the following code.\n\nimport pandas as pd\nimport numpy as np\nimport json\npath = 'assests/datasets/example.txt'\ndf = pd.DataFrame([json.loads(line) for line in open(path)])\n\nWe mainly use tz and a columns. So let us clean it.\n\ndf['tz'] = df['tz'].fillna('Missing')\ndf['tz'][df['tz'] == ''] = 'Unknown'\ndf['a'] = df['a'].fillna('Missing')\ndf['a'][df['a'] == ''] = 'Unknown'\n\nWe first want to extract the timezone infomation from it. The timezone info is in the column tz.\n\ntzone = df['tz']\ntvc = tzone.value_counts()\ntvc\n\nAmerica/New_York        1251\nUnknown                  521\nAmerica/Chicago          400\nAmerica/Los_Angeles      382\nAmerica/Denver           191\n                        ... \nEurope/Uzhgorod            1\nAustralia/Queensland       1\nEurope/Sofia               1\nAmerica/Costa_Rica         1\nAmerica/Tegucigalpa        1\nName: tz, Length: 98, dtype: int64\n\n\nAfter cleaning data, we would like to visulize the value counts.\n\nimport seaborn as sns\nsns.barplot(x=tvc[:10].values, y=tvc[:10].index)\n\n<AxesSubplot:>\n\n\n\n\n\nWe then would like to extract information from the column a. This column is about the agent of the connection. The important info is the part before the space ' '.\n\nagent = df['a']\nagent = agent.str.split(' ').str[0]\navc = agent.value_counts()\navc[:10]\n\nMozilla/5.0                 2594\nMozilla/4.0                  601\nGoogleMaps/RochesterNY       121\nMissing                      120\nOpera/9.80                    34\nTEST_INTERNET_AGENT           24\nGoogleProducer                21\nMozilla/6.0                    5\nBlackBerry8520/5.0.0.681       4\nBlackBerry8520/5.0.0.592       3\nName: a, dtype: int64\n\n\nNow let us assume that, if Windows appears in column a the user is using Windows os, if not then not. In this case, the os can be detected by the following code.\n\ndf['os'] = np.where(df['a'].str.contains('Windows'), 'Windows', 'Not Windows')\n\nNow we can make a bar plot about the counts based on os and timezone.\n\ntz_os_counts = df.groupby(['tz', 'os']).size().unstack().fillna(0)\ntz_os_counts.head()\n\n\n\n\n\n  \n    \n      os\n      Not Windows\n      Windows\n    \n    \n      tz\n      \n      \n    \n  \n  \n    \n      Africa/Cairo\n      0.0\n      3.0\n    \n    \n      Africa/Casablanca\n      0.0\n      1.0\n    \n    \n      Africa/Ceuta\n      0.0\n      2.0\n    \n    \n      Africa/Johannesburg\n      0.0\n      1.0\n    \n    \n      Africa/Lusaka\n      0.0\n      1.0\n    \n  \n\n\n\n\nWe then turn it into a DataFrame using the .stack(), .unstack() tricks.\n\ntovc = tz_os_counts.stack()[tz_os_counts.sum(axis=1).nlargest(10).index]\ntovc.name = 'count'\ndftovc = pd.DataFrame(tovc).reset_index()\n\nFinally we may draw the bar plot.\n\nsns.barplot(x='count', y='tz', hue='os', data=dftovc)\n\n<AxesSubplot:xlabel='count', ylabel='tz'>\n\n\n\n\n\n\n\n5.3.2 Example 2: US Baby Names 1880–2010\nThe United States Social Security Administration (SSA) has made available data on the frequency of baby names from 1880 through the present. Hadley Wickham, an author of several popular R packages, has often made use of this dataset in illustrating data manipulation in R. The dataset can be downloaded from here as a zip file. Please unzip it and put it in your working folder.\nIn the folder there are 131 .txt files. The naming scheme is yob + the year. Each file contains 3 columns: name, gender, and counts. We would like to add a column year, and combine all files into a single DataFrame. In our example, the year is from 1880 to 2010.\n\nimport pandas as pd\n\npath = 'assests/datasets/babynames/'\ndflist = list()\nfor year in range(1880, 2011):\n    filename = path + 'yob' + str(year) + '.txt'\n    df = pd.read_csv(filename, names=['name', 'gender', 'counts'])\n    df['year'] = year\n    dflist.append(df)\ndf = pd.concat(dflist, ignore_index=True)\n\nWe can plot the total births by sex and year.\n\nimport seaborn as sns\n\nsns.relplot(data=df.groupby(['gender', 'year']).sum().reset_index(),\n            x='year', y='counts', hue='gender', kind='line')\n\n\n\n<seaborn.axisgrid.FacetGrid at 0x1b79fc81250>\n\n\n\n\n\nFor further analysis, we would like to compute the proportions of each name relative to the total number of births per year per gender.\n\ndef add_prop(group):\n    group['prop'] = group.counts / group.counts.sum()\n    return group\n\ndf = df.groupby(['gender', 'year']).apply(add_prop)\ndf.head()\n\n\n\n\n\n\n\n  \n    \n      \n      name\n      gender\n      counts\n      year\n      prop\n    \n  \n  \n    \n      0\n      Mary\n      F\n      7065\n      1880\n      0.077643\n    \n    \n      1\n      Anna\n      F\n      2604\n      1880\n      0.028618\n    \n    \n      2\n      Emma\n      F\n      2003\n      1880\n      0.022013\n    \n    \n      3\n      Elizabeth\n      F\n      1939\n      1880\n      0.021309\n    \n    \n      4\n      Minnie\n      F\n      1746\n      1880\n      0.019188\n    \n  \n\n\n\n\nNow we would like to keep the first 100 names in each year, and save it as a new DataFrame top100.\n\ntop100 = (\n    df.groupby(['year', 'gender'])\n    .apply(lambda x: df.loc[x['counts'].nlargest(100).index])\n    .drop(columns=['year', 'gender'])\n    .reset_index()\n    .drop(columns='level_2')\n)\ntop100.head()\n\n\n\n\n\n\n\n  \n    \n      \n      year\n      gender\n      name\n      counts\n      prop\n    \n  \n  \n    \n      0\n      1880\n      F\n      Mary\n      7065\n      0.077643\n    \n    \n      1\n      1880\n      F\n      Anna\n      2604\n      0.028618\n    \n    \n      2\n      1880\n      F\n      Emma\n      2003\n      0.022013\n    \n    \n      3\n      1880\n      F\n      Elizabeth\n      1939\n      0.021309\n    \n    \n      4\n      1880\n      F\n      Minnie\n      1746\n      0.019188\n    \n  \n\n\n\n\nNote that level_2 is related to the original index after reset_index(). That’s why we don’t need it here.\nNow we would like to draw the trend of some names.\n\nnamelist = ['John', 'Harry', 'Mary']\nsns.relplot(data=top100[top100['name'].isin(namelist)],\n            x='year', y='counts', hue='name', kind='line')\n\n\n\n<seaborn.axisgrid.FacetGrid at 0x1b7a02e9a60>\n\n\n\n\n\nNow we would like to analyze the ending of names.\n\ndf['ending'] = df['name'].str[-1]\nendingcount = df.groupby(['gender', 'year', 'ending']).sum().reset_index()\n\nWe would like to draw barplots to show the distributions in year 1910, 1960 and 2010.\n\ncertainyear = endingcount[endingcount['year'].isin([1910, 1960, 2010])]\nimport matplotlib.pyplot as plt\n\nfig, axs = plt.subplots(2, 1, figsize=(10,7))\nsns.barplot(data=certainyear[endingcount['gender']=='M'],\n            x='ending', y='prop', hue='year', ax=axs[0])\nsns.barplot(data=certainyear[endingcount['gender']=='F'],\n            x='ending', y='prop', hue='year', ax=axs[1]).legend_.remove()\n\n\n\n\n\n\nWe would also like to draw the line plot to show the trending of certain letters through years.\n\nsns.relplot(data=endingcount[endingcount.ending.isin(['d', 'n', 'y'])],\n            x='year', y='prop', hue='ending', kind='line')\n\n\n\n<seaborn.axisgrid.FacetGrid at 0x1b7a4634d30>"
  },
  {
    "objectID": "contents/5/05-.html#exercises",
    "href": "contents/5/05-.html#exercises",
    "title": "5  Visualization",
    "section": "5.4 Exercises",
    "text": "5.4 Exercises\n\nExercise 5.1 Please download the mtcars file from here and read it as a DataFrame. Then create a scatter plot of the drat and wt variables from mtcars and color the dots by the carb variable.\n\n\nExercise 5.2 Please consider the baby name dataset. Please draw the trends of counts of names ending in a, e, n across years for each gender."
  },
  {
    "objectID": "contents/5/05-.html#projects",
    "href": "contents/5/05-.html#projects",
    "title": "5  Visualization",
    "section": "5.5 Projects",
    "text": "5.5 Projects\n\nExercise 5.3 Please read the file as a DataFrame from here. This is the Dining satisfaction with quick service restaurants questionare data provided by Dr. Siri McDowall, supported by DART SEED grant.\n\nPlease pick out all rating columns. Excluding last.visit, visit.again and recommend, compute the mean of the rest and add it to the DataFrame as a new column.\nUse a plot to show the relations among these four columns: last.visit, visit.again, recommend and mean.\nLook at the column Profession. Keep Student, and change everything else to be Professional, and add it as a new column Status to the DataFrame.\nDraw the histogram of mean with respect to Status.\nFind the counts of each recommend rating for each Status and draw the barplot. Do the same to last.visit/Status and visit.again/Status.\nExploer the dataset and draw one plot.\n\n\n\nExercise 5.4 Please use the baby name dataset. We would like to consider the diversity of the names. Please compute the number of popular names in top 50% for each year each gender. Draw a line plot to show the trend and discuss the result.\n\n\n\n\n\n[1] McKinney, W. (2017). Python for data analysis: Data wrangling with pandas, NumPy, and IPython. O’Reilly Media."
  },
  {
    "objectID": "contents/6/06-.html",
    "href": "contents/6/06-.html",
    "title": "6  Classes/Packages for Python",
    "section": "",
    "text": "Functions are declared with the def keyword and returned from the return keyword.\n\n\nExample 6.1 \ndef my_function(x, y, z=1.5):\n    if z > 1:\n        return z * (x + y)\n    else:\n        return z / (x + y)\n\n\nEach function can have positional arguments and keyword arguments.\n\nKeyword arguments are most commonly used to specify default values.\nIf no keywords are given, all arguments will be recognized by the positions.\nIf both positional arguments and keyword arguments are given, positional arguments have to be in front.\nThe order of keyword arguments are not important.\n\n\n\n\n\n\n\nNote\n\n\n\nAlthough there are global variable, it is always ecouraged to use local variables only. This means that the variables in and out of a function (as well as classes that we will talk about later) are not the same, even if they have the same name.\n\n\n\nExample 6.2 (Mutable objects as default value) It is highly recommended NOT to set any mutatable objects as the default value of an input of a function. The reason is that this default object is initialized when the function is defined, not when the function is called. Then all function calls will share the same default object.\nA typical example is an empty list. If you use an empty list as the defaul value, that list will be passed to the next function call, which is no longer empty. Please see the following example.\n\ndef add(x=[]):\n    x.append(1)\n    return x\n\nadd()\n\n[1]\n\n\n\nadd()\n\n[1, 1]\n\n\n\nadd()\n\n[1, 1, 1]\n\n\nEvery time the function is called with no arguments, the default value is used, which is the same list initialized at the beginning. The list at the begining is an empty list. But after we put things inside, it is no longer empyt.\nIf you want to set a mutable object as a default, the way is as follows:\n\ndef add(x=None):\n    if x is None:\n        x = list()\n    x.append(1)\n    return x\n\nadd()\n\n[1]\n\n\n\nadd()\n\n[1]\n\n\n\nadd()\n\n[1]"
  },
  {
    "objectID": "contents/6/06-.html#classes",
    "href": "contents/6/06-.html#classes",
    "title": "6  Classes/Packages for Python",
    "section": "6.2 Classes",
    "text": "6.2 Classes\nA class is an abstract structure that can be used to hold both variables and functions. Variables in a class are called attributes, and functions in a class are called methods.\nA class is defined in the following way.\n\nclass Circle:\n    def __init__(self, radius=1):\n        self.radius = radius\n    \n    def area(self):\n        return self.radius**2*3.14 \n\nIn this example, we define a class Circle, which represents a circle. There is one attribute radius, and one method area. When define a cirlce, we need to specify its radius, and we could use the method area to compute the area of the circle.\n\ncir1 = Circle()\ncir2 = Circle(radius=5)\n\ncir1.area()\n\n3.14\n\n\n\ncir2.area()\n\n78.5\n\n\nHere we define two circles. The first circle cir1 is of radius 1. This 1 comes from the default value. Check the definition of Circle.__init__().\nThe second circle cir2 is of radius 5, and this number is specified when we initialize the Circle instance.\nThen we compute the areas of these two circles by calling the area() method. You can also use cir1.radius to get access the radius of the circle. The syntax difference between attributes and methods is the () at the end.\n\n6.2.1 self\nYou may notice the self variable in the definition of the classes. The self is used to refered to the class its. When you want to get access to the class attributes or the class methods, you may use self.\nTake the code as an example.\n\nclass Circle:\n    def __init__(self, radius=1):\n        self.radius = radius\n\nIn the __init__ function, there are two radius.\n\nradius is the local variable that is used by the function. It is also the input argument.\nself.radius is the class attribute, that is shared by all class methods. For example, we may add another class method to the class Circle.\n\n\nclass Circle:\n    def __init__(self, radius=1):\n        self.radius = radius\n    \n    def area(self):\n        return self.radius**2*3.14 \n    \n    def perimeter(self):\n        return self.radius*3.14*2\n\nBoth area() and perimeter() use the same self.radius.\n\n\n\n\n\n\nNote\n\n\n\nClass attributes are defined in the __init__() function.\n\n\n\n\n6.2.2 A design example\nAssume that we live in a world without Pandas, and we would like to design a table object. Then what do we need?\nA table should have multiple rows and multiple columns. We should be able to get access entries by columns and row index. We should also be able to display the table by using the print funciton.\n\n\n\n\n\n\nNote\n\n\n\nThe .__str__() method will be called when you try to print the object. If you don’t explicitly override it, the type of the object will be shown.\n\n\nTherefore we may write the following class.\n\nclass myTableClass():\n    def __init__(self, listoflist=None):\n        if listoflist is None:\n            listoflist = [[]]\n        self.nrows = len(listoflist)\n        self.ncols = len(listoflist[0])\n        self.data = listoflist\n        self.shape = (self.nrows, self.ncols)\n    \n    def get(self, i, j):\n        return self.data[i][j]\n\n    def __str__(self):\n        tmp = [' '.join([str(x) for x in row]) for row in self.data]\n        return '\\n'.join(tmp)\n\nThis is a very brief table object. We may add more things to it. For example, we could talk about column names.\n\nclass myTableClass():\n    def __init__(self, listoflist=None, columns=None):\n        if listoflist is None:\n            listoflist = [[]]\n        if columns is None:\n            columns = list()\n        self.nrows = len(listoflist)\n        self.ncols = len(listoflist[0])\n        self.data = listoflist\n        self.shape = (self.nrows, self.ncols)\n        self.columns = columns\n    \n    def get(self, i, j):\n        return self.data[i][j]\n\n    def rename(self, columns=None):\n        if columns is not None:\n            self.columns = columns\n\n    def __str__(self):\n        tmp = [' '.join([str(x) for x in row]) for row in self.data]\n        if len(self.columns) != 0:\n            tmp.insert(0, self.columns)\n        return '\\n'.join(tmp)\n\n\n\n\n\n\n\nNote\n\n\n\nIn Jupyter notebook or similar environment, we might directly call df to show a DataFrame and the shown DataFrame is rendered very pretty. This is due to the IPython.display.display() method, and is part of IPython console components."
  },
  {
    "objectID": "contents/6/06-.html#inheritance",
    "href": "contents/6/06-.html#inheritance",
    "title": "6  Classes/Packages for Python",
    "section": "6.3 Inheritance",
    "text": "6.3 Inheritance\nOne of the most important feature of classes is inheritance. Attributes and methods can be passed from parents to children, and child classes can override those attributes and methods if needed.\nFor example, we would like to first write a people class.\n\nclass people():\n    def __init__(self, name='default', age=20):\n        self.name = name\n        self.age = age\n\n    def eat(self):\n        print('eat something.')\n\nThis people class defines a people who can eat. Then using this people class, we could build a children class: student.\n\nclass student(people):\n    pass\n\n\nstu1 = student('name1', 10)\nstu1.eat()\nstu1.name\n\neat something.\n\n\n'name1'\n\n\n\ntype(stu1)\n\n__main__.student\n\n\nNow you can see that this stu1 is a student, but it has all attributes and methods as a people. However at current stage student and people are exactly the same since we don’t have any new codes for student. Let us improve it a little bit.\n\nclass student(people):\n    def __init__(self, name='default', age=20, grade=1):\n        super().__init__(name, age)\n        self.grade = grade\n\n    def eat(self):\n        print('eat in the cafe.')\n\nstu1 = student('name1', 10)\nstu1.eat()\n\neat in the cafe.\n\n\nNow student class override the eat() method from people. If someone is a student, he or she will eat in the cafe instead of just eat something.\nIn addition, you may also notice that the __init__() constructor function is also overriden. The first part is super().__init__(name, age) which is just call the people’s constructor function. The second part is new in student, that we add a new attribute grade to it. Now stu1 have attributes from people and the new attribute defined in student.\n\nstu1.name, stu1.age\n\n('name1', 10)\n\n\n\nstu1.grade\n\n1"
  },
  {
    "objectID": "contents/6/06-.html#packages-modules",
    "href": "contents/6/06-.html#packages-modules",
    "title": "6  Classes/Packages for Python",
    "section": "6.4 packages / modules",
    "text": "6.4 packages / modules\nMain reference is RealPython and [1].\n\n6.4.1 import\nIn most cases we won’t only write one single Python file. If we want to use codes from other files, we need to import.\n\nIf both files are in the same folder, e.g. file1.py and file2.py, you may just put import file2 in file1.py, and use file2.myfunction() to call functions or variables defined in file2.py.\nIf both files are in the same folder, and you just want to use one function from file1.py in file2.py, you may from file1 import myfunction(), and then directly write myfunction() in file2.py.\n\n\nExample 6.3 This is from file1.py.\n\ns = \"This is from file1.py.\"\na = [100, 200, 300]\nprint(s)\n\ndef foo(arg):\n    print(f'arg = {arg}')\n\nclass Foo:\n    pass\n\nThis is from file1.py.\n\n\nIn file2.py, we could get access to these variables and functions and classes as follows.\n\nimport file1\nfile1.s\n\n'This is from file1.py.'\n\n\n\nfile1.a\n\n[100, 200, 300]\n\n\n\nfile1.foo(file1.a)\n\narg = [100, 200, 300]\n\n\n\nfile1.Foo()\n\n<file1.Foo at 0x2cee6b4aa90>\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAn alternative way is to use from <module> import <names> to directly use the names without the file1. prefix.\n\n\nPlease see the following Example to get a feel about how namespace works.\n\n\nExample 6.4 \ns = 'foo'\na = ['foo', 'bar', 'baz']\n\nfrom file1 import s as string, a as alist\ns\n\n'foo'\n\n\n\nstring\n\n'This is from file1.py.'\n\n\n\na\n\n['foo', 'bar', 'baz']\n\n\n\nalist\n\n[100, 200, 300]\n\n\n\nWe may use dir() to look at all objects in the current namespace.\n\n\n6.4.2 __name__\n__name__ is a variable to tell you want is the current active namespace. See the following example.\n\n\nExample 6.5 \nimport file1\nfile1.__name__\n\n'file1'\n\n\nThe result file1 means that the codes in file1.py are now treated as a package and are imported into other files.\n\n__name__\n\n'__main__'\n\n\nThe result __main__ means that the codes we are writing now are treated as in the “active” enviroment.\nYou may see the following codes in a lot of places.\n\nif __name__ == '__main__':\n    pass\n\nIt means that the following codes will only be run in the “active” mode. If you import the codes as a package, these part of codes won’t be run.\n\n\n\n6.4.3 Packages\nPacages is a way to group and organize mutliple modules. It allow for a hierachical structuring of the module namespace using dot notation.\nCreating a package is straightforward, since it makes use of the operating system’s inherent hierarchical file structure.\nPython defines two types of packages, regular packages and namespace packages. The above package is the regular one. Namespace packages allow codes are spread among different folders. We won’t talk about it in this course.\nTo create a regular package, what you need to do is to organize the files in suitable folders, and then add an __init__.py in each folder. The file can be empty, or you could add any initialization codes for the package which is represented by the folder.\n\n\n\n\n\n\nNote\n\n\n\nIn the past __init__.py is required for a package. After Python 3.3 the namespace package is introduced, the __init__.py is not required (but recommended) for regular packages, and cannot be used for namespace packages.\n\n\nLet us put the previous file1.py and file2.py into subfolder assests/codes/. To make it into a package assests and a subpackage codes, we need to put __init__.py in each folder.\n\nimport assests.codes.file1 as f1\nf1.s\n\n'This is from file1.py.'"
  },
  {
    "objectID": "contents/6/06-.html#exercieses",
    "href": "contents/6/06-.html#exercieses",
    "title": "6  Classes/Packages for Python",
    "section": "6.5 Exercieses",
    "text": "6.5 Exercieses\n\nExercise 6.1 (Heron’s formula) Consider a triangle whose sides are \\(a\\), \\(b\\) and \\(c\\). Heron’s formula states that the area of this triangle is \\[\\sqrt{s(s−a)(s−b)(s−c)}\\quad\\text{ where } s=\\frac12(a+b+c).\\]\nPlease write a function that given three points computes the area of the triangle with vertices being the given points. The input is required to be a list of three tuples, where each tuple contains two numbers representing the 2d-coordinate of a point.\n\n\nExercise 6.2 (array) Write a function to reverse an 1D NumPy array (first element becomes last).\n\n\nExercise 6.3 (Compare two numpy arraies) Consider two numpy arraies x and y. Compare them entry by entry. We would like to know how many are the same.\nWrite a function that the inputs are x and y, and the output is the number of the same numbers."
  },
  {
    "objectID": "contents/6/06-.html#projects",
    "href": "contents/6/06-.html#projects",
    "title": "6  Classes/Packages for Python",
    "section": "6.6 Projects",
    "text": "6.6 Projects\nProblems are based on [2].\n\nExercise 6.4 (Comma Code) Say you have a list value like this: spam = ['apples', 'bananas', 'tofu', 'cats'].\nWrite a function that takes a list value as an argument and returns a string with all the items separated by a comma and a space, with and inserted before the last item. For example, passing the previous spam list to the function would return ‘apples, bananas, tofu, and cats’. But your function should be able to work with any list value passed to it. Be sure to test the case where an empty list [] is passed to your function.\n\n\nExercise 6.5 (Fantasy Game Inventory) You are creating a fantasy video game. The data structure to model the player’s inventory will be a dictionary where the keys are string values describing the item in the inventory and the value is an integer value detailing how many of that item the player has. For example, the dictionary value {'rope': 1, 'torch': 6, 'gold coin': 42, 'dagger': 1, 'arrow': 12} means the player has 1 rope, 6 torches, 42 gold coins, and so on.\nWrite a function named displayInventory() that would take any possible inventory and display it like the following:\n\nInventory:\n12 arrow\n42 gold coin\n1 rope\n6 torch\n1 dagger\nTotal number of items: 62\n\nNote that this is the function version of Exercise 2.17.\n\n\nExercise 6.6 Create a Car class with two instance attributes:\n\n.color, which stores the name of the car’s color as a string.\n.mileage, which stores the number of miles on the car as an integer.\n\nThen instantiate two Car objects — a blue car with 20,000 miles and a red car with 30,000 miles — and print out their colors and mileage. Your expected output are below:\n\ncar1 = mycar(color='blue', mileage=20000)\ncar2 = mycar(color='red', mileage=30000)\n\nprint(car1)\nprint(car2)\n\nA blue car with 20000 mileage.\nA red car with 30000 mileage.\n\n\n\n\nExercise 6.7 Create a GoldenRetriever class that inherits from the Dog class. Give the sound argument of GoldenRetriever.speak() a default value of Bark. Use the following code for your parent Dog class:\n\nclass Dog:\n    species = \"Canis familiaris\"\n\n    def __init__(self, name, age):\n        self.name = name\n        self.age = age\n\n    def __str__(self):\n        return f\"{self.name} is {self.age} years old\"\n\n    def speak(self, sound):\n        return f\"{self.name} says {sound}\"\n\n\n\n\n\n\n[1] Beuzen, T. and Timbers, T. (2022). Python packages. Taylor & Francis Group.\n\n\n[2] Sweigart, A. (2020). Automate the boring stuff with python, 2nd edition practical programming for total beginners: Practical programming for total beginners. No Starch Press."
  },
  {
    "objectID": "contents/7/07-.html",
    "href": "contents/7/07-.html",
    "title": "7  R Fundamentals",
    "section": "",
    "text": "[1]\nA few advantages about R:"
  },
  {
    "objectID": "contents/7/07-.html#hello-world-for-r",
    "href": "contents/7/07-.html#hello-world-for-r",
    "title": "7  R Fundamentals",
    "section": "7.1 Hello world for R",
    "text": "7.1 Hello world for R\n\nprint('Hello world!')\n\n[1] \"Hello world!\""
  },
  {
    "objectID": "contents/7/07-.html#essential-concepts",
    "href": "contents/7/07-.html#essential-concepts",
    "title": "7  R Fundamentals",
    "section": "7.2 Essential concepts",
    "text": "7.2 Essential concepts\n\nIn R, assignments is <-, not =. = actually works, but it may cause confusions. So it is always recommended to use <-. The R Studio keybinding for <- is alt+-.\n. is NOT a special character in R, and can be used in variable names. So is.na() simply means a function called is.na. It is not a function na in a package is as in Python.\nIn R, the block is defined by {}. Indentation is not that important.\nR has a better package management system than Python, and therefore in most cases you don’t need virtual environment for R.\n\n\n7.2.1 R Markdown / Quarto\nThe counterpart of Jupyter notebook in R is .rmd/.qmd file. Similar to a notebook, in a R Markdown / Quarto file, there is a so-called code block that can run the codes inside to produce documents with both texts and codes and codes outputs.\nIn the following two sections about R, you are supposed to submit .rmd/.qmd file.\n\n\n\n\n\n\nNote\n\n\n\nQuarto is an extension/continuation of R Markdown. Most R Markdown file can be directly translated to a Quarto file without many modifications. The main difference between R Markdown and Quarto is that Quarto has better support for other languages such as Python and Julia. You may go to its homepage for more details.\nThis note is produced by Quarto.\n\n\nThe most import part of R Markdown / Quarto is the code block, that is\nprint('Hello world!')\nIn Quarto, you may also write\nprint('Hello world!')\nThere are many options to adjust how the code blocks are excacuted. You don’t need to worry about them right now. Currently just try to write your report together with code blocks.\n\n\n7.2.2 Development tools\n\n7.2.2.1 R Studio\nFor R, the almost definite choice of IDE is R Studio. You may download and install it from the homepage.\nNote that R Studio will soon be renamed to posit. Please keep an eye on it if it will make any differences.\n\n\n7.2.2.2 R Studio Cloud\nYou may directly go to the homepage to use R Stuido from cloud. If you don’t use it a lot it should be free.\n\n\n7.2.2.3 Google Colab\nYou may use R in Google Colab. The link is colab.to/r. After you open the notebook, you may go to Edit->Notebook settings to change Runtime type to be R.\nThe rest is similar to Jupyter notebook, while the codes are now R codes."
  },
  {
    "objectID": "contents/7/07-.html#data-structures",
    "href": "contents/7/07-.html#data-structures",
    "title": "7  R Fundamentals",
    "section": "7.3 Data structures",
    "text": "7.3 Data structures\nMain reference here is [2] and [1].\n\n7.3.1 Vectors\nVector is one of the basic data structure in R. It is created by c() function. Sometimes it is called atomic vector. You may store any data types in it. R recognizes six basic types: double, integers, characters, logicals, complex and raw.\nThe data type inside a vector can be checked by typeof function.\n\ndie <- c(1, 2, 3, 4, 5, 6)\ntypeof(die)\n\n[1] \"double\"\n\n\nFor consecutive numbers, an easier way to create vector is to use :.\n\ndie <- 1:6\n\n\n\n\n\n\n\nDanger\n\n\n\nNote that vector index starts from 1 in R, while list index starts from 0 in Python.\n\n\n\ndie[1]\n\n[1] 1\n\n\nWhen slicing with vectors, don’t forget to use c().\n\ndie[c(2, 3)]\n\n[1] 2 3\n\n\n\ndie[2:3]\n\n[1] 2 3\n\n\nYou may use length() function to get its length.\n\nlength(die)\n\n[1] 6\n\n\n\n\n7.3.2 Attributes\nR objects may have attributes. Attributes won’t be shown by default when you show the object. You may find the attributes of a R object by calling the attributes() function.\nThe following example show that the vector die defined in Section 7.3.1 doesn’t have attributes.\n\nattributes(die)\n\nNULL\n\n\nAttributes can be read and write using attr function. See the following example.\n\n\nExample 7.1 \nattr(die, 'date') <- '2022-01-01'\ndie\n\n[1] 1 2 3 4 5 6\nattr(,\"date\")\n[1] \"2022-01-01\"\n\nattr(die, 'date') <- NULL\ndie\n\n[1] 1 2 3 4 5 6\n\n\n\nYou may think attributes as metadata attached to a R object. They are used to tell some useful infomation of the object. Some functions will interact with certain attributes. R itself treat attributes class, comment, dim, dimnames, names, row.names and tsp specially. We will only talk about class and names here. dim will be discussed in the next section. Others will be discussed when we use them.\n\nclass: This is different from the class in Python. class in R is an attribute which talks about the class of an object. If the attribute class is not assigned to an object, the object will have an implicit class: matrix, array, function, numeric or the result of typeof.\n\nattr(x, 'class') will show the “external” class of an object. You may also use class(x) to read and write attribute class. If the class is not assigned, class(x) will show the implicit class, while attr(x, 'class') will show NULL.\n\n\nExample 7.2 \nattr(die, 'class')\n\nNULL\n\nclass(die)\n\n[1] \"integer\"\n\nclass(die) <- 'a die'\nattr(die, 'class')\n\n[1] \"a die\"\n\nclass(die)\n\n[1] \"a die\"\n\n\n\n\n\n\n\nnames: This attribute is used to name each element in a vector. After the names are assigned, it won’t be displayed below the data like other attributes. It will be displayed above the data with correct alignment. Similar to class, you may use names() to read and write the attribute.\n\n\n\nExample 7.3 \nnames(die) <- c('one', 'two', 'three', 'four', 'five', 'six')\ndie\n\n  one   two three  four  five   six \n    1     2     3     4     5     6 \n\nattributes(die)\n\n$names\n[1] \"one\"   \"two\"   \"three\" \"four\"  \"five\"  \"six\"  \n\nnames(die)\n\n[1] \"one\"   \"two\"   \"three\" \"four\"  \"five\"  \"six\"  \n\nis.vector(die)\n\n[1] TRUE\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nWhen you store different types of data into a single vector in R, R will convert them into a single type. The default way to do so is\n\nif there are only logicals and numbers, logicals will be converted to numbers by TRUE->1 and FALSE->0.\nif characters are presented, all are converted to characters by what it is.\n\n\nc(1, TRUE)\n\n[1] 1 1\n\nc('1', 1, TRUE)\n\n[1] \"1\"    \"1\"    \"TRUE\"\n\n\n\n\n\n\n7.3.3 matrices and arrays\n\nm <- matrix(c(1,2,3,4,5,6), nrow=2)\nm[1, ]\n\n[1] 1 3 5\n\n\nA matrix has dim attribute.\n\ndim(m)\n\n[1] 2 3\n\n\nNote that by assigning and removing dim attribute, you may change the object between vectors and matrices.\n\n\nExample 7.4 \nm\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2    4    6\n\nis.matrix(m)\n\n[1] TRUE\n\nis.vector(m)\n\n[1] FALSE\n\ndim(m)\n\n[1] 2 3\n\ndim(m) <- NULL\nm\n\n[1] 1 2 3 4 5 6\n\nis.matrix(m)\n\n[1] FALSE\n\nis.vector(m)\n\n[1] TRUE\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe dim of a matrix/vector can be a long vector. In this case, it will become an array.\n\n\n\n\n7.3.4 factors\n\n\n7.3.5 Lists\nList is very similar to a vector. The main difference is that vector can only store values, while list can store objects. The most typical example of objects is another vector. Please see the following example.\n\n\nExample 7.5 \nc(1:2, 3:4)\n\n[1] 1 2 3 4\n\nlist(1:2, 3:4)\n\n[[1]]\n[1] 1 2\n\n[[2]]\n[1] 3 4\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe attributes of an object is stored in an array.\n\nm <- matrix(c(1,2,3,4,5,6), nrow=2)\na <- attributes(m)\nclass(a)\n\n[1] \"list\"\n\n\n\n\n\n\n7.3.6 data.frame\nData Frame is a 2d version of a list. You may think about it in terms of tables.\n\ndf <- data.frame(face = c(\"ace\", \"two\", \"six\"),\n                 suit = c(\"clubs\", \"clubs\", \"clubs\"),\n                 value = c(1, 2, 3))\ndf\n\n  face  suit value\n1  ace clubs     1\n2  two clubs     2\n3  six clubs     3\n\n\n\nData Frame group vectors. Each vector represents a column.\nDifferent column can contain a different type of data, but every cell within one column must be the same type of data.\ndata.frame() can be used to create a data.frame.\nThe type of a data.frame is a list. Similar to matrix comparing to vector, a data.frame is a list with class data.frame, as well as a few other attributes.\n\n\n\n7.3.7 Examples\n\nExample 7.6 Consider a date.frame representing a deck of cards. Here we use expand.grid() to perform the Cartesian product.\n\nsuit <- c('spades', 'hearts', 'clubs', 'diamonds')\nface <- 1:13\ndeck <- expand.grid(suit, face)\nhead(deck)\n\n      Var1 Var2\n1   spades    1\n2   hearts    1\n3    clubs    1\n4 diamonds    1\n5   spades    2\n6   hearts    2\n\n\nWe may assign names to change the column names.\n\nnames(deck) <- c('suit', 'face')\nhead(deck)\n\n      suit face\n1   spades    1\n2   hearts    1\n3    clubs    1\n4 diamonds    1\n5   spades    2\n6   hearts    2\n\n\nNote that since suit and face are two vectors, merge() can also do the Cartesian product. expand.grid() is good for both vectors and data.frame.\n\nmerge(suit, face)\n\n          x  y\n1    spades  1\n2    hearts  1\n3     clubs  1\n4  diamonds  1\n5    spades  2\n6    hearts  2\n7     clubs  2\n8  diamonds  2\n9    spades  3\n10   hearts  3\n11    clubs  3\n12 diamonds  3\n13   spades  4\n14   hearts  4\n15    clubs  4\n16 diamonds  4\n17   spades  5\n18   hearts  5\n19    clubs  5\n20 diamonds  5\n21   spades  6\n22   hearts  6\n23    clubs  6\n24 diamonds  6\n25   spades  7\n26   hearts  7\n27    clubs  7\n28 diamonds  7\n29   spades  8\n30   hearts  8\n31    clubs  8\n32 diamonds  8\n33   spades  9\n34   hearts  9\n35    clubs  9\n36 diamonds  9\n37   spades 10\n38   hearts 10\n39    clubs 10\n40 diamonds 10\n41   spades 11\n42   hearts 11\n43    clubs 11\n44 diamonds 11\n45   spades 12\n46   hearts 12\n47    clubs 12\n48 diamonds 12\n49   spades 13\n50   hearts 13\n51    clubs 13\n52 diamonds 13\n\n\n\n\n\n7.3.8 Load data\n\n7.3.8.1 build-in datasets\nR has many build-in datasets. You may use data() to see all of them. Here are a few common datasets.\n\nmtcars: Motor Trend Car Road Tests: The data was extracted from the 1974 Motor Trend US magazine, and comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles (1973–74 models)\n\n\ndata(mtcars)\n\n\niris: iris data set gives the measurements in centimeters of the variables sepal length, sepal width, petal length and petal width, respectively, for 50 flowers from each of 3 species of iris. The species are Iris setosa, versicolor, and virginica.\n\n\ndata(iris)\n\n\nToothGrowth: ToothGrowth data set contains the result from an experiment studying the effect of vitamin C on tooth growth in 60 Guinea pigs.\n\n\ndata(ToothGrowth)\n\n\nPlantGrowth: Results obtained from an experiment to compare yields (as measured by dried weight of plants) obtained under a control and two different treatment condition.\n\n\ndata(PlantGrowth)\n\n\nUSArrests: This data set contains statistics about violent crime rates by us state.\n\n\ndata(USArrests)\n\n\n\n7.3.8.2 Read from files\nThe build-in read.csv() function can directly read .csv file into a data.frame.\n\nExample 7.7 We use the file yob1880.txt from Chapter 5 here. Put the file in the working folder and run the following code.\n\ndf <- read.csv('yob1880.txt', header = FALSE)\nhead(df)\n\n\n\n\nWe may also manually assign columns names.\n\nnames(df) <- c('name', 'sex', 'counts')\nhead(df)\n\n       name sex counts\n1      Mary   F   7065\n2      Anna   F   2604\n3      Emma   F   2003\n4 Elizabeth   F   1939\n5    Minnie   F   1746\n6  Margaret   F   1578\n\n\n\n\n\n\n\n\n\nNotes\n\n\n\nTo save data is straightforward.\n\nwrite.csv(df, file='df.csv', row.names=FALSE)\n\n\n\n\n\n\n7.3.9 Flow control\n\n7.3.9.1 for loop\n\n\nExample 7.8 \nfor (x in 1:10){\n    print(x)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7\n[1] 8\n[1] 9\n[1] 10\n\n\n\n\n\n7.3.9.2 if-else\n\n\nExample 7.9 \na <- 200\nb <- 33\n\nif (b > a) {\n  print(\"b is greater than a\")\n} else if (a == b) {\n  print(\"a and b are equal\")\n} else {\n  print(\"a is greater than b\")\n}\n\n[1] \"a is greater than b\"\n\n\n\n\n\n7.3.9.3 Functions\n\n\nExample 7.10 \nmyfunction <- function() {\n    die <- 1:6\n    sum(die)\n}\n\nmyfunction()\n\n[1] 21"
  },
  {
    "objectID": "contents/7/07-.html#r-notations",
    "href": "contents/7/07-.html#r-notations",
    "title": "7  R Fundamentals",
    "section": "7.4 R notations",
    "text": "7.4 R notations\n\n7.4.1 Selecting Values\nLet us start from a data.frame df. The basic usage is df[ , ], where the first index is to subset the rows and the second index is to subset the columns. There are six ways to writing indexes.\n\nPositive integers: the regular way. df[i, j] means the data in the ith row and jth column. If i or j are a vector, a data.frame will be returned."
  },
  {
    "objectID": "contents/7/07-.html#exercises",
    "href": "contents/7/07-.html#exercises",
    "title": "7  R Fundamentals",
    "section": "7.5 Exercises",
    "text": "7.5 Exercises\n\nExercise 7.1 Which of these are character strings and which are numbers? 1, \"1\", \"one\".\n\n\nExercise 7.2 Create an atomic vector that stores just the face names of the cards: the ace of spades, king of spades, queen of spades, jack of spades, and ten of spades. Which type of vector will you use to save the names?\nHint: The face name of the ace of spades would be ace and spades is the suit.\n\n\nExercise 7.3 Create the following matrix, which stores the name and suit of every card in a royal flush.\n\n\n     [,1]    [,2]    \n[1,] \"ace\"   \"spades\"\n[2,] \"king\"  \"spades\"\n[3,] \"queen\" \"spades\"\n[4,] \"jack\"  \"spades\"\n[5,] \"ten\"   \"spades\"\n\n\n\n\nExercise 7.4 Many card games assign a numerical value to each card. For example, in blackjack, each face card is worth 10 points, each number card is worth between 2 and 10 points, and each ace is worth 1 or 11 points, depending on the final score.\nMake a virtual playing card by combining “ace” “heart” and 1 into a vector. What type of atomic vector will result? Check if you are right, and explain your reason.\n\n\nExercise 7.5 Use a list to store a single playing card, like the ace of hearts, which has a point value of one. The list should save the face of the card, the suit, and the point value in separate elements."
  },
  {
    "objectID": "contents/7/07-.html#projects",
    "href": "contents/7/07-.html#projects",
    "title": "7  R Fundamentals",
    "section": "7.6 Projects",
    "text": "7.6 Projects\n\nExercise 7.6 Start a R Markdown / Quarto file. In the first section write a R code block to print Hello world!.\n\n\n\n\n\n[1] Wickham, H. and Grolemund, G. (2017). R for data science: Import, tidy, transform, visualize, and model data. O’Reilly Media.\n\n\n[2] Grolemund, G. (2014). Hands-on programming with r: Write your own functions and simulations. O’Reilly Media."
  },
  {
    "objectID": "contents/references.html",
    "href": "contents/references.html",
    "title": "References",
    "section": "",
    "text": "[1] Klosterman, S.\n(2021). Data\nscience projects with python: A case study approach to gaining valuable\ninsights from real data with machine learning. Packt\nPublishing, Limited.\n\n\n[2] McKinney, W.\n(2017). Python for data analysis: Data wrangling with pandas, NumPy,\nand IPython. O’Reilly Media.\n\n\n[3] Shaw, Z. A.\n(2017). Learn\npython 3 the hard way. Addison Wesley.\n\n\n[4] Sweigart, A.\n(2020). Automate the\nboring stuff with python, 2nd edition practical programming for total\nbeginners: Practical programming for total beginners. No Starch\nPress.\n\n\n[5] Prabhakaran, S.\n(2018). 101\nNumPy exercises for data analysis (python).\n\n\n[6] Grolemund, G.\n(2014). Hands-on programming with r: Write your own functions and\nsimulations. O’Reilly Media.\n\n\n[7] Prabhakaran, S.\n(2018). 101\npandas exercises for data analysis.\n\n\n[8] Beuzen, T. and\nTimbers, T. (2022). Python\npackages. Taylor & Francis Group.\n\n\n[9] Wickham, H. and\nGrolemund, G. (2017). R for data science: Import, tidy,\ntransform, visualize, and model data. O’Reilly Media.\n\n\n[10] Youens-Clark, K.\n(2020). Tiny python\nprojects. Manning Publications."
  },
  {
    "objectID": "contents/app/setup.html",
    "href": "contents/app/setup.html",
    "title": "Appendix A — Setup",
    "section": "",
    "text": "Note that all the following steps are tested in Windows 10/11. If you use other operation systems please contact me.\n\nGo to Anaconda download page. Download and install Anaconda.\nGo to VS Code download page. Download and install VS Code. Actually Anaconda contains one copy of VS Code. Here I just assume that some of you intall VS Code before Anaconda.\nWhen installing VS Code, you may accept all default settings. When installing Anaconda, please pay attention to the PATH setting.\n\n\n\n\n\n\nThe first box is unchecked by default. This setting is related to the ability to easily run Python code in Terminals. I recommend you to check it. If you don’t check it during this step, you may add it to the system environment variable PATH manually later.\n\nThe UI of VS Code looks as follows.\n\n\n\n\n\n\nPlease look at the fifth tab from the left sidebar. It is the Extension tab.\n\n\n\n\n\nPlease search for python and install the first Python extension from Microsoft. It will actually install five extensions. These are all we need for now.\n\nAfter all are installed, go to the first Explorer tab on the left side bar, and Open Folder. This is the working directory for your project.\n\n\n\n\n\n\nChoose one folder and start a new .py file.\n\n\n\n\n\n\nIf everything is setup correctly, you may see the Python version and environment name at the right lower corner. In our case the environment name is base. We will need it in the future.\n\n\n\n\n\n\nNote that we are not looking at the Python for Language Mode. If you see Select Interpreter there, it means that VS Code doesn’t find your Python interpreter. Please restart VS Code or select it manually, or check whether Anaconda is installed correctly.\n\n\n\n\n\nTo check whether everything is setup correctly, please run the following tests.\n\nUse ctrl+shift+p to open the Command Palette, type “Jupyter: Create Interactive Window” and press enter to open the Jupyter interactive window.\n\n\n\n\n\n\nIf the interactive window starts and you see the loading infomation of your kernel as follows, especially you see the environment name on the right upper corner, then you get everything correctly. However we will still do more tests.\n\n\n\n\n\n\nIn the window type import numpy as np to test whether you are able to import packages. If you don’t see any error messages then it means good.\n\n\n\n\n\n\n\nIn the editor window, type import numpy as np and right click the body to choose Run Current File in Interactive Window, and see whether it runs in interactive window.\n\n\n\n\n\n\n\nOpen the terminal. Please use Command Prompt instead of Powershell. Activate the conda environment by type the command conda activate base in the example above. Please change the name to match your own environment. If conda cannot be recognized, please register Python and Anaconda to the system environment path. Please see the next Appendix for details."
  },
  {
    "objectID": "contents/app/setup.html#sec-googlecolab",
    "href": "contents/app/setup.html#sec-googlecolab",
    "title": "Appendix A — Setup",
    "section": "A.2 Google Colab",
    "text": "A.2 Google Colab\nGoogle Colab is a product from Google Research, that allows anybody to write and execute arbitrary Python code through the browser, and is especially well suited to machine learning, data analysis and education.\nHere is the link to Google Colab. To use it you should have a Google account. Otherwise it is very simple to start, since a lot of packages for our course are already installed.\n\nA.2.1 Install packages\nIf you would like to install more packages, you can type %pip install + package name in a code cell and execute it.\nThe drawback here is that Google Colab can only stay for 24 hours. After that, all additionaly installed packages will be earsed. However you can put %pip install + package name at the beginning of your notebook and these packages will be installed every time you run the notebook.\n\n\nA.2.2 Upload files\nYou may directly upload files to the working directory of Google Colab. This has to be done in the browser. When working with these files, you may just use relative paths.\nThe drawback here is that Google Colab can only stay for 24 hours. After that, although your .ipynb files will be stores, all other files will be earsed.\n\n\nA.2.3 Mount Google Drive\nOne way to let the uploaded files stay in cloud is to upload them to Google Drive, and then load your Google Drive contents from Google Colab.\nGoole Drive is a cloud storage service provided by Google. When you register a Google account you will be automatically assigned a Google Drive account. You may get access to it from this link.\nHere are the steps to mount Google Drive:\n\nUpload your files to your Google Drive.\nRun the following codes in Colab code cells before you are loading the uploaded files:\n\n\nfrom google.colab import drive\ndrive.mount('/content/gdrive')\n\n\nA window pop up asking you about the permission. Authorize and the drive is mounted.\nTo work in directories, the most popular commands are\n\n%ls: list all files and folders in the working directory.\n%cd + folder name: Get into a specific folder.\n%cd..: Get into the parent folder. Then use these commands to find the files your just uploaded.\n\nFinally you may directly get access to those files just like they are in the working directory."
  },
  {
    "objectID": "contents/app/path.html",
    "href": "contents/app/path.html",
    "title": "Appendix B — PATH",
    "section": "",
    "text": "First in the start menu search for Edit the system environment variables.\n\n\n\n\n\n\n\nThen click the Environment Variables... button at the right lower corner.\n\n\n\n\n\n\n\nFind the Path variable in either the upper window or the lower window. Use which one depends on whether you want to register the variable for the user or for the machine. In this example I add for the user.\n\n\n\n\n\n\n\nFinally double click the variable and add the following path to it. You need to make changes according to your installation. I recommend you to locate your Anaconda installation first to get the path."
  }
]